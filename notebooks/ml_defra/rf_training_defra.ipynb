{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca1a56a7",
   "metadata": {},
   "source": [
    "# Random Forest Modelling Notebook for DEFRA\n",
    "\n",
    "- This notebook for Random Forest training using 2D flattened data.\n",
    "- Inputs will be taken from: `data/defra/ml_prep` folder.\n",
    "- Following the same structure as LAQN RF training for direct comparison.\n",
    "- Using Géron's *Hands-On Machine Learning with Scikit-Learn, Keras and TensorFlow* 3rd edition.\n",
    "\n",
    "---\n",
    "\n",
    "## What this notebook does\n",
    "\n",
    "1. Load prepared data from ml_prep output.\n",
    "2. Understand the X and y structure (following Géron Chapter 2).\n",
    "3. Train a baseline Random Forest model.\n",
    "4. Evaluate using RMSE, MAE, R² (Géron Chapter 2 evaluation approach).\n",
    "5. Fine-tune hyperparameters with GridSearchCV (Géron Chapter 2).\n",
    "6. Analyse feature importance.\n",
    "7. Save the trained model.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Random Forest?\n",
    "\n",
    "From Géron (2023, Chapter 7), Random Forest is an ensemble of Decision Trees trained on different random subsets of the training data. Each tree votes on the prediction, and the final output is the average (for regression) or majority vote (for classification).\n",
    "\n",
    "Key advantages for air quality prediction:\n",
    "- Handles nonlinear relationships without feature scaling.\n",
    "- Provides feature importance for interpretability.\n",
    "- Robust against overfitting when properly tuned.\n",
    "- Works well with tabular data like our flattened time series.\n",
    "\n",
    "---\n",
    "\n",
    "## DEFRA vs LAQN comparison context\n",
    "\n",
    "| Metric | LAQN | DEFRA |\n",
    "| --- | --- | --- |\n",
    "| Training samples | 9,946 | 11,138 |\n",
    "| Validation samples | 2,131 | 2,387 |\n",
    "| Test samples | 2,132 | 2,387 |\n",
    "| Features (flattened) | 468 | 288 |\n",
    "| Original features | 39 | 24 |\n",
    "| Target station | EN5_NO2 | London_Haringey_Priory_Park_South_NO2 |\n",
    "| Distance between targets | ~3.3 km | - |\n",
    "\n",
    "This comparison tests whether DEFRA's higher completeness (91.2% vs 87.1%) compensates for fewer stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed7557e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mandatory libraries for random forest training\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# scikit-learn for random forest and evaluation\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# before grid search, I decided to use kfold n_splits=5\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# modules for evaluation metrics - scikit-learn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# gridsearch for hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# visualisation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e542e78",
   "metadata": {},
   "source": [
    "### File paths\n",
    "\n",
    "Loading from the ml_prep output folder where all prepared arrays are saved.\n",
    "\n",
    "**CHANGE FROM LAQN:** Path changed from `data/laqn/ml_prep` to `data/defra/ml_prep`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1575cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /Users/burdzhuchaglayan/Desktop/data science projects/air-pollution-levels/data/defra/ml_prep\n",
      "Saving results to: /Users/burdzhuchaglayan/Desktop/data science projects/air-pollution-levels/data/defra/rf_model\n"
     ]
    }
   ],
   "source": [
    "# Paths setup matching ml_prep output \n",
    "base_dir = Path.cwd().parent.parent / \"data\" / \"defra\"\n",
    "ml_prep_dir = base_dir / \"ml_prep\"\n",
    "\n",
    "# Output folder for this notebook\n",
    "rf_output_dir = base_dir / \"rf_model\"\n",
    "rf_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Loading data from: {ml_prep_dir}\")\n",
    "print(f\"Saving results to: {rf_output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfc1049",
   "metadata": {},
   "source": [
    "## 1) Load prepared data\n",
    "\n",
    "The ml_prep notebook created:\n",
    "- `X_train_rf.npy`: Flattened training features (11,138 samples × 288 features)\n",
    "- `X_val_rf.npy`: Flattened validation features (2,387 samples × 288 features)\n",
    "- `X_test_rf.npy`: Flattened test features (2,387 samples × 288 features)\n",
    "- `y_train.npy`, `y_val.npy`, `y_test.npy`: Target values\n",
    "- `rf_feature_names.joblib`: Feature names for interpretability\n",
    "- `scaler.joblib`: MinMaxScaler to reverse normalisation\n",
    "\n",
    "The flattening was necessary because Random Forest expects 2D input (samples, features), but the original sequences were 3D (samples, timesteps, features).\n",
    "\n",
    "### DEFRA vs LAQN data shapes:\n",
    "\n",
    "| Dataset | LAQN | DEFRA |\n",
    "| --- | --- | --- |\n",
    "| X_train_rf | (9946, 468) | (11138, 288) |\n",
    "| X_val_rf | (2131, 468) | (2387, 288) |\n",
    "| X_test_rf | (2132, 468) | (2387, 288) |\n",
    "| y_train | (9946, 39) | (11138, 24) |\n",
    "\n",
    "DEFRA has ~12% more samples but fewer features (24 vs 39 original, 288 vs 468 flattened)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55c10c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "# load all prepared data\n",
    "print(\"Loading data\")\n",
    "\n",
    "X_train = np.load(ml_prep_dir / \"X_train_rf.npy\")\n",
    "X_val = np.load(ml_prep_dir / \"X_val_rf.npy\")\n",
    "X_test = np.load(ml_prep_dir / \"X_test_rf.npy\")\n",
    "\n",
    "y_train = np.load(ml_prep_dir / \"y_train.npy\")\n",
    "y_val = np.load(ml_prep_dir / \"y_val.npy\")\n",
    "y_test = np.load(ml_prep_dir / \"y_test.npy\")\n",
    "\n",
    "rf_feature_names = joblib.load(ml_prep_dir / \"rf_feature_names.joblib\")\n",
    "feature_names = joblib.load(ml_prep_dir / \"feature_names.joblib\")\n",
    "scaler = joblib.load(ml_prep_dir / \"scaler.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "841d2ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (11138, 288)\n",
      "X_val shape: (2387, 288)\n",
      "X_test shape: (2387, 288)\n",
      "y_train shape: (11138, 24)\n",
      "y_val shape: (2387, 24)\n",
      "y_test shape: (2387, 24)\n",
      "Number of RF features: 288\n",
      "Number of target features: 24\n"
     ]
    }
   ],
   "source": [
    "# check loaded data shapes\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "print(f\"Number of RF features: {len(rf_feature_names)}\")\n",
    "print(f\"Number of target features: {len(feature_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4d6986",
   "metadata": {},
   "source": [
    "X_train shape: (11138, 288)\n",
    "X_val shape: (2387, 288)\n",
    "X_test shape: (2387, 288)\n",
    "y_train shape: (11138, 24)\n",
    "y_val shape: (2387, 24)\n",
    "y_test shape: (2387, 24)\n",
    "Number of RF features: 288\n",
    "Number of target features: 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8782c6a1",
   "metadata": {},
   "source": [
    "## 2) Select target pollutant\n",
    "\n",
    "The y array has 24 outputs (one for each feature). For better evaluation, I will train a single-output model first.\n",
    "\n",
    "### Why single-output?\n",
    "\n",
    "Starting with one target keeps things simple:\n",
    "- Easier to interpret evaluation metrics (RMSE, R² for one pollutant).\n",
    "- Easier to understand feature importance (what predicts NO2 specifically).\n",
    "- Can train separate models for PM10 and O3 later and compare.\n",
    "\n",
    "### Which target to select?\n",
    "\n",
    "From DEFRA ml_prep, the target station is **London_Haringey_Priory_Park_South_NO2**:\n",
    "- Located ~3.3 km from LAQN's EN5 station\n",
    "- 95.1% data coverage\n",
    "- Enables direct comparison with LAQN RF results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c517a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available targets:\n",
      "   0: London_Hillingdon_O3\n",
      "   1: London_Harlington_PM10\n",
      "   2: London_Hillingdon_NO2\n",
      "   3: London_Westminster_NO2\n",
      "   4: London_Honor_Oak_Park_PM10\n",
      "   5: London_N._Kensington_NO2\n",
      "   6: Camden_Kerbside_NO2\n",
      "   7: London_Hillingdon_PM10\n",
      "   8: Southwark_A2_Old_Kent_Road_NO2\n",
      "   9: Borehamwood_Meadow_Park_NO2\n",
      "  10: London_Bloomsbury_NO2\n",
      "  11: London_Harlington_NO2\n",
      "  12: Borehamwood_Meadow_Park_PM10\n",
      "  13: London_Bloomsbury_O3\n",
      "  14: London_N._Kensington_O3\n",
      "  15: London_Haringey_Priory_Park_South_NO2\n",
      "  16: London_Bexley_NO2\n",
      "  17: London_Westminster_O3\n",
      "  18: London_Bloomsbury_PM10\n",
      "  19: London_Marylebone_Road_NO2\n",
      "  20: hour\n",
      "  21: day_of_week\n",
      "  22: month\n",
      "  23: is_weekend\n"
     ]
    }
   ],
   "source": [
    "# list targets\n",
    "print(\"Available targets:\")\n",
    "for i, name in enumerate(feature_names):\n",
    "    print(f\"  {i:2d}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930b7686",
   "metadata": {},
   "source": [
    "Available targets:\n",
    "   0: London_Hillingdon_O3\n",
    "   1: London_Harlington_PM10\n",
    "   2: London_Hillingdon_NO2\n",
    "   3: London_Westminster_NO2\n",
    "   4: London_Honor_Oak_Park_PM10\n",
    "   5: London_N._Kensington_NO2\n",
    "   6: Camden_Kerbside_NO2\n",
    "   7: London_Hillingdon_PM10\n",
    "   8: Southwark_A2_Old_Kent_Road_NO2\n",
    "   9: Borehamwood_Meadow_Park_NO2\n",
    "  10: London_Bloomsbury_NO2\n",
    "  11: London_Harlington_NO2\n",
    "  12: Borehamwood_Meadow_Park_PM10\n",
    "  13: London_Bloomsbury_O3\n",
    "  14: London_N._Kensington_O3\n",
    "  15: London_Haringey_Priory_Park_South_NO2\n",
    "  16: London_Bexley_NO2\n",
    "  17: London_Westminster_O3\n",
    "  18: London_Bloomsbury_PM10\n",
    "  19: London_Marylebone_Road_NO2\n",
    "  20: hour\n",
    "  21: day_of_week\n",
    "  22: month\n",
    "  23: is_weekend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd58874e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: London_Haringey_Priory_Park_South_NO2\n",
      "Target index: 15\n",
      "y_train_single: (11138,)\n",
      "Range: [0.0000, 1.0000]\n"
     ]
    }
   ],
   "source": [
    "# find the target station index\n",
    "# From ml_prep: London_Haringey_Priory_Park_South_NO2 is our target\n",
    "target_name = \"London_Haringey_Priory_Park_South_NO2\"\n",
    "\n",
    "# find index of target in feature_names\n",
    "try:\n",
    "    target_idx = feature_names.index(target_name)\n",
    "except ValueError:\n",
    "    # if exact name not found, search for partial match\n",
    "    for i, name in enumerate(feature_names):\n",
    "        if 'Haringey' in name and 'NO2' in name:\n",
    "            target_idx = i\n",
    "            target_name = name\n",
    "            break\n",
    "\n",
    "y_train_single = y_train[:, target_idx]\n",
    "y_val_single = y_val[:, target_idx]\n",
    "y_test_single = y_test[:, target_idx]\n",
    "\n",
    "print(f\"Target: {target_name}\")\n",
    "print(f\"Target index: {target_idx}\")\n",
    "print(f\"y_train_single: {y_train_single.shape}\")\n",
    "print(f\"Range: [{y_train_single.min():.4f}, {y_train_single.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2070ff",
   "metadata": {},
   "source": [
    "Target: London_Haringey_Priory_Park_South_NO2\n",
    "Target index: 15\n",
    "y_train_single: (11138,)\n",
    "Range: [0.0000, 1.0000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec23f60",
   "metadata": {},
   "source": [
    "## 3) Train baseline model (Géron Chapter 7)\n",
    "\n",
    "From Géron (2023, Chapter 7 - Ensemble Learning and Random Forests):\n",
    "\n",
    "> \"A random forest is an ensemble of decision trees, generally trained via the bagging method (or sometimes pasting), typically with `max_samples` set to the size of the training set. Instead of building a `BaggingClassifier` and passing it a `DecisionTreeClassifier`, you can use the `RandomForestClassifier` class, which is more convenient and optimized for decision trees (similarly, there is a `RandomForestRegressor` class for regression tasks).\"\n",
    "\n",
    "Since I am predicting continuous pollution values (regression), I use `RandomForestRegressor`.\n",
    "\n",
    "### Key parameters:\n",
    "\n",
    "| Parameter | Default | What it does |\n",
    "| --- | --- | --- |\n",
    "| n_estimators | 100 | Number of trees in the forest |\n",
    "| max_leaf_nodes | None | Maximum leaf nodes per tree |\n",
    "| n_jobs | -1 | CPU cores to use (-1 = all available) |\n",
    "| random_state | 42 | Seed for reproducibility |\n",
    "\n",
    "Géron's example uses `n_estimators=500` and `max_leaf_nodes=16`, but I start with defaults to establish a baseline before tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a77e6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training baseline Random Forest\n",
      "----------------------------------------\n",
      "\n",
      "Training complete in 33.32 seconds\n",
      "Number of trees: 100\n",
      "Max leaf nodes: None\n",
      "Max depth: None\n"
     ]
    }
   ],
   "source": [
    "# train baseline Random Forest\n",
    "# Using RandomForestRegressor for regression task predicting continuous values following Géron's structure from Chapter 7\n",
    "\n",
    "print(\"Training baseline Random Forest\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# baseline with default parameters\n",
    "rf_baseline = RandomForestRegressor(\n",
    "    n_estimators=100,      # default, Géron's example uses 500\n",
    "    random_state=42,       # for reproducibility\n",
    "    n_jobs=-1              # use all CPU cores\n",
    ")\n",
    "\n",
    "rf_baseline.fit(X_train, y_train_single)\n",
    "\n",
    "baseline_time = time.time() - start\n",
    "\n",
    "print(f\"\\nTraining complete in {baseline_time:.2f} seconds\")\n",
    "print(f\"Number of trees: {rf_baseline.n_estimators}\")\n",
    "print(f\"Max leaf nodes: {rf_baseline.max_leaf_nodes}\")\n",
    "print(f\"Max depth: {rf_baseline.max_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c30355",
   "metadata": {},
   "source": [
    "    Training baseline Random Forest\n",
    "    ----------------------------------------\n",
    "\n",
    "    Training complete in 33.32 seconds\n",
    "    Number of trees: 100\n",
    "    Max leaf nodes: None\n",
    "    Max depth: None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad01d60",
   "metadata": {},
   "source": [
    "## 4) Evaluate baseline model\n",
    "\n",
    "To evaluate the baseline model, I use three metrics from scikit-learn's `sklearn.metrics` module.\n",
    "\n",
    "### RMSE (Root Mean Square Error)\n",
    "\n",
    "$$RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}$$\n",
    "\n",
    "Penalises large errors more heavily. Lower is better.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "```\n",
    "\n",
    "### MAE (Mean Absolute Error)\n",
    "\n",
    "$$MAE = \\frac{1}{n}\\sum_{i=1}^{n}|y_i - \\hat{y}_i|$$\n",
    "\n",
    "Average absolute difference between actual and predicted. More interpretable than RMSE. Lower is better.\n",
    "\n",
    "### R² (Coefficient of Determination)\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\sum(y_i - \\hat{y}_i)^2}{\\sum(y_i - \\bar{y})^2}$$\n",
    "\n",
    "Proportion of variance explained by the model. Range 0 to 1, higher is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1127be82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X, y_true, name):\n",
    "    \"\"\"\n",
    "    Evaluate model using RMSE, MAE, and R².\n",
    "    \n",
    "    Params:\n",
    "    model : trained sklearn model\n",
    "    X : feature matrix (n_samples, n_features)\n",
    "    y_true : actual values (n_samples,)\n",
    "    name : string for display\n",
    "    \n",
    "    Returns: dict with rmse, mae, r2, and y_pred\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # RMSE using np.sqrt\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    # MAE avg absolute difference\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    # R^2 proportion of variance explained\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  RMSE = {rmse:.6f}\")\n",
    "    print(f\"  MAE  = {mae:.6f}\")\n",
    "    print(f\"  R^2  = {r2:.6f}\")\n",
    "    \n",
    "    return {'rmse': rmse, 'mae': mae, 'r2': r2, 'y_pred': y_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8985c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Evaluation\n",
      "========================================\n",
      "Training:\n",
      "  RMSE = 0.016983\n",
      "  MAE  = 0.011019\n",
      "  R^2  = 0.984685\n",
      "\n",
      "Validation:\n",
      "  RMSE = 0.042742\n",
      "  MAE  = 0.027620\n",
      "  R^2  = 0.865686\n",
      "\n",
      "Test:\n",
      "  RMSE = 0.033585\n",
      "  MAE  = 0.022963\n",
      "  R^2  = 0.851746\n"
     ]
    }
   ],
   "source": [
    "# Evaluate baseline on three sets\n",
    "print(\"Baseline Model Evaluation\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "base_train = evaluate(rf_baseline, X_train, y_train_single, \"Training\")\n",
    "print()\n",
    "base_val = evaluate(rf_baseline, X_val, y_val_single, \"Validation\")\n",
    "print()\n",
    "base_test = evaluate(rf_baseline, X_test, y_test_single, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad4508c",
   "metadata": {},
   "source": [
    "    Baseline Model Evaluation\n",
    "    ========================================\n",
    "    Training:\n",
    "    RMSE = 0.016983\n",
    "    MAE  = 0.011019\n",
    "    R^2  = 0.984685\n",
    "\n",
    "    Validation:\n",
    "    RMSE = 0.042742\n",
    "    MAE  = 0.027620\n",
    "    R^2  = 0.865686\n",
    "\n",
    "    Test:\n",
    "    RMSE = 0.033585\n",
    "    MAE  = 0.022963\n",
    "    R^2  = 0.851746"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf8d005",
   "metadata": {},
   "source": [
    "The gap between training R² (0.985) and validation R² (0.866) is **0.119** which shows mild overfitting. Similar to LAQN (0.118 gap), the model memorised training data rather than learning general patterns. However, DEFRA's validation R² (0.866) is already higher than LAQN's (0.861), suggesting better generalisation despite similar overfitting levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe5362d",
   "metadata": {},
   "source": [
    "### Checking for overfitting\n",
    "\n",
    "The training R² is higher than validation R², indicating some overfitting. This happens when the model memorises training data instead of learning general patterns.\n",
    "\n",
    "Signs of overfitting:\n",
    "- Training R² close to 1.0 (0.985), validation R² lower (0.866).\n",
    "- Gap of 0.119 between training and validation R².\n",
    "\n",
    "**DEFRA vs LAQN overfitting comparison:**\n",
    "\n",
    "| Metric | LAQN | DEFRA |\n",
    "|--------|------|-------|\n",
    "| Training R² | 0.979 | 0.985 |\n",
    "| Validation R² | 0.861 | 0.866 |\n",
    "| Gap | 0.118 | 0.119 |\n",
    "\n",
    "Both datasets show similar overfitting levels (~0.12 gap). However, DEFRA starts from a higher baseline, so even with overfitting, it generalises better. I'll tune hyperparameters to reduce overfitting further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0e9bb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfitting Check\n",
      "========================================\n",
      "Training R^2:   0.9847\n",
      "Validation R^2: 0.8657\n",
      "Gap:            0.1190\n",
      "\n",
      "Mild overfitting = tuning may help.\n"
     ]
    }
   ],
   "source": [
    "# overfitting check\n",
    "r2_gap = base_train['r2'] - base_val['r2']\n",
    "print(\"Overfitting Check\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Training R^2:   {base_train['r2']:.4f}\")\n",
    "print(f\"Validation R^2: {base_val['r2']:.4f}\")\n",
    "print(f\"Gap:            {r2_gap:.4f}\")\n",
    "\n",
    "if r2_gap > 0.15:\n",
    "    print(f\"\\nModel overfits significantly.\")\n",
    "elif r2_gap > 0.05:\n",
    "    print(\"\\nMild overfitting = tuning may help.\")\n",
    "else:\n",
    "    print(\"\\nNo significant overfitting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52fa88d",
   "metadata": {},
   "source": [
    "    Overfitting Check\n",
    "    ========================================\n",
    "    Training R^2:   0.9847\n",
    "    Validation R^2: 0.8657\n",
    "    Gap:            0.1190\n",
    "\n",
    "    Mild overfitting = tuning may help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01bec12",
   "metadata": {},
   "source": [
    "## 5) Cross-validation \n",
    "\n",
    "### What is K-fold cross-validation?\n",
    "\n",
    "From scikit-learn documentation:\n",
    "> \"K-Fold cross-validator provides train/test indices to split data in train/test sets. Split dataset into k consecutive folds (without shuffling by default). Each fold is then used once as a validation while the k - 1 remaining folds form the training set.\"\n",
    "\n",
    "### sklearn.model_selection.KFold\n",
    "\n",
    "```python\n",
    "class sklearn.model_selection.KFold(n_splits=5, shuffle=False, random_state=None)\n",
    "```\n",
    "\n",
    "**Parameters:**\n",
    "- `n_splits`: int, default=5. Number of folds. Must be at least 2.\n",
    "- `shuffle`: bool, default=False. Whether to shuffle the data before splitting.\n",
    "- `random_state`: int or None. Controls randomness when shuffle is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a02b96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 5-fold Cross-Validation:\n",
      "----------------------------------------\n",
      "Fold 1: RMSE = 0.050789\n",
      "Fold 2: RMSE = 0.050265\n",
      "Fold 3: RMSE = 0.049500\n",
      "Fold 4: RMSE = 0.037068\n",
      "Fold 5: RMSE = 0.045720\n",
      "\n",
      "CV RMSE: 0.046668 +/- 0.005119\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "cv_rmse_scores = []\n",
    "\n",
    "print(\"Running 5-fold Cross-Validation:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "    # split data\n",
    "    X_fold_train = X_train[train_idx]\n",
    "    X_fold_val = X_train[val_idx]\n",
    "    y_fold_train = y_train_single[train_idx]\n",
    "    y_fold_val = y_train_single[val_idx]\n",
    "    \n",
    "    # train and evaluate\n",
    "    rf_baseline.fit(X_fold_train, y_fold_train)\n",
    "    y_pred = rf_baseline.predict(X_fold_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_fold_val, y_pred))\n",
    "    cv_rmse_scores.append(rmse)\n",
    "    print(f\"Fold {i+1}: RMSE = {rmse:.6f}\")\n",
    "\n",
    "print(f\"\\nCV RMSE: {np.mean(cv_rmse_scores):.6f} +/- {np.std(cv_rmse_scores):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2637a4f1",
   "metadata": {},
   "source": [
    "    Running 5-fold Cross-Validation:\n",
    "    ----------------------------------------\n",
    "    Fold 1: RMSE = 0.050789\n",
    "    Fold 2: RMSE = 0.050265\n",
    "    Fold 3: RMSE = 0.049500\n",
    "    Fold 4: RMSE = 0.037068\n",
    "    Fold 5: RMSE = 0.045720\n",
    "\n",
    "    CV RMSE: 0.046668 +/- 0.005119"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4120b8",
   "metadata": {},
   "source": [
    "## 5-Fold Cross-Validation Results\n",
    "\n",
    "### DEFRA Results:\n",
    "| Fold | RMSE |\n",
    "|------|------|\n",
    "| Fold 1 | 0.050789 |\n",
    "| Fold 2 | 0.050265 |\n",
    "| Fold 3 | 0.049500 |\n",
    "| Fold 4 | 0.037068 |\n",
    "| Fold 5 | 0.045720 |\n",
    "| **CV RMSE** | **0.046668 ± 0.005119** |\n",
    "\n",
    "### DEFRA vs LAQN Cross-Validation Comparison:\n",
    "\n",
    "| Metric | LAQN | DEFRA | Difference |\n",
    "|--------|------|-------|------------|\n",
    "| CV RMSE (mean) | 0.054215 | 0.046668 | -13.9% ✓ |\n",
    "| CV RMSE (std) | 0.004412 | 0.005119 | +16.0% |\n",
    "| Best fold | 0.049685 | 0.037068 | -25.4% ✓ |\n",
    "| Worst fold | 0.062451 | 0.050789 | -18.7% ✓ |\n",
    "| Range | 0.012766 | 0.013721 | +7.5% |\n",
    "\n",
    "### Key observations:\n",
    "\n",
    "**1. DEFRA has lower mean CV RMSE (0.047 vs 0.054)**\n",
    "\n",
    "DEFRA predictions are ~14% more accurate on average across all folds. This confirms the baseline findings - higher data quality leads to better predictions.\n",
    "\n",
    "**2. DEFRA has slightly higher variance (±0.005 vs ±0.004)**\n",
    "\n",
    "DEFRA's fold scores vary more, particularly Fold 4 (0.037) which is unusually good. This suggests some time periods in DEFRA data are easier to predict than others.\n",
    "\n",
    "**3. Both datasets show consistent performance**\n",
    "\n",
    "Neither shows extreme variation between folds, indicating stable model behaviour across different data subsets.\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "The cross-validation confirms DEFRA's superior performance is genuine, not a lucky train/test split. The 14% lower CV RMSE demonstrates that DEFRA's higher data completeness (91.2% vs 87.1%) translates to measurably better predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c27db5",
   "metadata": {},
   "source": [
    "## 6) Hyperparameter tuning with GridSearchCV\n",
    "\n",
    "From Géron (2023, Chapter 2):\n",
    "\n",
    "> \"GridSearchCV uses cross-validation to evaluate all the possible combinations of hyperparameter values you want to test.\"\n",
    "\n",
    "### Parameter grid\n",
    "\n",
    "Using the same grid as LAQN for fair comparison:\n",
    "\n",
    "| Parameter | Values to test | Purpose |\n",
    "| --- | --- | --- |\n",
    "| n_estimators | [100, 200] | Number of trees |\n",
    "| max_depth | [10, 20, None] | Tree depth limit |\n",
    "| min_samples_split | [2, 5] | Minimum samples to split |\n",
    "| min_samples_leaf | [1, 2] | Minimum samples in leaf |\n",
    "\n",
    "Total combinations: 2 × 3 × 2 × 2 = 24"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
