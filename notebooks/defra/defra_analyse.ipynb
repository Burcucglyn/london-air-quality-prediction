{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64359774",
   "metadata": {},
   "source": [
    "# DEFRA Dataset Assesment\n",
    "\n",
    "\n",
    "1) I'll be start adding my main paths and modules I will be using in this notebook below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "432092e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible python modules i will be using below\n",
    "from curses import meta\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "#define base path  without hardcoding\n",
    "base_dir = Path.home() / \"Desktop\" / \"data science projects\" / \"air-pollution-levels\" / \"data\" / \"defra\" / \"optimised\"\n",
    "#metadata file for pollutant name, location and site names\n",
    "metadata_path = Path.home() / \"Desktop\" / \"data science projects\" / \"air-pollution-levels\" / \"data\" / \"defra\" /\"test\"/\"std_london_sites_pollutant.csv\"\n",
    "\n",
    "# output path for saving statistics 1. function\n",
    "#the first analyse dataset created without inclitiong nan optimased files, and cross referencing that's why changed the name to dataset_statistics-noNAN-incl.csv\n",
    "stats_output_path = base_dir/\"report\"/ \"defra_stats.csv\"\n",
    "\n",
    "# log file from nan replacement process\n",
    "nan_log_path = Path.home() / \"Desktop\" / \"data science projects\" / \"air-pollution-levels\" / \"data\" / \"defra\" / \"logs\" / \"NaN_values_record.csv\"\n",
    "\n",
    "# possible python modules i will be using below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f95bb4",
   "metadata": {},
   "source": [
    "## 1) Initial Dataset Assessment: Raw Numbers\n",
    "\n",
    "Before conducting quality checks, I need to establish the baseline characteristics of the DEFRA dataset. This section calculates comprehensive statistics about the data collection effort, including file counts, measurement records, station coverage, and pollutant distribution.\n",
    "\n",
    "### Purpose\n",
    "- Document the scale and scope of data collection.\n",
    "- Establish baseline metrics for comparison with LAQN.\n",
    "- Provide context for subsequent quality analysis.\n",
    "\n",
    "### Methodology\n",
    "The function `get_defra_dataset_statistics()` performs the following:\n",
    "1. Loads standardised metadata to identify unique stations and pollutants.\n",
    "2. Counts files across all three yearly directories (2023, 2024, 2025).\n",
    "3. Calculates total measurement records by reading all CSV files.\n",
    "4. Determines spatial coverage from unique coordinate pairs.\n",
    "5. Documents temporal coverage (35 months: January 2023 to November 2025).\n",
    "\n",
    "### Notes\n",
    "- File counting is fast (scans directory structure only).\n",
    "- Record counting can be slow (reads every CSV file).\n",
    "- Results are saved to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e6f4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_defra_dataset_statistics(base_dir, metadata_path, nan_log_path):\n",
    "    \"\"\"\n",
    "    Calculate statistics at DEFRA dataset.\n",
    "    This function walks through the monthly data directories 2023, 2024, 2025 and calculates key metrics needed for reporting.\n",
    "    \n",
    "    Parameters:\n",
    "        base_dir : Path\n",
    "            Base directory containing defra data folders.\n",
    "        metadata_path : Path\n",
    "            Path to the standardised metadata csv file.\n",
    "        nan_log_path : Path\n",
    "            Path to the NaN values log file after notice data flags, changed them to NaN.\n",
    "            \n",
    "    Returns:\n",
    "        dict : Dictionary containing all calculated statistics.\n",
    "    \"\"\"\n",
    "    \n",
    "    stats = {}\n",
    "    \n",
    "    # read metadata to get station and pollutant info\n",
    "    print(\"\\nloading metadata from std_london_sites_pollutant.csv...\")\n",
    "    metadata = pd.read_csv(metadata_path, encoding=\"utf-8\")\n",
    "    \n",
    "    # calculate metadata statistics\n",
    "    stats['unique_stations'] = metadata['station_name'].nunique()\n",
    "    stats['total_combinations'] = len(metadata)\n",
    "    stats['unique_pollutants'] = metadata['pollutant_std'].nunique()\n",
    "    \n",
    "    # get pollutant breakdown\n",
    "    pollutant_counts = metadata['pollutant_std'].value_counts()\n",
    "    stats['pollutant_distribution'] = pollutant_counts.to_dict()\n",
    "    \n",
    "    # create set of expected station/pollutant pairs from metadata\n",
    "    expected_pairs = set(\n",
    "        zip(metadata['station_name'], metadata['pollutant_std'])\n",
    "    )\n",
    "    stats['expected_pairs'] = len(expected_pairs)\n",
    "    print(f\"  expected station/pollutant pairs from metadata: {len(expected_pairs)}\")\n",
    "    \n",
    "    # count unique coordinates for spatial coverage, i will be use this for laqn dataset as well\n",
    "    # group by lat/lon and count unique locations, instead of station names and will do the validation afterwards\n",
    "    unique_coords = metadata[['latitude', 'longitude']].drop_duplicates()\n",
    "    stats['unique_locations'] = len(unique_coords)\n",
    "    \n",
    "    # count files in monthly data directories\n",
    "    total_files = 0\n",
    "    files_by_year = {}\n",
    "    \n",
    "    # loop through each years measurement directory\n",
    "    print(\"\\nscanning optimised directory for collected data...\")\n",
    "    for year in ['2023', '2024', '2025']:\n",
    "        year_dir = Path(base_dir) / f'{year}measurements'\n",
    "        \n",
    "        if year_dir.exists():\n",
    "            # count all CSV files in this years directory and subdirectories\n",
    "            year_files = list(year_dir.rglob('*.csv'))\n",
    "            files_by_year[year] = len(year_files)\n",
    "            total_files += len(year_files)\n",
    "            print(f\"  {year}: {len(year_files)} files\")\n",
    "        else:\n",
    "            files_by_year[year] = 0\n",
    "            print(f\"  {year}: directory not found\")\n",
    "    \n",
    "    stats['total_files'] = total_files\n",
    "    stats['files_by_year'] = files_by_year\n",
    "    \n",
    "    # calculate total measurement records, this requires reading all csv files and counting rows\n",
    "    total_records = 0\n",
    "    records_by_year = {}\n",
    "    total_missing = 0\n",
    "    missing_by_year = {}\n",
    "    \n",
    "    # concatenate all CSVs for missing value breakdown\n",
    "    all_csvs = []\n",
    "    \n",
    "    print(\"\\nreading all CSV files to calculate statistics...\")\n",
    "    for year in ['2023', '2024', '2025']:\n",
    "        year_dir = Path(base_dir) / f'{year}measurements'\n",
    "        year_records = 0\n",
    "        year_missing = 0\n",
    "        \n",
    "        if year_dir.exists():\n",
    "            # read each csv, count rows and missing values\n",
    "            for csv_file in year_dir.rglob('*.csv'):\n",
    "                try:\n",
    "                    df = pd.read_csv(csv_file)\n",
    "                    year_records += len(df)\n",
    "                    \n",
    "                    # count missing NaN or empty string values in value column\n",
    "                    # calculation: missing values in value column only\n",
    "                    if 'value' in df.columns:\n",
    "                        missing_in_file = df['value'].isna().sum() + (df['value'] == \"\").sum()\n",
    "                        year_missing += missing_in_file\n",
    "                    \n",
    "                    # store dataframe for later aggregation\n",
    "                    all_csvs.append(df)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"  warning: could not read {csv_file.name}: {e}\")\n",
    "            \n",
    "            records_by_year[year] = year_records\n",
    "            missing_by_year[year] = year_missing\n",
    "            total_records += year_records\n",
    "            total_missing += year_missing\n",
    "            print(f\"  {year}: {year_records:,} records, {year_missing:,} missing ({(year_missing/year_records*100):.2f}%)\")\n",
    "        else:\n",
    "            records_by_year[year] = 0\n",
    "            missing_by_year[year] = 0\n",
    "    \n",
    "    stats['total_records'] = total_records\n",
    "    stats['records_by_year'] = records_by_year\n",
    "    stats['missing_by_year'] = missing_by_year\n",
    "    stats['total_missing'] = total_missing\n",
    "    stats['overall_completeness'] = ((total_records - total_missing) / total_records * 100) if total_records > 0 else 0\n",
    "    \n",
    "    # cross-reference metadata with collected data\n",
    "    print(\"\\ncross-referencing collected data with metadata...\")\n",
    "    \n",
    "    if all_csvs:\n",
    "        all_data = pd.concat(all_csvs, ignore_index=True)\n",
    "        \n",
    "        # check if required columns exist in csv files\n",
    "        # file structure: timestamp,value,timeseries_id,station_name,pollutant_name,pollutant_std,latitude,longitude\n",
    "        if 'station_name' in all_data.columns and 'pollutant_std' in all_data.columns:\n",
    "            # identify actual station/pollutant pairs in collected data\n",
    "            collected_pairs = set(\n",
    "                zip(all_data['station_name'], all_data['pollutant_std'])\n",
    "            )\n",
    "            stats['collected_pairs'] = len(collected_pairs)\n",
    "            \n",
    "            # find missing pairs (in metadata but not in collected data)\n",
    "            missing_pairs = expected_pairs - collected_pairs\n",
    "            stats['missing_pairs'] = list(missing_pairs)\n",
    "            stats['missing_pairs_count'] = len(missing_pairs)\n",
    "            \n",
    "            # find extra pairs (in collected data but not in metadata)\n",
    "            extra_pairs = collected_pairs - expected_pairs\n",
    "            stats['extra_pairs'] = list(extra_pairs)\n",
    "            stats['extra_pairs_count'] = len(extra_pairs)\n",
    "            \n",
    "            print(f\"  expected pairs from metadata: {len(expected_pairs)}\")\n",
    "            print(f\"  actually collected pairs: {len(collected_pairs)}\")\n",
    "            print(f\"  missing pairs (in metadata but not collected): {len(missing_pairs)}\")\n",
    "            print(f\"  extra pairs (collected but not in metadata): {len(extra_pairs)}\")\n",
    "            \n",
    "            # group by station and pollutant_std, count missing values\n",
    "            # calculation: (100 * missing value cell number) / (total number of row value col)\n",
    "            missing_breakdown = {}\n",
    "            \n",
    "            for (station, pollutant), group in all_data.groupby(['station_name', 'pollutant_std']):\n",
    "                total_rows = len(group)\n",
    "                # count missing in value column\n",
    "                if 'value' in group.columns:\n",
    "                    missing_rows = group['value'].isna().sum() + (group['value'] == \"\").sum()\n",
    "                else:\n",
    "                    missing_rows = 0\n",
    "                \n",
    "                missing_breakdown[(station, pollutant)] = (int(missing_rows), int(total_rows))\n",
    "            \n",
    "            stats['missing_by_station_pollutant'] = missing_breakdown\n",
    "        else:\n",
    "            print(\"  warning: station_name or pollutant_std columns not found\")\n",
    "            stats['missing_by_station_pollutant'] = {}\n",
    "            stats['collected_pairs'] = 0\n",
    "            stats['missing_pairs'] = []\n",
    "            stats['missing_pairs_count'] = 0\n",
    "            stats['extra_pairs'] = []\n",
    "            stats['extra_pairs_count'] = 0\n",
    "    else:\n",
    "        stats['missing_by_station_pollutant'] = {}\n",
    "        stats['collected_pairs'] = 0\n",
    "        stats['missing_pairs'] = list(expected_pairs)\n",
    "        stats['missing_pairs_count'] = len(expected_pairs)\n",
    "        stats['extra_pairs'] = []\n",
    "        stats['extra_pairs_count'] = 0\n",
    "    \n",
    "    # distribution of nan by pollutant over time\n",
    "    if stats['missing_by_station_pollutant']:\n",
    "        pollutant_missing_summary = {}\n",
    "        \n",
    "        for (station, pollutant), (missing, total) in stats['missing_by_station_pollutant'].items():\n",
    "            if pollutant not in pollutant_missing_summary:\n",
    "                pollutant_missing_summary[pollutant] = {'total_missing': 0, 'total_records': 0}\n",
    "            \n",
    "            pollutant_missing_summary[pollutant]['total_missing'] += missing\n",
    "            pollutant_missing_summary[pollutant]['total_records'] += total\n",
    "        \n",
    "        # calculate percentages\n",
    "        for pollutant in pollutant_missing_summary:\n",
    "            total_missing = pollutant_missing_summary[pollutant]['total_missing']\n",
    "            total_records = pollutant_missing_summary[pollutant]['total_records']\n",
    "            percentage = (total_missing / total_records * 100) if total_records > 0 else 0\n",
    "            pollutant_missing_summary[pollutant]['percentage_missing'] = percentage\n",
    "        \n",
    "        stats['missing_by_pollutant_type'] = pollutant_missing_summary\n",
    "    else:\n",
    "        stats['missing_by_pollutant_type'] = {}\n",
    "    \n",
    "    # log file created during data cleaning process\n",
    "    if Path(nan_log_path).exists():\n",
    "        nan_log = pd.read_csv(nan_log_path)\n",
    "        \n",
    "        # calculate replacement statistics per year\n",
    "        replacements_by_year = nan_log.groupby('year_folder')['invalid_flags_replaced'].sum().to_dict()\n",
    "        stats['nan_replacements_by_year'] = replacements_by_year\n",
    "        stats['total_nan_replacements'] = nan_log['invalid_flags_replaced'].sum()\n",
    "        \n",
    "        # get mean percentage of invalid flags\n",
    "        stats['mean_invalid_percentage'] = nan_log['percentage_invalid'].mean()\n",
    "        stats['max_invalid_percentage'] = nan_log['percentage_invalid'].max()\n",
    "        \n",
    "    else:\n",
    "        stats['nan_replacements_by_year'] = {}\n",
    "        stats['total_nan_replacements'] = 0\n",
    "        stats['mean_invalid_percentage'] = 0\n",
    "        stats['max_invalid_percentage'] = 0\n",
    "    \n",
    "    # calculate temporal coverage based on the files collected, understands which months have data\n",
    "    stats['temporal_coverage'] = {\n",
    "        'start_date': '2023-01-01',\n",
    "        'end_date': '2025-11-19',  \n",
    "        'total_months': 35\n",
    "    }\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df5aaa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset_statistics(stats):\n",
    "    \"\"\"\n",
    "    Print dataset statistics\n",
    "    \n",
    "    Parameters:\n",
    "        stats : dict\n",
    "            returned by get_defra_dataset_statistics().\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"Defra dataset statistics: initial assessment\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    print(\"\\nScale and scope:\")\n",
    "    print(f\"Total files collected: {stats['total_files']:,}\")\n",
    "    print(f\"Total measurement records: {stats['total_records']:,}\")\n",
    "    print(f\"Total missing values (nan): {stats['total_missing']:,}\")\n",
    "    print(f\"Overall completeness: {stats['overall_completeness']:.2f}%\")\n",
    "    print(f\"Unique monitoring stations: {stats['unique_stations']}\")\n",
    "    print(f\"Total station-pollutant combinations: {stats['total_combinations']}\")\n",
    "    print(f\"Unique pollutant types: {stats['unique_pollutants']}\")\n",
    "    print(f\"Unique geographic locations: {stats['unique_locations']}\")\n",
    "    \n",
    "    # data collection coverage\n",
    "    print(\"\\nData collection coverage:\")\n",
    "    print(f\"Expected pairs (from metadata): {stats.get('expected_pairs', 0)}\")\n",
    "    print(f\"Actually collected pairs: {stats.get('collected_pairs', 0)}\")\n",
    "    print(f\"Missing pairs (not collected): {stats.get('missing_pairs_count', 0)}\")\n",
    "    print(f\"Extra pairs (not in metadata): {stats.get('extra_pairs_count', 0)}\")\n",
    "    \n",
    "    if stats.get('missing_pairs_count', 0) > 0:\n",
    "        print(f\"\\nwarning: {stats['missing_pairs_count']} station/pollutant pairs from metadata were not found in collected data.\")\n",
    "        print(\"first 10 missing pairs:\")\n",
    "        for i, (station, pollutant) in enumerate(stats['missing_pairs'][:10], 1):\n",
    "            print(f\"  {i}. {station} - {pollutant}\")\n",
    "    \n",
    "    if stats.get('extra_pairs_count', 0) > 0:\n",
    "        print(f\"\\nNote: {stats['extra_pairs_count']} station/pollutant pairs in collected data are not in metadata.\")\n",
    "    \n",
    "    print(\"\\nfiles by year:\")\n",
    "    for year, count in stats['files_by_year'].items():\n",
    "        print(f\"  {year}: {count:,} files\")\n",
    "    \n",
    "    print(\"\\nrecords by year:\")\n",
    "    for year, count in stats['records_by_year'].items():\n",
    "        missing = stats['missing_by_year'].get(year, 0)\n",
    "        missing_pct = (missing / count * 100) if count > 0 else 0\n",
    "        print(f\"  {year}: {count:,} records, {missing:,} missing ({missing_pct:.2f}%)\")\n",
    "    \n",
    "    # adding nan value summary below\n",
    "    print(\"\\nnan replacement summary:\")\n",
    "    print(f\"Total invalid flags replaced: {stats['total_nan_replacements']:,}\")\n",
    "    print(f\"Mean invalid percentage per file: {stats['mean_invalid_percentage']:.2f}%\")\n",
    "    print(f\"Max invalid percentage: {stats['max_invalid_percentage']:.2f}%\")\n",
    "    \n",
    "    # count of replacements by year\n",
    "    if stats['nan_replacements_by_year']:\n",
    "        print(\"\\nreplacements by year:\")\n",
    "        for year_folder, count in stats['nan_replacements_by_year'].items():\n",
    "            print(f\"  {year_folder}: {count:,} flags replaced\")\n",
    "    \n",
    "    print(\"\\ntemporal coverage:\")\n",
    "    print(f\"start date: {stats['temporal_coverage']['start_date']}\")\n",
    "    print(f\"end date: {stats['temporal_coverage']['end_date']}\")\n",
    "    print(f\"total months: {stats['temporal_coverage']['total_months']}\")\n",
    "    \n",
    "    print(\"\\npollutant distribution:\")\n",
    "    print(\"station/pollutant combinations by type:\")\n",
    "    for pollutant, count in sorted(stats['pollutant_distribution'].items(), \n",
    "                                   key=lambda x: x[1], reverse=True):\n",
    "        percentage = (count / stats['total_combinations']) * 100\n",
    "        print(f\"  {pollutant}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # missing value distribution by pollutant type\n",
    "    print(\"\\nMissing value distribution by pollutant type:\")\n",
    "    if stats.get('missing_by_pollutant_type'):\n",
    "        # sort by percentage missing (highest first)\n",
    "        sorted_pollutants = sorted(\n",
    "            stats['missing_by_pollutant_type'].items(),\n",
    "            key=lambda x: x[1]['percentage_missing'],\n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        print(f\"{'pollutant':<20} {'total records':>15} {'missing':>12} {'% missing':>12}\")\n",
    "        print(\"-\" * 60)\n",
    "        for pollutant, data in sorted_pollutants:\n",
    "            print(f\"{pollutant:<20} {data['total_records']:>15,} {data['total_missing']:>12,} {data['percentage_missing']:>11.2f}%\")\n",
    "    else:\n",
    "        print(\"  no missing value distribution available.\")\n",
    "    \n",
    "    # print missing values by station/pollutant breakdown with row_number column\n",
    "    print(\"\\nMissing values by station/pollutant:\")\n",
    "    if stats.get('missing_by_station_pollutant'):\n",
    "        # prepare a sorted list by missing percentage descending\n",
    "        breakdown = []\n",
    "        for (station, pollutant), (missing, total) in stats['missing_by_station_pollutant'].items():\n",
    "            percent = (missing / total * 100) if total > 0 else 0\n",
    "            # row_number is the same as total (number of rows in value column)\n",
    "            row_number = total\n",
    "            breakdown.append((station, pollutant, row_number, missing, total, percent))\n",
    "        \n",
    "        # sort by percentage descending and take top 20\n",
    "        breakdown.sort(key=lambda x: x[5], reverse=True)\n",
    "        breakdown = breakdown[:20]\n",
    "        \n",
    "        print(f\"{'station':<30} {'pollutant':<20} {'row_number':>12} {'missing':>10} {'total':>10} {'% missing':>12}\")\n",
    "        print(\"-\" * 95)\n",
    "        for station, pollutant, row_number, missing, total, percent in breakdown:\n",
    "            print(f\"{station:<30} {pollutant:<20} {row_number:>12,} {missing:>10,} {total:>10,} {percent:>11.2f}%\")\n",
    "    else:\n",
    "        print(\" No missing value breakdown available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d0ac31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loading metadata from std_london_sites_pollutant.csv...\n",
      "  expected station/pollutant pairs from metadata: 141\n",
      "\n",
      "scanning optimised directory for collected data...\n",
      "  2023: 1431 files\n",
      "  2024: 1193 files\n",
      "  2025: 939 files\n",
      "\n",
      "reading all CSV files to calculate statistics...\n",
      "  2023: 1,000,126 records, 90,161 missing (9.01%)\n",
      "  2024: 868,320 records, 101,256 missing (11.66%)\n",
      "  2025: 657,545 records, 30,750 missing (4.68%)\n",
      "\n",
      "cross-referencing collected data with metadata...\n",
      "  expected pairs from metadata: 141\n",
      "  actually collected pairs: 141\n",
      "  missing pairs (in metadata but not collected): 0\n",
      "  extra pairs (collected but not in metadata): 0\n",
      "\n",
      "========================================\n",
      "defra dataset statistics: initial assessment\n",
      "========================================\n",
      "\n",
      "scale and scope:\n",
      "total files collected: 3,563\n",
      "total measurement records: 2,525,991\n",
      "total missing values (nan): 222,167\n",
      "overall completeness: 91.20%\n",
      "unique monitoring stations: 18\n",
      "total station-pollutant combinations: 144\n",
      "unique pollutant types: 37\n",
      "unique geographic locations: 20\n",
      "\n",
      "data collection coverage:\n",
      "expected pairs (from metadata): 141\n",
      "actually collected pairs: 141\n",
      "missing pairs (not collected): 0\n",
      "extra pairs (not in metadata): 0\n",
      "\n",
      "files by year:\n",
      "  2023: 1,431 files\n",
      "  2024: 1,193 files\n",
      "  2025: 939 files\n",
      "\n",
      "records by year:\n",
      "  2023: 1,000,126 records, 90,161 missing (9.01%)\n",
      "  2024: 868,320 records, 101,256 missing (11.66%)\n",
      "  2025: 657,545 records, 30,750 missing (4.68%)\n",
      "\n",
      "nan replacement summary:\n",
      "total invalid flags replaced: 222,167\n",
      "mean invalid percentage per file: 9.61%\n",
      "max invalid percentage: 100.00%\n",
      "\n",
      "replacements by year:\n",
      "  2023measurements: 90,161 flags replaced\n",
      "  2024measurements: 101,256 flags replaced\n",
      "  2025measurements: 30,750 flags replaced\n",
      "\n",
      "temporal coverage:\n",
      "start date: 2023-01-01\n",
      "end date: 2025-11-19\n",
      "total months: 35\n",
      "\n",
      "pollutant distribution:\n",
      "station/pollutant combinations by type:\n",
      "  PM10: 15 (10.4%)\n",
      "  PM2.5: 15 (10.4%)\n",
      "  NO2: 14 (9.7%)\n",
      "  NOx: 14 (9.7%)\n",
      "  NO: 14 (9.7%)\n",
      "  O3: 9 (6.2%)\n",
      "  SO2: 3 (2.1%)\n",
      "  n-Pentane: 2 (1.4%)\n",
      "  m,p-Xylene: 2 (1.4%)\n",
      "  n-Butane: 2 (1.4%)\n",
      "  n-Heptane: 2 (1.4%)\n",
      "  n-Hexane: 2 (1.4%)\n",
      "  n-Octane: 2 (1.4%)\n",
      "  Propene: 2 (1.4%)\n",
      "  o-Xylene: 2 (1.4%)\n",
      "  Propane: 2 (1.4%)\n",
      "  i-Pentane: 2 (1.4%)\n",
      "  Toluene: 2 (1.4%)\n",
      "  trans-2-Butene: 2 (1.4%)\n",
      "  trans-2-Pentene: 2 (1.4%)\n",
      "  Isoprene: 2 (1.4%)\n",
      "  Ethyne: 2 (1.4%)\n",
      "  i-Octane: 2 (1.4%)\n",
      "  i-Hexane: 2 (1.4%)\n",
      "  i-Butane: 2 (1.4%)\n",
      "  Ethylbenzene: 2 (1.4%)\n",
      "  Ethene: 2 (1.4%)\n",
      "  Ethane: 2 (1.4%)\n",
      "  cis-2-Butene: 2 (1.4%)\n",
      "  Benzene: 2 (1.4%)\n",
      "  1-Pentene: 2 (1.4%)\n",
      "  1-Butene: 2 (1.4%)\n",
      "  1,3-Butadiene: 2 (1.4%)\n",
      "  1,3,5-TMB: 2 (1.4%)\n",
      "  1,2,4-TMB: 2 (1.4%)\n",
      "  1,2,3-TMB: 2 (1.4%)\n",
      "  CO: 2 (1.4%)\n",
      "\n",
      "missing value distribution by pollutant type:\n",
      "pollutant              total records      missing    % missing\n",
      "------------------------------------------------------------\n",
      "PM10                         227,142       37,580       16.54%\n",
      "O3                           194,333       27,184       13.99%\n",
      "PM2.5                        234,748       29,623       12.62%\n",
      "SO2                           72,928        7,181        9.85%\n",
      "NO                           326,061       25,444        7.80%\n",
      "NO2                          326,072       25,429        7.80%\n",
      "NOx                          325,387       24,964        7.67%\n",
      "n-Octane                      26,649        1,764        6.62%\n",
      "CO                            48,578        3,078        6.34%\n",
      "m,p-Xylene                    25,503        1,612        6.32%\n",
      "1,3,5-TMB                     26,649        1,641        6.16%\n",
      "Toluene                       26,649        1,640        6.15%\n",
      "i-Octane                      26,649        1,624        6.09%\n",
      "n-Heptane                     26,649        1,622        6.09%\n",
      "1,2,4-TMB                     26,649        1,610        6.04%\n",
      "Ethylbenzene                  26,649        1,592        5.97%\n",
      "Benzene                       26,649        1,586        5.95%\n",
      "o-Xylene                      26,649        1,568        5.88%\n",
      "1,2,3-TMB                     26,649        1,560        5.85%\n",
      "1-Pentene                     26,572        1,381        5.20%\n",
      "cis-2-Butene                  26,599        1,378        5.18%\n",
      "trans-2-Pentene               26,599        1,366        5.14%\n",
      "Isoprene                      26,618        1,341        5.04%\n",
      "Ethyne                        26,529        1,328        5.01%\n",
      "1,3-Butadiene                 26,568        1,320        4.97%\n",
      "i-Hexane                      26,599        1,321        4.97%\n",
      "trans-2-Butene                26,599        1,321        4.97%\n",
      "n-Hexane                      26,580        1,320        4.97%\n",
      "Propane                       26,618        1,316        4.94%\n",
      "Ethane                        26,599        1,315        4.94%\n",
      "Ethene                        26,618        1,312        4.93%\n",
      "Propene                       26,618        1,312        4.93%\n",
      "i-Butane                      26,599        1,308        4.92%\n",
      "1-Butene                      26,599        1,307        4.91%\n",
      "n-Butane                      26,599        1,307        4.91%\n",
      "i-Pentane                     26,618        1,306        4.91%\n",
      "n-Pentane                     26,618        1,306        4.91%\n",
      "\n",
      "missing values by station/pollutant:\n",
      "station                        pollutant               missing      total    % missing\n",
      "-------------------------------------------------------------------------------------\n",
      "London Eltham                  PM10                     16,337     16,826       97.09%\n",
      "London Eltham                  NO2                      13,187     16,840       78.31%\n",
      "London Eltham                  NO                       13,182     16,835       78.30%\n",
      "London Eltham                  NOx                      13,125     16,793       78.16%\n",
      "London Eltham                  O3                       12,537     16,842       74.44%\n",
      "London Teddington Bushy Park   PM10                     10,525     24,327       43.26%\n",
      "London Teddington Bushy Park   PM2.5                    20,820     48,656       42.79%\n",
      "London Haringey Priory Park South O3                        8,171     24,288       33.64%\n",
      "London Marylebone Road         PM10                        632      2,355       26.84%\n",
      "London Marylebone Road         PM2.5                       479      2,355       20.34%\n",
      "London Norbury Manor School    PM10                        936      5,258       17.80%\n",
      "London Norbury Manor School    PM2.5                       936      5,258       17.80%\n",
      "London Bexley                  PM10                      4,012     24,273       16.53%\n",
      "Southwark A2 Old Kent Road     PM10                        388      2,355       16.48%\n",
      "Haringey Roadside              NOx                       3,725     24,250       15.36%\n",
      "Haringey Roadside              NO2                       3,708     24,285       15.27%\n",
      "Haringey Roadside              NO                        3,708     24,287       15.27%\n",
      "London Westminster             PM2.5                     3,463     24,299       14.25%\n",
      "London Marylebone Road         SO2                       2,987     24,290       12.30%\n",
      "London Marylebone Road         CO                        2,729     24,293       11.23%\n"
     ]
    }
   ],
   "source": [
    "# run the analysis\n",
    "stats = get_defra_dataset_statistics(base_dir, metadata_path, nan_log_path)\n",
    "print_dataset_statistics(stats)\n",
    "\n",
    "# # Save statistics for later use as csv\n",
    "# save statistics for later use as csv\n",
    "# prepare flat data structure for csv\n",
    "stats_rows = []\n",
    "stats_rows.append([\"metric\", \"value\"])\n",
    "stats_rows.append([\"total_files\", stats['total_files']])\n",
    "stats_rows.append([\"total_records\", stats['total_records']])\n",
    "stats_rows.append([\"total_missing\", stats['total_missing']])\n",
    "stats_rows.append([\"overall_completeness_pct\", f\"{stats['overall_completeness']:.2f}\"])\n",
    "stats_rows.append([\"unique_stations\", stats['unique_stations']])\n",
    "stats_rows.append([\"total_combinations\", stats['total_combinations']])\n",
    "stats_rows.append([\"unique_pollutants\", stats['unique_pollutants']])\n",
    "stats_rows.append([\"unique_locations\", stats['unique_locations']])\n",
    "stats_rows.append([\"expected_pairs\", stats.get('expected_pairs', 0)])\n",
    "stats_rows.append([\"collected_pairs\", stats.get('collected_pairs', 0)])\n",
    "stats_rows.append([\"missing_pairs_count\", stats.get('missing_pairs_count', 0)])\n",
    "stats_rows.append([\"extra_pairs_count\", stats.get('extra_pairs_count', 0)])\n",
    "stats_rows.append([\"total_nan_replacements\", stats['total_nan_replacements']])\n",
    "stats_rows.append([\"mean_invalid_pct\", f\"{stats['mean_invalid_percentage']:.2f}\"])\n",
    "stats_rows.append([\"max_invalid_pct\", f\"{stats['max_invalid_percentage']:.2f}\"])\n",
    "\n",
    "# add year-specific metrics\n",
    "for year in ['2023', '2024', '2025']:\n",
    "    stats_rows.append([f\"files_{year}\", stats['files_by_year'].get(year, 0)])\n",
    "    stats_rows.append([f\"records_{year}\", stats['records_by_year'].get(year, 0)])\n",
    "    stats_rows.append([f\"missing_{year}\", stats['missing_by_year'].get(year, 0)])\n",
    "    year_key = f'{year}measurements'\n",
    "    stats_rows.append([f\"replacements_{year}\", stats['nan_replacements_by_year'].get(year_key, 0)])\n",
    "\n",
    "# save to csv\n",
    "pd.DataFrame(stats_rows[1:], columns=stats_rows[0]).to_csv(stats_output_path, index=False)\n",
    "print(f\"\\nstatistics saved to: {stats_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f816ef",
   "metadata": {},
   "source": [
    "    2023: 1431 files\n",
    "    2024: 1193 files\n",
    "    2025: 939 files\n",
    "    2023: 1,000,126 records\n",
    "    2024: 868,320 records\n",
    "    2025: 657,545 records\n",
    "\n",
    "    ========================================\n",
    "    Defra dataset statistics: initial assessment\n",
    "    ========================================\n",
    "\n",
    "    Scale and scope:\n",
    "    Total files collected: 3,563\n",
    "    Total measurement records: 2,525,991\n",
    "    Unique monitoring stations: 18\n",
    "    Total station-pollutant combinations: 144\n",
    "    Unique pollutant types: 37\n",
    "    Unique geographic locations: 20\n",
    "\n",
    "    Files by year:\n",
    "    2023: 1,431 files\n",
    "    2024: 1,193 files\n",
    "    2025: 939 files\n",
    "\n",
    "    Records by year:\n",
    "    2023: 1,000,126 measurement records\n",
    "    2024: 868,320 measurement records\n",
    "    2025: 657,545 measurement records\n",
    "\n",
    "    Temporal coverage:\n",
    "    start date: 2023-01-01\n",
    "    end date: 2025-11-19\n",
    "    total months: 35\n",
    "\n",
    "    Pollutant distribution:\n",
    "    Station/Pollutant combinations by type:\n",
    "    PM10: 15 (10.4%)\n",
    "    PM2.5: 15 (10.4%)\n",
    "    NO2: 14 (9.7%)\n",
    "    NOx: 14 (9.7%)\n",
    "    NO: 14 (9.7%)\n",
    "    O3: 9 (6.2%)\n",
    "    SO2: 3 (2.1%)\n",
    "    n-Pentane: 2 (1.4%)\n",
    "    m,p-Xylene: 2 (1.4%)\n",
    "    n-Butane: 2 (1.4%)\n",
    "    n-Heptane: 2 (1.4%)\n",
    "    n-Hexane: 2 (1.4%)\n",
    "    n-Octane: 2 (1.4%)\n",
    "    Propene: 2 (1.4%)\n",
    "    o-Xylene: 2 (1.4%)\n",
    "    Propane: 2 (1.4%)\n",
    "    i-Pentane: 2 (1.4%)\n",
    "    Toluene: 2 (1.4%)\n",
    "    trans-2-Butene: 2 (1.4%)\n",
    "    trans-2-Pentene: 2 (1.4%)\n",
    "    Isoprene: 2 (1.4%)\n",
    "    Ethyne: 2 (1.4%)\n",
    "    i-Octane: 2 (1.4%)\n",
    "    i-Hexane: 2 (1.4%)\n",
    "    i-Butane: 2 (1.4%)\n",
    "    Ethylbenzene: 2 (1.4%)\n",
    "    Ethene: 2 (1.4%)\n",
    "    Ethane: 2 (1.4%)\n",
    "    cis-2-Butene: 2 (1.4%)\n",
    "    Benzene: 2 (1.4%)\n",
    "    1-Pentene: 2 (1.4%)\n",
    "    1-Butene: 2 (1.4%)\n",
    "    1,3-Butadiene: 2 (1.4%)\n",
    "    1,3,5-TMB: 2 (1.4%)\n",
    "    1,2,4-TMB: 2 (1.4%)\n",
    "    1,2,3-TMB: 2 (1.4%)\n",
    "    CO: 2 (1.4%)\n",
    "\n",
    "- notes: analyse the stats:  2023: 1431 files, 2024: 1193 files, 2025: 939, making a total of 3,563 files. This is roughly 1k fewer than the laqn dataset which defra's issue  rate around 8%, and laqn's after hardcore cleaning decreased to %17ish. The number of monitoring stations is 18, with 37 unique pollutants and 144 station/pollutant combo. Although the defra dataset is smaller than the laqn dataset in terms of files and station/pollutant combinations promising better accuricy, and numerically six times more pollutant types than the laqn dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc7810e",
   "metadata": {},
   "source": [
    "    Expected station/pollutant pairs from metadata: 141\n",
    "    2023: 1431 files\n",
    "    2024: 1193 files\n",
    "    2025: 939 files\n",
    "    2023: 1,000,126 records, 90,161 missing (9.01%)\n",
    "    2024: 868,320 records, 101,256 missing (11.66%)\n",
    "    2025: 657,545 records, 30,750 missing (4.68%)\n",
    "\n",
    "    Cross-referencing collected data with metadata...\n",
    "    Expected pairs from metadata: 141\n",
    "    Actually collected pairs: 141\n",
    "    Missing pairs (in metadata but not collected): 0\n",
    "    Extra pairs (collected but not in metadata): 0\n",
    "\n",
    "    ========================================\n",
    "    Defra dataset statistics: initial assessment\n",
    "    ========================================\n",
    "\n",
    "    Scale and scope:\n",
    "    Total files collected: 3,563\n",
    "    Total measurement records: 2,525,991\n",
    "    Total missing values (nan): 222,167\n",
    "    Overall completeness: 91.20%\n",
    "    Unique monitoring stations: 18\n",
    "    Total station-pollutant combinations: 144\n",
    "    Unique pollutant types: 37\n",
    "    Unique geographic locations: 20\n",
    "\n",
    "    Data collection coverage:\n",
    "    Expected pairs (from metadata): 141\n",
    "    Actually collected pairs: 141\n",
    "    Missing pairs (not collected): 0\n",
    "    Extra pairs (not in metadata): 0\n",
    "\n",
    "    Files by year:\n",
    "    2023: 1,431 files\n",
    "    2024: 1,193 files\n",
    "    2025: 939 files\n",
    "\n",
    "    Records by year:\n",
    "    2023: 1,000,126 records, 90,161 missing (9.01%)\n",
    "    2024: 868,320 records, 101,256 missing (11.66%)\n",
    "    2025: 657,545 records, 30,750 missing (4.68%)\n",
    "\n",
    "    Nan replacement summary:\n",
    "    Total invalid flags replaced: 222,167\n",
    "    Mean invalid percentage per file: 9.61%\n",
    "    Max invalid percentage: 100.00%\n",
    "\n",
    "    Replacements by year:\n",
    "    2023measurements: 90,161 flags replaced\n",
    "    2024measurements: 101,256 flags replaced\n",
    "    2025measurements: 30,750 flags replaced\n",
    "\n",
    "    Temporal coverage:\n",
    "    start date: 2023-01-01\n",
    "    end date: 2025-11-19\n",
    "    total months: 35\n",
    "\n",
    "    Pollutant distribution:\n",
    "    Station/Pollutant combinations by type:\n",
    "    PM10: 15 (10.4%)\n",
    "    PM2.5: 15 (10.4%)\n",
    "    NO2: 14 (9.7%)\n",
    "    NOx: 14 (9.7%)\n",
    "    NO: 14 (9.7%)\n",
    "    O3: 9 (6.2%)\n",
    "    SO2: 3 (2.1%)\n",
    "    n-Pentane: 2 (1.4%)\n",
    "    m,p-Xylene: 2 (1.4%)\n",
    "    n-Butane: 2 (1.4%)\n",
    "    n-Heptane: 2 (1.4%)\n",
    "    n-Hexane: 2 (1.4%)\n",
    "    n-Octane: 2 (1.4%)\n",
    "    Propene: 2 (1.4%)\n",
    "    o-Xylene: 2 (1.4%)\n",
    "    Propane: 2 (1.4%)\n",
    "    i-Pentane: 2 (1.4%)\n",
    "    Toluene: 2 (1.4%)\n",
    "    trans-2-Butene: 2 (1.4%)\n",
    "    trans-2-Pentene: 2 (1.4%)\n",
    "    Isoprene: 2 (1.4%)\n",
    "    Ethyne: 2 (1.4%)\n",
    "    i-Octane: 2 (1.4%)\n",
    "    i-Hexane: 2 (1.4%)\n",
    "    i-Butane: 2 (1.4%)\n",
    "    Ethylbenzene: 2 (1.4%)\n",
    "    Ethene: 2 (1.4%)\n",
    "    Ethane: 2 (1.4%)\n",
    "    cis-2-Butene: 2 (1.4%)\n",
    "    Benzene: 2 (1.4%)\n",
    "    1-Pentene: 2 (1.4%)\n",
    "    1-Butene: 2 (1.4%)\n",
    "    1,3-Butadiene: 2 (1.4%)\n",
    "    1,3,5-TMB: 2 (1.4%)\n",
    "    1,2,4-TMB: 2 (1.4%)\n",
    "    1,2,3-TMB: 2 (1.4%)\n",
    "    CO: 2 (1.4%)\n",
    "\n",
    "    Missing value distribution by pollutant type:\n",
    "    Pollutant              Total Records      Missing    % Missing\n",
    "    ------------------------------------------------------------\n",
    "    PM10                         227,142       37,580       16.54%\n",
    "    O3                           194,333       27,184       13.99%\n",
    "    PM2.5                        234,748       29,623       12.62%\n",
    "    SO2                           72,928        7,181        9.85%\n",
    "    NO                           326,061       25,444        7.80%\n",
    "    NO2                          326,072       25,429        7.80%\n",
    "    NOx                          325,387       24,964        7.67%\n",
    "    n-Octane                      26,649        1,764        6.62%\n",
    "    CO                            48,578        3,078        6.34%\n",
    "    m,p-Xylene                    25,503        1,612        6.32%\n",
    "    1,3,5-TMB                     26,649        1,641        6.16%\n",
    "    Toluene                       26,649        1,640        6.15%\n",
    "    i-Octane                      26,649        1,624        6.09%\n",
    "    n-Heptane                     26,649        1,622        6.09%\n",
    "    1,2,4-TMB                     26,649        1,610        6.04%\n",
    "    Ethylbenzene                  26,649        1,592        5.97%\n",
    "    Benzene                       26,649        1,586        5.95%\n",
    "    o-Xylene                      26,649        1,568        5.88%\n",
    "    1,2,3-TMB                     26,649        1,560        5.85%\n",
    "    1-Pentene                     26,572        1,381        5.20%\n",
    "    cis-2-Butene                  26,599        1,378        5.18%\n",
    "    trans-2-Pentene               26,599        1,366        5.14%\n",
    "    Isoprene                      26,618        1,341        5.04%\n",
    "    Ethyne                        26,529        1,328        5.01%\n",
    "    1,3-Butadiene                 26,568        1,320        4.97%\n",
    "    i-Hexane                      26,599        1,321        4.97%\n",
    "    trans-2-Butene                26,599        1,321        4.97%\n",
    "    n-Hexane                      26,580        1,320        4.97%\n",
    "    Propane                       26,618        1,316        4.94%\n",
    "    Ethane                        26,599        1,315        4.94%\n",
    "    Ethene                        26,618        1,312        4.93%\n",
    "    Propene                       26,618        1,312        4.93%\n",
    "    i-Butane                      26,599        1,308        4.92%\n",
    "    1-Butene                      26,599        1,307        4.91%\n",
    "    n-Butane                      26,599        1,307        4.91%\n",
    "    i-Pentane                     26,618        1,306        4.91%\n",
    "    n-Pentane                     26,618        1,306        4.91%\n",
    "\n",
    "    Missing values by station/pollutant:\n",
    "    Station                        Pollutant               Missing      Total    % Missing\n",
    "    -------------------------------------------------------------------------------------\n",
    "    London Eltham                  PM10                     16,337     16,826       97.09%\n",
    "    London Eltham                  NO2                      13,187     16,840       78.31%\n",
    "    London Eltham                  NO                       13,182     16,835       78.30%\n",
    "    London Eltham                  NOx                      13,125     16,793       78.16%\n",
    "    London Eltham                  O3                       12,537     16,842       74.44%\n",
    "    London Teddington Bushy Park   PM10                     10,525     24,327       43.26%\n",
    "    London Teddington Bushy Park   PM2.5                    20,820     48,656       42.79%\n",
    "    London Haringey Priory Park South O3                        8,171     24,288       33.64%\n",
    "    London Marylebone Road         PM10                        632      2,355       26.84%\n",
    "    London Marylebone Road         PM2.5                       479      2,355       20.34%\n",
    "    London Norbury Manor School    PM10                        936      5,258       17.80%\n",
    "    London Norbury Manor School    PM2.5                       936      5,258       17.80%\n",
    "    London Bexley                  PM10                      4,012     24,273       16.53%\n",
    "    Southwark A2 Old Kent Road     PM10                        388      2,355       16.48%\n",
    "    Haringey Roadside              NOx                       3,725     24,250       15.36%\n",
    "    Haringey Roadside              NO2                       3,708     24,285       15.27%\n",
    "    Haringey Roadside              NO                        3,708     24,287       15.27%\n",
    "    London Westminster             PM2.5                     3,463     24,299       14.25%\n",
    "    London Marylebone Road         SO2                       2,987     24,290       12.30%\n",
    "    London Marylebone Road         CO                        2,729     24,293       11.23%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f97ae28",
   "metadata": {},
   "source": [
    "## 2) Spatial Coverage Analysis\n",
    "\n",
    " analysing spatial distribution patterns before accepting the dataset. I need to understand where defra stations are located, identify any geographic biases, and compare coverage to laqn.\n",
    "\n",
    "### Purpose\n",
    "- Create maps showing station locations across London.\n",
    "- Analyse density by borough to identify coverage gaps\n",
    "- Compare spatial distribution to laqn network\n",
    "- Ensure no geographic areas are overrepresented or underrepresented\n",
    "\n",
    "### Methodology\n",
    "1. Load defra metadata with coordinates\n",
    "2. Create interactive folium map showing all stations\n",
    "3. Calculate station density by borough\n",
    "4. Identify coverage gaps in london\n",
    "5. Compare to laqn spatial distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2364fa78",
   "metadata": {},
   "source": [
    "sources: \n",
    "- https://python-visualization.github.io/folium/latest/getting_started.html\n",
    "- https://pandas.pydata.org/docs/user_guide/groupby.html \n",
    "- plotting: https://geopandas.org/en/stable/docs/user_guide/data_structures.html#geoseries\n",
    "    - general: https://geopandas.org/en/stable/getting_started.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b5f56c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "042b68d2",
   "metadata": {},
   "source": [
    "## 3) Statistical Validation\n",
    "\n",
    "A critical gap from the laqn report by applying formal statistical tests to validate data quality patterns. While descriptive statistics show 0% (before I notice the flags of the dataset) issue rate, I need statistical evidence that this pattern is real and not due to chance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
