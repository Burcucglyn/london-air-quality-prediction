{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c5dab22",
   "metadata": {},
   "source": [
    "# Cleaning LAQN Datasets\n",
    "I will be removing the files has %100 missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de71d062",
   "metadata": {},
   "source": [
    "import and path statements below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e451156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "\n",
    "# paths beloww\n",
    "base_dir = Path(\"/Users/burdzhuchaglayan/Desktop/data science projects/air-pollution-levels\")\n",
    "\n",
    "# filter logs_missin_value.csv value=100% missing value function paths below.\n",
    "input_all_missing_file = base_dir / \"data\" / \"laqn\" / \"missing\" / \"logs_missin_value.csv\"\n",
    "output_filtered_value_file = base_dir / \"data\" / \"laqn\" / \"missing\" / \"value_100filtered_missing.csv\"\n",
    "\n",
    "# analyse the sites/speciest not have any value so they're not active site/species/  analyse_affected_sites function\n",
    "output_notActive_site_species = base_dir / \"data\"/ \"laqn\"/ \"missing\"/ \"notActive_site_species.csv\"\n",
    "\n",
    "# create paths for metadata removal and update the actitive site/species list below.\n",
    "actv_sites_species_path = base_dir / \"data\" / \"laqn\" / \"actv_sites_species.csv\"\n",
    "updated_actv_site_species_path = base_dir / \"data\" / \"laqn\" / \"updated_actv_siteSpecies.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc34a874",
   "metadata": {},
   "source": [
    "#### 1) filter logs_missin_value.csv file according to 100 percent missing values.\n",
    "- filters based on 100 value column and than creates another missing_files csv.\n",
    "- filters siteCode and speciesCode columns different to find out that what site's don't have that species on their system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "311c97fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def filter_missing_pollutants():\n",
    "    \"\"\"\n",
    "    Filter the logs_missin_value.csv to create:\n",
    "   value_100filtered_missing.csv - rows with 100% EmptyValuePercentage and siteCode != SpeciesCode\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Filtering missing value logs from: {input_all_missing_file}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    # Load the file\n",
    "    df = pd.read_csv(input_all_missing_file, encoding='utf-8')\n",
    "    print(f\"Loaded {len(df)} rows from logs_missin_value.csv\")\n",
    "\n",
    "    # 1. Filter for 100% EmptyValuePercentage\n",
    "    df_100 = df[df['EmptyValuePercentage'] == 100]\n",
    "    df_100.to_csv(output_filtered_value_file, index=False)\n",
    "    print(f\"Saved {len(df_100)} rows with 100% missing values to: {output_filtered_value_file}\")\n",
    "\n",
    "    # 2. Filter where siteCode != SpeciesCode\n",
    "    df_100 = df_100[df_100['siteCode'] != df_100['SpeciesCode']]\n",
    "    df_100.to_csv(output_filtered_value_file, index=False)\n",
    "    print(f\"Saved {len(df_100)} rows (siteCode != SpeciesCode) to: {output_filtered_value_file}\")\n",
    "\n",
    "    print(\"=\"*100)\n",
    "    print(\"Filtering complete.\\n\")\n",
    "\n",
    "    return df_100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16643af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Filtering missing value logs from: /Users/burdzhuchaglayan/Desktop/data science projects/air-pollution-levels/data/laqn/missing/logs_missin_value.csv\n",
      "========================================\n",
      "Loaded 4136 rows from logs_missin_value.csv\n",
      "Saved 3401 rows with 100% missing values to: /Users/burdzhuchaglayan/Desktop/data science projects/air-pollution-levels/data/laqn/missing/value_100filtered_missing.csv\n",
      "Saved 3401 rows (siteCode != SpeciesCode) to: /Users/burdzhuchaglayan/Desktop/data science projects/air-pollution-levels/data/laqn/missing/value_100filtered_missing.csv\n",
      "====================================================================================================\n",
      "Filtering complete.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>path</th>\n",
       "      <th>siteCode</th>\n",
       "      <th>SpeciesCode</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>EmptyValuePercentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BL0_CO_2023-04-01_2023-04-30.csv</td>\n",
       "      <td>/Users/burdzhuchaglayan/Desktop/data science p...</td>\n",
       "      <td>BL0</td>\n",
       "      <td>CO</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023_apr</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BT4_SO2_2023-04-01_2023-04-30.csv</td>\n",
       "      <td>/Users/burdzhuchaglayan/Desktop/data science p...</td>\n",
       "      <td>BT4</td>\n",
       "      <td>SO2</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023_apr</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BT5_PM2.5_2023-04-01_2023-04-30.csv</td>\n",
       "      <td>/Users/burdzhuchaglayan/Desktop/data science p...</td>\n",
       "      <td>BT5</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023_apr</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BT6_PM2.5_2023-04-01_2023-04-30.csv</td>\n",
       "      <td>/Users/burdzhuchaglayan/Desktop/data science p...</td>\n",
       "      <td>BT6</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023_apr</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BT6_SO2_2023-04-01_2023-04-30.csv</td>\n",
       "      <td>/Users/burdzhuchaglayan/Desktop/data science p...</td>\n",
       "      <td>BT6</td>\n",
       "      <td>SO2</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023_apr</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4129</th>\n",
       "      <td>WM0_O3_2025-09-01_2025-09-30.csv</td>\n",
       "      <td>/Users/burdzhuchaglayan/Desktop/data science p...</td>\n",
       "      <td>WM0</td>\n",
       "      <td>O3</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025_sep</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4130</th>\n",
       "      <td>WM0_PM10_2025-09-01_2025-09-30.csv</td>\n",
       "      <td>/Users/burdzhuchaglayan/Desktop/data science p...</td>\n",
       "      <td>WM0</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025_sep</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4131</th>\n",
       "      <td>WM0_PM2.5_2025-09-01_2025-09-30.csv</td>\n",
       "      <td>/Users/burdzhuchaglayan/Desktop/data science p...</td>\n",
       "      <td>WM0</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025_sep</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>WM0_SO2_2025-09-01_2025-09-30.csv</td>\n",
       "      <td>/Users/burdzhuchaglayan/Desktop/data science p...</td>\n",
       "      <td>WM0</td>\n",
       "      <td>SO2</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025_sep</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>WM6_PM10_2025-09-01_2025-09-30.csv</td>\n",
       "      <td>/Users/burdzhuchaglayan/Desktop/data science p...</td>\n",
       "      <td>WM6</td>\n",
       "      <td>PM10</td>\n",
       "      <td>2025</td>\n",
       "      <td>2025_sep</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3401 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 filename  \\\n",
       "0        BL0_CO_2023-04-01_2023-04-30.csv   \n",
       "2       BT4_SO2_2023-04-01_2023-04-30.csv   \n",
       "3     BT5_PM2.5_2023-04-01_2023-04-30.csv   \n",
       "4     BT6_PM2.5_2023-04-01_2023-04-30.csv   \n",
       "5       BT6_SO2_2023-04-01_2023-04-30.csv   \n",
       "...                                   ...   \n",
       "4129     WM0_O3_2025-09-01_2025-09-30.csv   \n",
       "4130   WM0_PM10_2025-09-01_2025-09-30.csv   \n",
       "4131  WM0_PM2.5_2025-09-01_2025-09-30.csv   \n",
       "4132    WM0_SO2_2025-09-01_2025-09-30.csv   \n",
       "4133   WM6_PM10_2025-09-01_2025-09-30.csv   \n",
       "\n",
       "                                                   path siteCode SpeciesCode  \\\n",
       "0     /Users/burdzhuchaglayan/Desktop/data science p...      BL0          CO   \n",
       "2     /Users/burdzhuchaglayan/Desktop/data science p...      BT4         SO2   \n",
       "3     /Users/burdzhuchaglayan/Desktop/data science p...      BT5       PM2.5   \n",
       "4     /Users/burdzhuchaglayan/Desktop/data science p...      BT6       PM2.5   \n",
       "5     /Users/burdzhuchaglayan/Desktop/data science p...      BT6         SO2   \n",
       "...                                                 ...      ...         ...   \n",
       "4129  /Users/burdzhuchaglayan/Desktop/data science p...      WM0          O3   \n",
       "4130  /Users/burdzhuchaglayan/Desktop/data science p...      WM0        PM10   \n",
       "4131  /Users/burdzhuchaglayan/Desktop/data science p...      WM0       PM2.5   \n",
       "4132  /Users/burdzhuchaglayan/Desktop/data science p...      WM0         SO2   \n",
       "4133  /Users/burdzhuchaglayan/Desktop/data science p...      WM6        PM10   \n",
       "\n",
       "      year     month  EmptyValuePercentage  \n",
       "0     2023  2023_apr                 100.0  \n",
       "2     2023  2023_apr                 100.0  \n",
       "3     2023  2023_apr                 100.0  \n",
       "4     2023  2023_apr                 100.0  \n",
       "5     2023  2023_apr                 100.0  \n",
       "...    ...       ...                   ...  \n",
       "4129  2025  2025_sep                 100.0  \n",
       "4130  2025  2025_sep                 100.0  \n",
       "4131  2025  2025_sep                 100.0  \n",
       "4132  2025  2025_sep                 100.0  \n",
       "4133  2025  2025_sep                 100.0  \n",
       "\n",
       "[3401 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "filter_missing_pollutants()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6bf485",
   "metadata": {},
   "source": [
    "### 2) Function for identifying site-species combinations not monitored throughout the year\n",
    "\n",
    "- This function analyses the value_100filtered_missing.csv file to find site-species pairs that have 100% missing values for every month in a year.\n",
    "- If a station has no valid values for a given species across all months (2023: 12 months, 2024: 12 months, 2025: 11 months), it is considered as not monitoring that species.\n",
    "- The function groups and pivots the data to summarise which site-species pairs are consistently missing, providing a clear list of non-active monitoring combinations.\n",
    "- The output includes summary statistics and a filtered table of site-species pairs that are not monitored, which can be used for further reporting or to update active site/species metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7acb10ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_month_number(month_str):\n",
    "    # expects format 2025_jul returns 7 for 'jul\n",
    "    month_map = {'jan':1, 'feb':2, 'mar':3, 'apr':4, 'may':5, 'jun':6,\n",
    "                 'jul':7, 'aug':8, 'sep':9, 'oct':10, 'nov':11, 'dec':12}\n",
    "    m = re.match(r\"\\d{4}_(\\w{3})\", str(month_str).lower())\n",
    "    if m:\n",
    "        return month_map.get(m.group(1), None)\n",
    "    return None\n",
    "\n",
    "def analyse_affected_sites(output_filtered_value_file, output_notActive_site_species):\n",
    "    \"\"\"\n",
    "    Scan for site-species combinations with 100% missing values for all months in a year.\n",
    "    Prints summary and returns the grouped DataFrame.\n",
    "    \"\"\"\n",
    "    # Load the CSV\n",
    "    df = pd.read_csv(output_filtered_value_file, encoding='utf-8')\n",
    "    print(\"CSV structure (columns):\", df.columns.tolist())\n",
    "    print(\"First 5 rows:\\n\", df.head())\n",
    "\n",
    "    # Extract month number from 'month' column\n",
    "    df['month_number'] = df['month'].apply(extract_month_number)\n",
    "\n",
    "    # Remove rows where month conversion failed\n",
    "    df = df[df['month_number'].notna()].copy()\n",
    "\n",
    "    # Count files per site, species, year, and month\n",
    "    df['count'] = 1\n",
    "    summary = df.groupby(['siteCode', 'SpeciesCode', 'year', 'month']).size().reset_index(name='count')\n",
    "    print(\"\\nGrouped summary (site, species, year, month):\")\n",
    "    print(summary.head())\n",
    "\n",
    "    # Pivot for wide view: months per year\n",
    "    pivot = summary.pivot_table(index=['siteCode', 'SpeciesCode', 'year'], values='count', aggfunc='sum', fill_value=0)\n",
    "    print(\"\\nPivot table (site, species, year):\")\n",
    "    print(pivot.head())\n",
    "\n",
    "    # Pivot to see years as columns (site/species as index)\n",
    "    summary_year = df.groupby(['siteCode', 'SpeciesCode', 'year'])['count'].sum().reset_index()\n",
    "    pivot_year = summary_year.pivot_table(index=['siteCode', 'SpeciesCode'], columns='year', values='count', fill_value=0)\n",
    "    print(\"\\nPivot table (site/species x year):\")\n",
    "    print(pivot_year.head())\n",
    "\n",
    "    # Ensure columns are strings for year\n",
    "    pivot_year.columns = pivot_year.columns.astype(str)\n",
    "    required_years = ['2023', '2024', '2025']\n",
    "    pivot_year = pivot_year[[col for col in required_years if col in pivot_year.columns]]\n",
    "\n",
    "    # Filter for exact month counts: 2023 (12), 2024 (12), 2025 (11)\n",
    "    filtered = pivot_year[\n",
    "        (pivot_year.get('2023', 0) == 12) &\n",
    "        (pivot_year.get('2024', 0) == 12) &\n",
    "        (pivot_year.get('2025', 0) == 11)\n",
    "    ]\n",
    "    print(\"\\nFiltered site/species with all months missing (2023:12, 2024:12, 2025:11):\")\n",
    "    print(filtered)\n",
    "\n",
    "    # Save the filtered DataFrame to CSV (commented out for now)\n",
    "    filtered.to_csv(output_notActive_site_species, index=True, encoding='utf-8')\n",
    "    print(f\"\\nFiltered site/species combos saved to: {output_notActive_site_species}\")\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "057be847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV structure (columns): ['filename', 'path', 'siteCode', 'SpeciesCode', 'year', 'month', 'EmptyValuePercentage']\n",
      "First 5 rows:\n",
      "                               filename  \\\n",
      "0     BL0_CO_2023-04-01_2023-04-30.csv   \n",
      "1     BT4_O3_2023-04-01_2023-04-30.csv   \n",
      "2    BT4_SO2_2023-04-01_2023-04-30.csv   \n",
      "3  BT5_PM2.5_2023-04-01_2023-04-30.csv   \n",
      "4  BT6_PM2.5_2023-04-01_2023-04-30.csv   \n",
      "\n",
      "                                                path siteCode SpeciesCode  \\\n",
      "0  /Users/burdzhuchaglayan/Desktop/data science p...      BL0          CO   \n",
      "1  /Users/burdzhuchaglayan/Desktop/data science p...      BT4          O3   \n",
      "2  /Users/burdzhuchaglayan/Desktop/data science p...      BT4         SO2   \n",
      "3  /Users/burdzhuchaglayan/Desktop/data science p...      BT5       PM2.5   \n",
      "4  /Users/burdzhuchaglayan/Desktop/data science p...      BT6       PM2.5   \n",
      "\n",
      "   year     month  EmptyValuePercentage  \n",
      "0  2023  2023_apr                100.00  \n",
      "1  2023  2023_apr                 52.87  \n",
      "2  2023  2023_apr                100.00  \n",
      "3  2023  2023_apr                100.00  \n",
      "4  2023  2023_apr                100.00  \n",
      "\n",
      "Grouped summary (site, species, year, month):\n",
      "  siteCode SpeciesCode  year     month  count\n",
      "0      BG1         NO2  2023  2023_jun      1\n",
      "1      BG1         NO2  2023  2023_may      1\n",
      "2      BG1         NO2  2024  2024_apr      1\n",
      "3      BG1         NO2  2024  2024_aug      1\n",
      "4      BG1         NO2  2024  2024_feb      1\n",
      "\n",
      "Pivot table (site, species, year):\n",
      "                           count\n",
      "siteCode SpeciesCode year       \n",
      "BG1      NO2         2023      2\n",
      "                     2024      5\n",
      "                     2025      5\n",
      "         SO2         2023      3\n",
      "                     2024      4\n",
      "\n",
      "Pivot table (site/species x year):\n",
      "year                  2023  2024  2025\n",
      "siteCode SpeciesCode                  \n",
      "BG1      NO2           2.0   5.0   5.0\n",
      "         SO2           3.0   4.0   8.0\n",
      "BG2      NO2           1.0   2.0   6.0\n",
      "         PM10          1.0   2.0   6.0\n",
      "BL0      CO           12.0  12.0  11.0\n",
      "\n",
      "Filtered site/species with all months missing (2023:12, 2024:12, 2025:11):\n",
      "year                  2023  2024  2025\n",
      "siteCode SpeciesCode                  \n",
      "BL0      CO           12.0  12.0  11.0\n",
      "BT4      SO2          12.0  12.0  11.0\n",
      "BT6      SO2          12.0  12.0  11.0\n",
      "BX1      CO           12.0  12.0  11.0\n",
      "         PM10         12.0  12.0  11.0\n",
      "BY7      CO           12.0  12.0  11.0\n",
      "CR9      NO2          12.0  12.0  11.0\n",
      "         PM10         12.0  12.0  11.0\n",
      "EN4      PM10         12.0  12.0  11.0\n",
      "         SO2          12.0  12.0  11.0\n",
      "GB0      PM10         12.0  12.0  11.0\n",
      "GR4      SO2          12.0  12.0  11.0\n",
      "GR9      O3           12.0  12.0  11.0\n",
      "HG1      PM10         12.0  12.0  11.0\n",
      "         SO2          12.0  12.0  11.0\n",
      "HI0      CO           12.0  12.0  11.0\n",
      "         SO2          12.0  12.0  11.0\n",
      "HK6      O3           12.0  12.0  11.0\n",
      "HV3      SO2          12.0  12.0  11.0\n",
      "IS2      CO           12.0  12.0  11.0\n",
      "KC1      PM10         12.0  12.0  11.0\n",
      "KF1      PM10         12.0  12.0  11.0\n",
      "         PM2.5        12.0  12.0  11.0\n",
      "LB4      SO2          12.0  12.0  11.0\n",
      "LH0      CO           12.0  12.0  11.0\n",
      "MEB      NO2          12.0  12.0  11.0\n",
      "MR8      NO2          12.0  12.0  11.0\n",
      "         PM10         12.0  12.0  11.0\n",
      "         PM2.5        12.0  12.0  11.0\n",
      "MY1      PM10         12.0  12.0  11.0\n",
      "TH2      CO           12.0  12.0  11.0\n",
      "TH5      O3           12.0  12.0  11.0\n",
      "         SO2          12.0  12.0  11.0\n",
      "WA9      CO           12.0  12.0  11.0\n",
      "WM0      CO           12.0  12.0  11.0\n",
      "         O3           12.0  12.0  11.0\n",
      "         PM10         12.0  12.0  11.0\n",
      "         SO2          12.0  12.0  11.0\n",
      "\n",
      "Filtered site/species combos saved to: /Users/burdzhuchaglayan/Desktop/data science projects/air-pollution-levels/data/laqn/missing/notActive_site_species.csv\n"
     ]
    }
   ],
   "source": [
    "# use the function to analyse affected sites/species\n",
    "filtered = analyse_affected_sites(input_all_missing_file, output_notActive_site_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a8b87e",
   "metadata": {},
   "source": [
    "### 3) Remove non-active site/species pairs from active metadata\n",
    "\n",
    "This function updates the active site/species metadata by removing any pairs that are identified as non-active (i.e., those with 100% missing values for all months in a year).\n",
    "\n",
    "- **Inputs:**\n",
    "  - `actv_sites_species.csv`: The current list of active site/species pairs.\n",
    "  - `notActive_site_species.csv`: The list of site/species pairs with no valid data (100% missing) for all months (2023: 12, 2024: 12, 2025: 11).\n",
    "\n",
    "- **Process:**\n",
    "  - Compares the active list to the non-active list.\n",
    "  - Removes any rows from the active metadata where `(SiteName, SpeciesCode)` matches `(siteCode, SpeciesCode)` in the non-active list.\n",
    "\n",
    "- **Output:**\n",
    "  - Saves the updated active site/species list as `updated_actv_siteSpecies.csv` in the same directory.\n",
    "\n",
    "This ensures that the active metadata only includes site/species pairs that are genuinely monitored, improving the accuracy of subsequent analyses and reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8913c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_species_code(code):\n",
    "    # Treat PM2.5 and PM25 as equivalent, and normalise case/whitespace\n",
    "    code = str(code).strip().upper().replace('.', '')\n",
    "    return code\n",
    "\n",
    "def remove_nonactive_from_active():\n",
    "    \"\"\"\n",
    "    Remove non-active site/species combinations from the active metadata list.\n",
    "    - Reads actv_sites_species.csv (columns: SiteName, SpeciesCode)\n",
    "    - Reads notActive_site_species.csv (columns: siteCode, SpeciesCode)\n",
    "    - Removes any (SiteName, SpeciesCode) in the active list that matches (siteCode, SpeciesCode) in the non-active list.\n",
    "    - Saves the updated list as updated_actv_siteSpecies.csv.\n",
    "    - Prints a summary of removals for reporting and reproducibility.\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    df_active = pd.read_csv(actv_sites_species_path, encoding='utf-8')\n",
    "    df_nonactive = pd.read_csv(output_notActive_site_species, encoding='utf-8')\n",
    "\n",
    "\n",
    "    # Normalise species codes in both dataframes\n",
    "    df_active['SpeciesCode_norm'] = df_active['SpeciesCode'].apply(normalise_species_code)\n",
    "    df_nonactive['SpeciesCode_norm'] = df_nonactive['SpeciesCode'].apply(normalise_species_code)\n",
    "\n",
    "    # Create set of non-active pairs (normalised)\n",
    "    nonactive_set = set(zip(df_nonactive['siteCode'], df_nonactive['SpeciesCode_norm']))\n",
    "    active_set = set(zip(df_active['SiteCode'], df_active['SpeciesCode_norm']))\n",
    "\n",
    "    # Filter active DataFrame (normalised)\n",
    "    filtered_active = df_active[\n",
    "        ~df_active.apply(lambda row: (row['SiteCode'], row['SpeciesCode_norm']) in nonactive_set, axis=1)\n",
    "    ].copy()\n",
    "\n",
    "    # Calculate and print what was removed\n",
    "    removed_count = len(df_active) - len(filtered_active)\n",
    "    print(\"=\"*60)\n",
    "    if removed_count > 0:\n",
    "        print(f\"{removed_count} non-active site/species pairs were removed from the active list.\")\n",
    "    else:\n",
    "        print(\"No matching non-active site/species pairs found in the active list. No rows were removed.\")\n",
    "    print(f\"Original rows: {len(df_active)}, Rows after removal: {len(filtered_active)}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Save the filtered DataFrame\n",
    "    filtered_active.drop(columns=['SpeciesCode_norm'], inplace=True)\n",
    "    filtered_active.to_csv(updated_actv_site_species_path, index=False, encoding='utf-8')\n",
    "    print(f\"Filtered active data saved to: {updated_actv_site_species_path}\")\n",
    "\n",
    "    # Show what was removed\n",
    "    removed_combinations = df_active[\n",
    "        ~df_active.apply(lambda row: (row['SiteCode'], row['SpeciesCode_norm']) in set(\n",
    "            zip(filtered_active['SiteCode'], filtered_active['SpeciesCode_norm'])\n",
    "        ), axis=1)\n",
    "    ][['SiteCode', 'SpeciesCode']].drop_duplicates()\n",
    "    if not removed_combinations.empty:\n",
    "        print(\"\\nRemoved site/species combinations:\")\n",
    "        print(removed_combinations.to_string(index=False))\n",
    "\n",
    "    # Report non-active pairs not present in the active list\n",
    "    not_in_active = nonactive_set - active_set\n",
    "    if not_in_active:\n",
    "        print(f\"\\n{len(not_in_active)} site/species pairs in notActive_site_species.csv are not present in actv_sites_species.csv:\")\n",
    "        for site, species in sorted(not_in_active):\n",
    "            print(f\"  SiteCode: {site}, SpeciesCode: {species}\")\n",
    "    else:\n",
    "        print(\"\\nAll site/species pairs in notActive_site_species.csv are present in actv_sites_species.csv.\")\n",
    "\n",
    "    return filtered_active\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a693fccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "38 non-active site/species pairs were removed from the active list.\n",
      "Original rows: 252, Rows after removal: 214\n",
      "============================================================\n",
      "Filtered active data saved to: /Users/burdzhuchaglayan/Desktop/data science projects/air-pollution-levels/data/laqn/updated_actv_siteSpecies.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'SpeciesCode_norm'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/data science projects/air-pollution-levels/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'SpeciesCode_norm'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# run the code\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m cleaned_df = \u001b[43mremove_nonactive_from_active\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mremove_nonactive_from_active\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFiltered active data saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mupdated_actv_site_species_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Show what was removed\u001b[39;00m\n\u001b[32m     49\u001b[39m removed_combinations = df_active[\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     ~\u001b[43mdf_active\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSiteCode\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSpeciesCode_norm\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfiltered_active\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSiteCode\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiltered_active\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSpeciesCode_norm\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m ][[\u001b[33m'\u001b[39m\u001b[33mSiteCode\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mSpeciesCode\u001b[39m\u001b[33m'\u001b[39m]].drop_duplicates()\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m removed_combinations.empty:\n\u001b[32m     55\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mRemoved site/species combinations:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/data science projects/air-pollution-levels/.venv/lib/python3.11/site-packages/pandas/core/frame.py:10401\u001b[39m, in \u001b[36mDataFrame.apply\u001b[39m\u001b[34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m  10387\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[32m  10389\u001b[39m op = frame_apply(\n\u001b[32m  10390\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  10391\u001b[39m     func=func,\n\u001b[32m   (...)\u001b[39m\u001b[32m  10399\u001b[39m     kwargs=kwargs,\n\u001b[32m  10400\u001b[39m )\n\u001b[32m> \u001b[39m\u001b[32m10401\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/data science projects/air-pollution-levels/.venv/lib/python3.11/site-packages/pandas/core/apply.py:916\u001b[39m, in \u001b[36mFrameApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_raw(engine=\u001b[38;5;28mself\u001b[39m.engine, engine_kwargs=\u001b[38;5;28mself\u001b[39m.engine_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/data science projects/air-pollution-levels/.venv/lib/python3.11/site-packages/pandas/core/apply.py:1063\u001b[39m, in \u001b[36mFrameApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m         results, res_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m         results, res_index = \u001b[38;5;28mself\u001b[39m.apply_series_numba()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/data science projects/air-pollution-levels/.venv/lib/python3.11/site-packages/pandas/core/apply.py:1081\u001b[39m, in \u001b[36mFrameApply.apply_series_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mmode.chained_assignment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1079\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[32m   1080\u001b[39m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m         results[i] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[32m   1083\u001b[39m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[32m   1084\u001b[39m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[32m   1085\u001b[39m             results[i] = results[i].copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mremove_nonactive_from_active.<locals>.<lambda>\u001b[39m\u001b[34m(row)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFiltered active data saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mupdated_actv_site_species_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Show what was removed\u001b[39;00m\n\u001b[32m     49\u001b[39m removed_combinations = df_active[\n\u001b[32m     50\u001b[39m     ~df_active.apply(\u001b[38;5;28;01mlambda\u001b[39;00m row: (row[\u001b[33m'\u001b[39m\u001b[33mSiteCode\u001b[39m\u001b[33m'\u001b[39m], row[\u001b[33m'\u001b[39m\u001b[33mSpeciesCode_norm\u001b[39m\u001b[33m'\u001b[39m]) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m         \u001b[38;5;28mzip\u001b[39m(filtered_active[\u001b[33m'\u001b[39m\u001b[33mSiteCode\u001b[39m\u001b[33m'\u001b[39m], \u001b[43mfiltered_active\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSpeciesCode_norm\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m     52\u001b[39m     ), axis=\u001b[32m1\u001b[39m)\n\u001b[32m     53\u001b[39m ][[\u001b[33m'\u001b[39m\u001b[33mSiteCode\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mSpeciesCode\u001b[39m\u001b[33m'\u001b[39m]].drop_duplicates()\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m removed_combinations.empty:\n\u001b[32m     55\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mRemoved site/species combinations:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/data science projects/air-pollution-levels/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/data science projects/air-pollution-levels/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'SpeciesCode_norm'"
     ]
    }
   ],
   "source": [
    "# run the code\n",
    "cleaned_df = remove_nonactive_from_active()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6191adb5",
   "metadata": {},
   "source": [
    " output of the code:\n",
    "\n",
    "        ============================================================\n",
    "        36 non-active site/species pairs were removed from the active list.\n",
    "        Original rows: 252, Rows after removal: 216\n",
    "        ============================================================\n",
    "\n",
    "        Removed site/species combinations:\n",
    "        SiteCode SpeciesCode\n",
    "            BG1         NO2\n",
    "            BG1         SO2\n",
    "            BG2         NO2\n",
    "            BG2        PM10\n",
    "            BX2         NO2\n",
    "            BX2        PM10\n",
    "            BX2        PM25\n",
    "            BQ7         NO2\n",
    "            BQ7          O3\n",
    "            BQ7        PM10\n",
    "            BQ7        PM25\n",
    "            BX1          CO\n",
    "            BX1         NO2\n",
    "            BX1          O3\n",
    "            BX1        PM10\n",
    "            BX1         SO2\n",
    "            BQ9        PM10\n",
    "            BQ9        PM25\n",
    "            BT8         NO2\n",
    "            BT8        PM10\n",
    "            BT8        PM25\n",
    "            BT4         NO2\n",
    "            BT4          O3\n",
    "            BT4        PM10\n",
    "            BT4        PM25\n",
    "            BT4         SO2\n",
    "            BT6         NO2\n",
    "            BT6        PM10\n",
    "            BT6        PM25\n",
    "            BT6         SO2\n",
    "            BT5         NO2\n",
    "            BT5        PM10\n",
    "            BT5        PM25\n",
    "            BY7          CO\n",
    "            BY7         NO2\n",
    "            BY7        PM10\n",
    "            BY7        PM25\n",
    "            BL0          CO\n",
    "            BL0         NO2\n",
    "            BL0          O3\n",
    "            BL0        PM10\n",
    "            BL0        PM25\n",
    "            BL0         SO2\n",
    "            CD1         NO2\n",
    "            CD1        PM10\n",
    "            CD1        PM25\n",
    "            CR5         NO2\n",
    "            CR8        PM25\n",
    "            CR9         NO2\n",
    "            CR9        PM10\n",
    "            CR7         NO2\n",
    "            EA6         NO2\n",
    "            EA6        PM10\n",
    "            EA8         NO2\n",
    "            EA8        PM10\n",
    "            EI8        PM10\n",
    "            EI1         NO2\n",
    "            EI1        PM10\n",
    "            EN5         NO2\n",
    "            EN5        PM10\n",
    "            EN5        PM25\n",
    "            EN1         NO2\n",
    "            EN4         NO2\n",
    "            EN4        PM10\n",
    "            EN4         SO2\n",
    "            EN7         NO2\n",
    "            GN0         NO2\n",
    "            GN0        PM10\n",
    "            GN0        PM25\n",
    "            GR7         NO2\n",
    "            GR7        PM10\n",
    "            GR4         NO2\n",
    "            GR4          O3\n",
    "            GR4        PM10\n",
    "            GR4        PM25\n",
    "            GR4         SO2\n",
    "            GB6         NO2\n",
    "            GB6          O3\n",
    "            GB6        PM10\n",
    "            GB0        PM10\n",
    "            GB0        PM25\n",
    "            GN4         NO2\n",
    "            GN4        PM10\n",
    "            GN6         NO2\n",
    "            GN6        PM10\n",
    "            GN6        PM25\n",
    "            GN3         NO2\n",
    "            GN3          O3\n",
    "            GN3        PM10\n",
    "            GN3        PM25\n",
    "            GN5         NO2\n",
    "            GN5        PM10\n",
    "            TL4         NO2\n",
    "            GR9         NO2\n",
    "            GR9          O3\n",
    "            GR9        PM10\n",
    "            GR9        PM25\n",
    "            GR8         NO2\n",
    "            GR8        PM10\n",
    "            GR8        PM25\n",
    "            HK6         NO2\n",
    "            HK6          O3\n",
    "            HK6        PM10\n",
    "            HK6        PM25\n",
    "            HG4         NO2\n",
    "            HG4          O3\n",
    "            HG1         NO2\n",
    "            HG1        PM10\n",
    "            HG1        PM25\n",
    "            HG1         SO2\n",
    "            HV1         NO2\n",
    "            HV1        PM10\n",
    "            HV1        PM25\n",
    "            HV3         NO2\n",
    "            HV3        PM10\n",
    "            HV3         SO2\n",
    "            LH0          CO\n",
    "            LH0         NO2\n",
    "            LH0          O3\n",
    "            LH0        PM10\n",
    "            LH0        PM25\n",
    "            HI0          CO\n",
    "            HI0         NO2\n",
    "            HI0          O3\n",
    "            HI0        PM10\n",
    "            HI0         SO2\n",
    "            IS6         NO2\n",
    "            IS6        PM10\n",
    "            IS6        PM25\n",
    "            IS2          CO\n",
    "            IS2         NO2\n",
    "            IS2        PM10\n",
    "            IS2        PM25\n",
    "            KC1          CO\n",
    "            KC1         NO2\n",
    "            KC1          O3\n",
    "            KC1        PM10\n",
    "            KC1        PM25\n",
    "            KC1         SO2\n",
    "            KF1        PM10\n",
    "            KF1        PM25\n",
    "            GT1         NO2\n",
    "            GT1        PM10\n",
    "            GT1        PM25\n",
    "            LB5         NO2\n",
    "            LB5        PM10\n",
    "            LB5         SO2\n",
    "            LB4         NO2\n",
    "            LB4        PM10\n",
    "            LB4        PM25\n",
    "            LB4         SO2\n",
    "            LB6         NO2\n",
    "            LB6        PM10\n",
    "            WAC         NO2\n",
    "            WAC        PM10\n",
    "            WAC        PM25\n",
    "            HP1         NO2\n",
    "            HP1          O3\n",
    "            HP1        PM10\n",
    "            HP1        PM25\n",
    "            TD5        PM10\n",
    "            TD5        PM25\n",
    "            MR8         NO2\n",
    "            MR8        PM10\n",
    "            MR8        PM25\n",
    "            ME2         NO2\n",
    "            ME2        PM10\n",
    "            ME2        PM25\n",
    "            MEA         NO2\n",
    "            MEA        PM25\n",
    "            ME9         NO2\n",
    "            MEB         NO2\n",
    "            MEB        PM10\n",
    "            MEB        PM25\n",
    "            TL6         NO2\n",
    "            TL6        PM25\n",
    "            TL5         NO2\n",
    "            CE3         NO2\n",
    "            CE3        PM10\n",
    "            CE3        PM25\n",
    "            RI2         NO2\n",
    "            RI2          O3\n",
    "            RI2        PM10\n",
    "            RI2        PM25\n",
    "            RI1         NO2\n",
    "            RI1        PM10\n",
    "            RHI         NO2\n",
    "            RHI        PM10\n",
    "            RHI        PM25\n",
    "            SK5         NO2\n",
    "            SK5        PM10\n",
    "            TH4         NO2\n",
    "            TH4          O3\n",
    "            TH4        PM10\n",
    "            TH4        PM25\n",
    "            CW3         NO2\n",
    "            CW3        PM10\n",
    "            CW3        PM25\n",
    "            TH7         NO2\n",
    "            TH7        PM25\n",
    "            TH2          CO\n",
    "            TH2         NO2\n",
    "            TH2        PM25\n",
    "            TH6         NO2\n",
    "            TH6          O3\n",
    "            TH6        PM10\n",
    "            TH5         NO2\n",
    "            TH5          O3\n",
    "            TH5        PM10\n",
    "            TH5        PM25\n",
    "            TH5         SO2\n",
    "            WAA         NO2\n",
    "            WAA        PM10\n",
    "            WAA        PM25\n",
    "            WA9          CO\n",
    "            WA9         NO2\n",
    "            WA9        PM10\n",
    "            WA9        PM25\n",
    "            WA7         NO2\n",
    "            WA7        PM10\n",
    "            WA7        PM25\n",
    "            WAB         NO2\n",
    "            WAB        PM10\n",
    "            WAB        PM25\n",
    "            CE2         NO2\n",
    "            CE2          O3\n",
    "            CE2        PM10\n",
    "            CE2        PM25\n",
    "            WM5         NO2\n",
    "            WM5        PM25\n",
    "            WMD         NO2\n",
    "            WMD        PM25\n",
    "            WM0          CO\n",
    "            WM0         NO2\n",
    "            WM0          O3\n",
    "            WM0        PM10\n",
    "            WM0        PM25\n",
    "            WM0         SO2\n",
    "            MY1          CO\n",
    "            MY1         NO2\n",
    "            MY1          O3\n",
    "            MY1        PM10\n",
    "            MY1         SO2\n",
    "            WM6         NO2\n",
    "            WM6        PM10\n",
    "            WM6        PM25\n",
    "            WME         NO2\n",
    "            WME          O3\n",
    "            WME        PM25\n",
    "\n",
    "        2 site/species pairs in notActive_site_species.csv are not present in actv_sites_species.csv:\n",
    "        SiteCode: KF1, SpeciesCode: PM2.5\n",
    "        SiteCode: MR8, SpeciesCode: PM2.5\n",
    "\n",
    "    - Normalised species codes (e.g., PM2.5/PM25) for accurate matching. after that KF1 and MR8 PM2.5 also removed, from actv_site_species.csv."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
