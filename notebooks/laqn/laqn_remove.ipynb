{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c5dab22",
   "metadata": {},
   "source": [
    "# Cleaning LAQN Datasets\n",
    "I will be removing the files has %100 missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de71d062",
   "metadata": {},
   "source": [
    "import and path statements below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e451156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "\n",
    "# paths beloww\n",
    "base_dir = Path(\"/Users/burdzhuchaglayan/Desktop/data science projects/air-pollution-levels\")\n",
    "nonActive_path = base_dir / \"data\" / \"laqn\" / \"missing\" / \"nonActive_siteSpecies.csv\"\n",
    "optimased_dir = base_dir / \"data\" / \"laqn\" / \"optimased\"\n",
    "processed_dir = base_dir / \"data\" / \"laqn\" / \"processed\"\n",
    "month_dirs = sorted([d for d in optimased_dir.iterdir() if d.is_dir()])\n",
    "\n",
    "# Change output directory to data/laqn/missing\n",
    "output_dir = base_dir / \"data\" / \"laqn\" / \"missing\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# function for value higher than 80%\n",
    "input_file = base_dir / \"data\" / \"laqn\" / \"missing\" / \"rm_100percnt_missingValues_log.csv\"\n",
    "output_file = base_dir / \"data\" / \"laqn\" / \"missing\" / \"logs_emptyValue_higher80.csv\"\n",
    "\n",
    "# affected sites/species analysis function\n",
    "nonactive_sites_input = base_dir / \"data\" / \"laqn\" / \"missing\" / \"affected_sites_species_counts.csv\"\n",
    "\n",
    "# function to remove non-active sites/species from active metadata csv file I used in get_laqn fetching script\n",
    "active_path = base_dir / \"data\" / \"laqn\" / \"actv_sites_species.csv\"\n",
    "nonactive_path = base_dir / \"data\" / \"laqn\" / \"missing\" / \"nonActive_siteSpecies.csv\"\n",
    "output_path = base_dir / \"data\" / \"laqn\" / \"updated_actv_siteSpecies.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc34a874",
   "metadata": {},
   "source": [
    "### 1. Funtion for removes 100 percent missed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "311c97fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_nonActiveSiteSpecies():\n",
    "    \"\"\"\n",
    "    Remove CSV files in optimased/ that have 100% missing values,\n",
    "    as listed in logs_missin_value.csv.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read log file\n",
    "    df = pd.read_csv(nonActive_path, encoding='utf-8')\n",
    "    print(f\"Loaded {len(df)} rows from {nonActive_path}\")\n",
    "\n",
    "    # Remove files\n",
    "    removed = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        site = str(row['siteCode'])\n",
    "        species = str(row['SpeciesCode'])\n",
    "        # search for files matching site/species in all month folders\n",
    "        for month_dir in optimased_dir.iterdir():\n",
    "            if month_dir.is_dir():\n",
    "                pattern = f\"{site}_{species}_*.csv\"\n",
    "                for file in month_dir.glob(pattern):\n",
    "                    if file.exists():\n",
    "                        os.remove(file)\n",
    "                        print(f\"Removed: {file}\")\n",
    "                        removed += 1\n",
    "    print(f\"Total files removed: {removed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16643af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 38 rows from /Users/burdzhuchaglayan/Desktop/data science projects/air-pollution-levels/data/laqn/missing/nonActive_siteSpecies.csv\n",
      "Total files removed: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "rm_nonActiveSiteSpecies()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62380ec7",
   "metadata": {},
   "source": [
    "### 3) Document missing data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1170ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     siteCode SpeciesCode  year     month  count\n",
      "0         BG1         NO2  2023  2023_jun      1\n",
      "1         BG1         NO2  2023  2023_may      1\n",
      "2         BG1         NO2  2024  2024_apr      1\n",
      "3         BG1         NO2  2024  2024_aug      1\n",
      "4         BG1         NO2  2024  2024_feb      1\n",
      "...       ...         ...   ...       ...    ...\n",
      "4131      WME       PM2.5  2025  2025_jul      1\n",
      "4132      WME       PM2.5  2025  2025_jun      1\n",
      "4133      WME       PM2.5  2025  2025_mar      1\n",
      "4134      WME       PM2.5  2025  2025_may      1\n",
      "4135      WME       PM2.5  2025  2025_sep      1\n",
      "\n",
      "[4136 rows x 5 columns]\n",
      "month\n",
      "2024_aug    138\n",
      "2025_mar    135\n",
      "2024_may    133\n",
      "2023_dec    131\n",
      "2023_oct    131\n",
      "2024_sep    129\n",
      "2024_jul    128\n",
      "2023_aug    127\n",
      "2024_jan    127\n",
      "2023_sep    126\n",
      "2023_nov    125\n",
      "2024_oct    124\n",
      "2025_jan    124\n",
      "2024_feb    123\n",
      "2024_jun    123\n",
      "2024_mar    123\n",
      "2024_nov    123\n",
      "2024_apr    123\n",
      "2023_may    122\n",
      "2024_dec    121\n",
      "2023_mar    121\n",
      "2025_feb    120\n",
      "2023_jan    118\n",
      "2023_jul    117\n",
      "2023_jun    113\n",
      "2023_apr    112\n",
      "2025_jul    109\n",
      "2023_feb    106\n",
      "2025_apr    105\n",
      "2025_sep    103\n",
      "2025_jun    100\n",
      "2025_aug     99\n",
      "2025_may     96\n",
      "2025_nov     92\n",
      "2025_oct     89\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_log = pd.read_csv(nonActive_path, encoding ='utf-8')\n",
    "\n",
    "# Check which sites/species were most affected\n",
    "grouped = missing_log.groupby(['siteCode', 'SpeciesCode', 'year', 'month']).size().reset_index(name='count')\n",
    "print(grouped)\n",
    "\n",
    "# Save to CSV\n",
    "grouped.to_csv(nonActive_path.parent /\"affected_sites_species_counts.csv\", index=False)\n",
    "\n",
    "\n",
    "# Check temporal distribution\n",
    "missing_log['month'] = missing_log['path'].str.extract(r'(\\d{4}_\\w{3})')\n",
    "print(missing_log['month'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6bf485",
   "metadata": {},
   "source": [
    "### 4) Function for whihc site-species are not monitored through to affecte_sites_species_counts.csv. \n",
    " - If the station don't have value for all round year for that specie that's mean that that station not monitoring that species.\n",
    " - the funtion will returns tuples coveres monitored sitesm summary stats.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7acb10ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_month_number(month_str):\n",
    "    # expects format '2025_jul', returns 7 for 'jul'\n",
    "    month_map = {'jan':1, 'feb':2, 'mar':3, 'apr':4, 'may':5, 'jun':6,\n",
    "                 'jul':7, 'aug':8, 'sep':9, 'oct':10, 'nov':11, 'dec':12}\n",
    "    m = re.match(r\"\\d{4}_(\\w{3})\", str(month_str).lower())\n",
    "    if m:\n",
    "        return month_map.get(m.group(1), None)\n",
    "    return None\n",
    "\n",
    "def analyze_affected_sites( input_csv_path: Path, output_directory: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Simple scan of affected sites across 2023-2025 (2025 up to Nov).\n",
    "    Args:\n",
    "        non-active_sites: Path to affected_sites_species_counts.csv\n",
    "        output_dir: Where to save output\n",
    "    Returns:\n",
    "        Filtered DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the CSV\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "\n",
    "    # Extract month number\n",
    "    df['month_number'] = df['month'].apply(extract_month_number)\n",
    "\n",
    "    # Remove rows where month conversion failed (just in case)\n",
    "    df = df[df['month_number'].notna()].copy()\n",
    "    \n",
    "    # Filter: 2023 (all months), 2024 (all months), 2025 (Jan-Nov only)\n",
    "    filtered = df[\n",
    "        (df['year'] == 2023) |\n",
    "        (df['year'] == 2024) |\n",
    "        ((df['year'] == 2025) & (df['month_number'] <= 11))\n",
    "    ].copy()\n",
    "    \n",
    "    # Create output directory\n",
    "    output_directory.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save filtered result\n",
    "    output_file_path = output_directory / \"non_active_sites_species.csv\"\n",
    "    filtered.to_csv(output_file_path, index=False)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"=\"*60)\n",
    "    print(\"affected sites/species analysis (2023-2025)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nTotal rows: {len(filtered)}\")\n",
    "    print(f\"Unique sites: {filtered['siteCode'].nunique()}\")\n",
    "    print(f\"Unique species: {filtered['SpeciesCode'].nunique()}\")\n",
    "    print(f\"Total missing files: {filtered['count'].sum()}\")\n",
    "    \n",
    "    print(f\"\\nBreakdown by year:\")\n",
    "    print(filtered.groupby('year')['count'].sum())\n",
    "    \n",
    "    print(f\"\\nTop 10 affected site-species:\")\n",
    "    top10 = filtered.groupby(['siteCode', 'SpeciesCode'])['count'].sum().sort_values(ascending=False).head(10)\n",
    "    print(top10)\n",
    "    \n",
    "    print(f\"\\n Saved to: {output_file_path}\")\n",
    "    \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a8b87e",
   "metadata": {},
   "source": [
    "### 5) function to remove non-active site/species from active metadata csv file.\n",
    "- what does function:\n",
    "    - removes rows from actv_sites_species.csv where (SiteName, SpeciesCode) matches any (siteCode, SpeciesCode) in nonActive_siteSpecies.csv\n",
    "    - result is saved as updated_actv_siteSpecies.csv in the same directory\n",
    "\n",
    "- paths:\n",
    "    - actv_sites_species.csv: base_dir / data / laqn / actv_sites_species.csv\n",
    "    - nonActive_siteSpecies.csv: base_dir / data / laqn / missing / nonActive_siteSpecies.csv\n",
    "    - updated_actv_siteSpecies.csv: base_dir / data / laqn / updated_actv_siteSpecies.csv\n",
    "\n",
    "- new csv file save as:updated_actv_siteSpecies.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be7a3717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "affected sites/species analysis (2023-2025)\n",
      "============================================================\n",
      "\n",
      "Total rows: 4136\n",
      "Unique sites: 81\n",
      "Unique species: 6\n",
      "Total missing files: 4136\n",
      "\n",
      "Breakdown by year:\n",
      "year\n",
      "2023    1449\n",
      "2024    1515\n",
      "2025    1172\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 10 affected site-species:\n",
      "siteCode  SpeciesCode\n",
      "HK6       O3             35\n",
      "HV3       SO2            35\n",
      "EN4       PM10           35\n",
      "BX1       PM10           35\n",
      "LB4       SO2            35\n",
      "KF1       PM2.5          35\n",
      "          PM10           35\n",
      "KC1       PM10           35\n",
      "BY7       CO             35\n",
      "IS2       CO             35\n",
      "Name: count, dtype: int64\n",
      "\n",
      " Saved to: /Users/burdzhuchaglayan/Desktop/data science projects/air-pollution-levels/data/laqn/missing/non_active_sites_species.csv\n",
      "\n",
      "============================================================\n",
      "First 10 row of filtered data:\n",
      "============================================================\n",
      "  siteCode SpeciesCode  year     month  count  month_number\n",
      "0      BG1         NO2  2023  2023_jun      1             6\n",
      "1      BG1         NO2  2023  2023_may      1             5\n",
      "2      BG1         NO2  2024  2024_apr      1             4\n",
      "3      BG1         NO2  2024  2024_aug      1             8\n",
      "4      BG1         NO2  2024  2024_feb      1             2\n",
      "5      BG1         NO2  2024  2024_mar      1             3\n",
      "6      BG1         NO2  2024  2024_sep      1             9\n",
      "7      BG1         NO2  2025  2025_aug      1             8\n",
      "8      BG1         NO2  2025  2025_jun      1             6\n",
      "9      BG1         NO2  2025  2025_nov      1            11\n"
     ]
    }
   ],
   "source": [
    "result_df = analyze_affected_sites(\n",
    "    input_csv_path=nonactive_sites_input,\n",
    "    output_directory=output_dir\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"First 10 row of filtered data:\")\n",
    "print(\"=\"*60)\n",
    "print(result_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c7b8062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year                  2023  2024  2025\n",
      "siteCode SpeciesCode                  \n",
      "BG1      NO2           2.0   5.0   5.0\n",
      "         SO2           3.0   4.0   8.0\n",
      "BG2      NO2           1.0   2.0   6.0\n",
      "         PM10          1.0   2.0   6.0\n",
      "BL0      CO           12.0  12.0  11.0\n",
      "...                    ...   ...   ...\n",
      "WM6      PM10          0.0  11.0  11.0\n",
      "         PM2.5        12.0   1.0   0.0\n",
      "WME      NO2          12.0  12.0   9.0\n",
      "         O3           12.0  12.0   7.0\n",
      "         PM2.5        12.0  12.0   8.0\n",
      "\n",
      "[233 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/burdzhuchaglayan/Desktop/data science projects/air-pollution-levels/data/laqn/missing/non_active_sites_species.csv\")\n",
    "\n",
    "# Group by siteCode, SpeciesCode, and year, then sum counts\n",
    "summary = df.groupby(['siteCode', 'SpeciesCode', 'year'])['count'].sum().reset_index()\n",
    "\n",
    "# Pivot to see years as columns (optional, for a wide view)\n",
    "pivot = summary.pivot_table(index=['siteCode', 'SpeciesCode'], columns='year', values='count', fill_value=0)\n",
    "pivot.to_csv(\"/Users/burdzhuchaglayan/Desktop/data science projects/air-pollution-levels/data/laqn/missing/nonActive_siteSpecies.csv\")\n",
    "\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96dc4266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered site/species combos saved. Shape: (38, 3)\n"
     ]
    }
   ],
   "source": [
    "pivot = pd.read_csv(\n",
    "    \"/Users/burdzhuchaglayan/Desktop/data science projects/air-pollution-levels/data/laqn/missing/nonActive_siteSpecies.csv\",\n",
    "    index_col=[0, 1]\n",
    ")\n",
    "\n",
    "# Ensure columns are integers (years)\n",
    "pivot.columns = pivot.columns.astype(str)\n",
    "required_years = ['2023', '2024', '2025']\n",
    "\n",
    "# Only keep rows where all required years are present\n",
    "pivot = pivot[[col for col in required_years if col in pivot.columns]]\n",
    "\n",
    "# Filter for exact month counts: 2023 (12), 2024 (12), 2025 (11)\n",
    "filtered = pivot[\n",
    "    (pivot['2023'] == 12) &\n",
    "    (pivot['2024'] == 12) &\n",
    "    (pivot['2025'] == 11)\n",
    "]\n",
    "\n",
    "# Save the filtered DataFrame back to CSV\n",
    "filtered.to_csv(\n",
    "    \"/Users/burdzhuchaglayan/Desktop/data science projects/air-pollution-levels/data/laqn/missing/nonActive_siteSpecies.csv\"\n",
    ")\n",
    "\n",
    "print(f\"Filtered site/species combos saved. Shape: {filtered.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
