{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f197f750",
   "metadata": {},
   "source": [
    "# CNN model training\n",
    "\n",
    "## LAQN air quality prediction\n",
    "\n",
    "## what this notebook does?\n",
    "\n",
    "this notebook trains a convolutional neural network (CNN) to predict nitrogen dioxide (NO2) levels using the same LAQN data that was used for random forest. the goal is to compare CNN performance against the random forest baseline (test R² = 0.814)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40234ea0",
   "metadata": {},
   "source": [
    "## 1. setup and imports\n",
    "\n",
    "First, as usual import everything. \n",
    "tensorflow/keras is the deep learning library. \n",
    "numpy handles arrays. \n",
    "matplotlib and seaborn make plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5baaa093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operating system: Darwin\n",
      "processor: arm\n",
      "tensorflow version: 2.16.2\n",
      "built with CUDA: False\n",
      "\n",
      "available devices:\n",
      "  - PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n"
     ]
    }
   ],
   "source": [
    "# std libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# scikit-learn for metrics r^2, MSE, MAE\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# tensorflow and keras for neural network\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import platform\n",
    "\n",
    "print(f'operating system: {platform.system()}')\n",
    "print(f'processor: {platform.processor()}')\n",
    "print(f'tensorflow version: {tf.__version__}')\n",
    "print(f'built with CUDA: {tf.test.is_built_with_cuda()}')\n",
    "\n",
    "# check all available devices\n",
    "print('\\navailable devices:')\n",
    "for device in tf.config.list_physical_devices():\n",
    "    print(f'  - {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca50154",
   "metadata": {},
   "source": [
    "        operating system: Darwin\n",
    "        processor: arm\n",
    "        tensorflow version: 2.16.2\n",
    "        built with CUDA: False\n",
    "\n",
    "        available devices:\n",
    "        - PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74981b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from: /Users/burdzhuchaglayan/Desktop/data science projects/air-pollution-levels/data/laqn/ml_prep\n",
      "saving outputs to: /Users/burdzhuchaglayan/Desktop/data science projects/air-pollution-levels/data/laqn/cnn_model\n"
     ]
    }
   ],
   "source": [
    "# set paths update this to match your folder structure using cwd\n",
    "base_dir = Path.cwd().parent.parent / 'data' / 'laqn'\n",
    "data_dir = base_dir / 'ml_prep' # where ml_prep saved the arrays\n",
    "output_dir = base_dir / 'cnn_model' # where we save CNN outputs \n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f'loading data from: {data_dir}')\n",
    "print(f'saving outputs to: {output_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca668bd",
   "metadata": {},
   "source": [
    "\n",
    "### GPU availability\n",
    "\n",
    "- TensorFlow code, and tf.keras models will transparently run on a single GPU with no code changes required.\n",
    "> Note: Use tf.config.list_physical_devices('GPU') to confirm that TensorFlow is using the GPU.\n",
    "- The simplest way to run on multiple GPUs, on one or many machines, is using Distribution Strategies.\n",
    "\n",
    "Source: *Use a GPU :  Tensorflow Core* (no date) *TensorFlow*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fc46095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no GPU found, using CPU (training will be slower but still works)\n"
     ]
    }
   ],
   "source": [
    "# checks gpu availability taken from documentation.\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f'GPU available: {len(gpus)} device(s)')\n",
    "    for gpu in gpus:\n",
    "        print(f'  - {gpu.name}')\n",
    "else:\n",
    "    print('no GPU found, using CPU (training will be slower but still works)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5137c237",
   "metadata": {},
   "source": [
    "## 2. load prepared data\n",
    "\n",
    "the data was prepared in ml_prep notebook. it created sequences where each sample has 12 hours of history to predict the next hour. this is the same data random forest used, just in 3D shape instead of flattened.\n",
    "\n",
    "### why 3D data for CNN?\n",
    "\n",
    "random forest needs flat 2D data: (samples, features). CNN needs 3D data: (samples, timesteps, features). the 3D shape lets CNN learn patterns across time, not just treat each timestep as an independent feature.\n",
    "\n",
    "think of it like this:\n",
    "- 2D (random forest): each row is a list of 468 numbers with no structure\n",
    "- 3D (CNN): each sample is a 12×39 grid where rows are hours and columns are features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7be915f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded successfully\n",
      "\n",
      "shapes:\n",
      "X_train:(9946, 12, 39)\n",
      "X_val:(2131, 12, 39)\n",
      "X_test:(2132, 12, 39)\n",
      "y_train:(9946, 39)\n",
      "y_val:(2131, 39)\n",
      "y_test:(2132, 39)\n"
     ]
    }
   ],
   "source": [
    "# load the 3d sequences for cnn\n",
    "X_train = np.load(data_dir / 'X_train.npy')\n",
    "X_val = np.load(data_dir / 'X_val.npy')\n",
    "X_test = np.load(data_dir / 'X_test.npy')\n",
    "\n",
    "y_train = np.load(data_dir / 'y_train.npy')\n",
    "y_val = np.load(data_dir / 'y_val.npy')\n",
    "y_test = np.load(data_dir / 'y_test.npy')\n",
    "\n",
    "#load feature_names and scaler\n",
    "feature_names = joblib.load(data_dir / 'feature_names.joblib')\n",
    "scaler = joblib.load(data_dir / 'scaler.joblib')\n",
    "\n",
    "print('data loaded successfully')\n",
    "print(f'\\nshapes:')\n",
    "print(f'X_train:{X_train.shape}')\n",
    "print(f'X_val:{X_val.shape}')\n",
    "print(f'X_test:{X_test.shape}')\n",
    "print(f'y_train:{y_train.shape}')\n",
    "print(f'y_val:{y_val.shape}')\n",
    "print(f'y_test:{y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44896cc7",
   "metadata": {},
   "source": [
    "    data loaded successfully\n",
    "\n",
    "    shapes:\n",
    "    X_train:(9946, 12, 39)\n",
    "    X_val:(2131, 12, 39)\n",
    "    X_test:(2132, 12, 39)\n",
    "    y_train:(9946, 39)\n",
    "    y_val:(2131, 39)\n",
    "    y_test:(2132, 39)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d096fba6",
   "metadata": {},
   "source": [
    "### understanding the shapes\n",
    "\n",
    "X_train shape is (9946, 12, 39). this means:\n",
    "\n",
    "| dimension | value | what it represents |\n",
    "|-----------|-------|-------------------|\n",
    "| samples | 9,946 | individual training examples |\n",
    "| timesteps | 12 | hours of history per sample |\n",
    "| features | 39 | 24 NO2 + 8 PM10 + 3 O3 + 4 temporal |\n",
    "\n",
    "y_train shape is (9946, 39). the model predicts all 39 features for the next hour.\n",
    "\n",
    "for fair comparison with random forest, I focus on EN5_NO2 (first column) as the single target. this is the same station used in the RF training report. EN5 had the highest data coverage (99.6%) which makes it the most reliable target for evaluation.\n",
    "\n",
    "the 3D shape is the key difference from random forest:\n",
    "- random forest got flattened 2D: (9946, 468) where 468 = 12 × 39\n",
    "- CNN keeps the 3D structure: (9946, 12, 39)\n",
    "\n",
    "why does this matter? CNN can learn that hour 1 connects to hour 2 connects to hour 3. random forest just sees 468 separate numbers with no time relationship. this is why CNN might capture temporal patterns better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ecacd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
