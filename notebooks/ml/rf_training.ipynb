{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cb60f4c",
   "metadata": {},
   "source": [
    "# Random Forest Modelling Notebook for LAQN\n",
    "\n",
    "- Starting ML, very excited.\n",
    "- This notebook is for Random Forest training using 2D flattened data.\n",
    "- Inputs will be taken from: `data/laqn/ml_prep` folder.\n",
    "- I will be using Géron's *Hands-On Machine Learning with Scikit-Learn, Keras and TensorFlow* 3rd edition as primary source to understand the X_training and y sets better and clear implementation structures mirroring from the book.\n",
    "\n",
    "---\n",
    "\n",
    "## What this notebook does\n",
    "\n",
    "1. Load prepared data from ml_prep output.\n",
    "2. Understand the X and y structure (following Géron Chapter 2).\n",
    "3. Train a baseline Random Forest model.\n",
    "4. Evaluate using RMSE, MAE, R² (Géron Chapter 2 evaluation approach).\n",
    "5. Fine-tune hyperparameters with GridSearchCV (Géron Chapter 2).\n",
    "6. Analyse feature importance.\n",
    "7. Save the trained model.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Random Forest?\n",
    "\n",
    "From Géron (2023, Chapter 7), Random Forest is an ensemble of Decision Trees trained on different random subsets of the training data. Each tree votes on the prediction, and the final output is the average (for regression) or majority vote (for classification).\n",
    "\n",
    "Key advantages for air quality prediction:\n",
    "- Handles nonlinear relationships without feature scaling.\n",
    "- Provides feature importance for interpretability.\n",
    "- Robust against overfitting when properly tuned.\n",
    "- Works well with tabular data like our flattened time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9ec12bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mandatory libraries for random forest training\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# scikit-learn for random forest and evaluation\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# visualisation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f82194a",
   "metadata": {},
   "source": [
    "### File paths\n",
    "\n",
    "Loading from the ml_prep output folder where all prepared arrays are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eb4bf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /Users/burdzhuchaglayan/Desktop/data science projects/air-pollution-levels/data/laqn/ml_prep\n",
      "Saving results to: /Users/burdzhuchaglayan/Desktop/data science projects/air-pollution-levels/data/laqn/rf_model\n"
     ]
    }
   ],
   "source": [
    "#Paths setup matching ml_prep output \n",
    "base_dir = Path.cwd().parent.parent / \"data\" / \"laqn\"\n",
    "ml_prep_dir = base_dir / \"ml_prep\"\n",
    "\n",
    "#Output folder for this notebook\n",
    "rf_output_dir = base_dir / \"rf_model\"\n",
    "rf_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Loading data from: {ml_prep_dir}\")\n",
    "print(f\"Saving results to: {rf_output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0a8431",
   "metadata": {},
   "source": [
    "## 1) Load prepared data\n",
    "\n",
    "The ml_prep notebook created:\n",
    "- `X_train_rf.npy`: Flattened training features (9,946 samples × 468 features)\n",
    "- `X_val_rf.npy`: Flattened validation features (2,131 samples × 468 features)\n",
    "- `X_test_rf.npy`: Flattened test features (2,132 samples × 468 features)\n",
    "- `y_train.npy`, `y_val.npy`, `y_test.npy`: Target values\n",
    "- `rf_feature_names.joblib`: Feature names for interpretability\n",
    "- `scaler.joblib`: MinMaxScaler to reverse normalisation\n",
    "\n",
    "The flattening was necessary because Random Forest expects 2D input (samples, features), but the original sequences were 3D (samples, timesteps, features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4765b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "# load all prepared data\n",
    "print(\"Loading data\")\n",
    "\n",
    "X_train = np.load(ml_prep_dir / \"X_train_rf.npy\")\n",
    "X_val = np.load(ml_prep_dir / \"X_val_rf.npy\")\n",
    "X_test = np.load(ml_prep_dir / \"X_test_rf.npy\")\n",
    "\n",
    "y_train = np.load(ml_prep_dir / \"y_train.npy\")\n",
    "y_val = np.load(ml_prep_dir / \"y_val.npy\")\n",
    "y_test = np.load(ml_prep_dir / \"y_test.npy\")\n",
    "\n",
    "rf_feature_names = joblib.load(ml_prep_dir / \"rf_feature_names.joblib\")\n",
    "feature_names = joblib.load(ml_prep_dir / \"feature_names.joblib\")\n",
    "scaler = joblib.load(ml_prep_dir / \"scaler.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "762e3181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (9946, 468)\n",
      "X_val shape: (2131, 468)\n",
      "X_test shape: (2132, 468)\n",
      "y_train shape: (9946, 39)\n",
      "y_val shape: (2131, 39)\n",
      "y_test shape: (2132, 39)\n",
      "Number of RF features: 468\n",
      "Number of target features: 39\n"
     ]
    }
   ],
   "source": [
    "#check loaded data shapes\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "print(f\"Number of RF features: {len(rf_feature_names)}\")\n",
    "print(f\"Number of target features: {len(feature_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051b4d05",
   "metadata": {},
   "source": [
    "    X_train shape: (9946, 468)\n",
    "    X_val shape: (2131, 468)\n",
    "    X_test shape: (2132, 468)\n",
    "    y_train shape: (9946, 39)\n",
    "    y_val shape: (2131, 39)\n",
    "    y_test shape: (2132, 39)\n",
    "    Number of RF features: 468\n",
    "    Number of target features: 39"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f74be7b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
