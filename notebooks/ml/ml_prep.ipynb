{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cefdb13",
   "metadata": {},
   "source": [
    "# ML LAQN Data Preparation for Air Quality Prediction\n",
    "\n",
    "I will be prepearte LAQN data for machine learning models in this notebook.\n",
    "\n",
    "## What this notebook does\n",
    "\n",
    "1. Loads cleaned data from the optimised folder.\n",
    "\n",
    "   ```bash\n",
    "   ├── optimased/                              # Optimased validated measurements folder, will be use this folder's files for ML.\n",
    "   │   ├── 2023_jan/                           # Monthly folders.\n",
    "   │   ├── 2023_feb/\n",
    "   │   ├── ...\n",
    "   │   └── 2025_nov/\n",
    "   │       └── {SiteCode}_{SpeciesCode}_{StartDate}_{EndDate}.csv #structure of the optimased \n",
    "   ```\n",
    "\n",
    "2. All measurements into a single dataset.\n",
    "3. Temporal features (hour, day, month).\n",
    "\n",
    "## Output path:\n",
    "\n",
    "data will be satve: `data/ml/` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6211404b",
   "metadata": {},
   "source": [
    "- Usual drill, I will be adding my paths under this md cell for organise myself better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47580d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting with adding mandotary and very helpful python modules below.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# preprocessing libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e66ead",
   "metadata": {},
   "source": [
    "- The dataset/file paths will be below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a623752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml prep file path\n",
    "base_dir = Path.cwd().parent.parent / \"data\" / \"laqn\"\n",
    "project_rooth = Path.cwd() / \"ml_prep.ipynb\"\n",
    "\n",
    "# laqn optimased data files path\n",
    "optimased_path = base_dir / \"optimased\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0026754",
   "metadata": {},
   "source": [
    "## 1) Load LAQN data:\n",
    "\n",
    "1. Loads cleaned data from the optimised folder.\n",
    "\n",
    "   ```bash\n",
    "   ├── optimased/                              # Optimased validated measurements folder, will be use this folder's files for ML.\n",
    "   │   ├── 2023_jan/                           # Monthly folders.\n",
    "   │   ├── 2023_feb/\n",
    "   │   ├── ...\n",
    "   │   └── 2025_nov/\n",
    "   │       └── {SiteCode}_{SpeciesCode}_{StartDate}_{EndDate}.csv #structure of the optimased \n",
    "   ```\n",
    "\n",
    "   heads of the optimased files column structure: \n",
    "   `@MeasurementDateGMT,@Value,SpeciesCode,SiteCode,SpeciesName,SiteName,SiteType,Latitude,Longitude`\n",
    "\n",
    " - load_data function will be create to combine all the files in to one df.\n",
    "\n",
    "   Why needs to be on one df? \n",
    "\n",
    "   - Each file contains hourly measurements for one station, one pollutant, one month. \n",
    "   - Time continuity : Machine learning requires identifying patterns over time. If Jan and Feb are in separate files, the model can't learn that pollution on Jan 31 affects Feb1.\n",
    "   - Train/test split. %70 for training, %15 validation and %15 test.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8303f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data (optimased_path) :\n",
    "    \"\"\"\n",
    "    Function to load the optimased data files from the laqn dataset.\n",
    "    param:\n",
    "        optimased_path: path for data/laqn/optimased directory.\n",
    "    \"\"\"\n",
    "    optimased_path = Path(optimased_path)\n",
    "    all_files = []\n",
    "    file_count = 0\n",
    "\n",
    "    # Get all monthly folders sorted chronologically\n",
    "    monthly_folders = sorted([f for f in optimased_path.iterdir() if f.is_dir()])\n",
    "    \n",
    "    print(f\"Found {len(monthly_folders)} monthly folders\")\n",
    "    \n",
    "    # Iterate through each monthly folder\n",
    "    for folder in monthly_folders:\n",
    "        # Get all CSV files in this folder\n",
    "        csv_files = list(folder.glob(\"*.csv\"))\n",
    "        \n",
    "        for csv_file in csv_files:\n",
    "            try:\n",
    "                df = pd.read_csv(csv_file)\n",
    "                all_files.append(df)\n",
    "                file_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {csv_file.name}: {e}\")\n",
    "        \n",
    "        # Progress update\n",
    "        print(f\"  Loaded {folder.name}: {len(csv_files)} files\")\n",
    "    \n",
    "    # Combine all dataframes\n",
    "    if not all_files:\n",
    "        raise ValueError(f\"No CSV files found in {optimased_path}\")\n",
    "    \n",
    "    combined_df = pd.concat(all_files, ignore_index=True)\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*40)\n",
    "    print(f\"Total files loaded: {file_count}\")\n",
    "    print(f\"Total rows: {len(combined_df):,}\")\n",
    "    print(f\"Columns: {list(combined_df.columns)}\")\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be321c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36 monthly folders\n",
      "  Loaded 2023_apr: 141 files\n",
      "  Loaded 2023_aug: 141 files\n",
      "  Loaded 2023_dec: 141 files\n",
      "  Loaded 2023_feb: 141 files\n",
      "  Loaded 2023_jan: 141 files\n",
      "  Loaded 2023_jul: 141 files\n",
      "  Loaded 2023_jun: 141 files\n",
      "  Loaded 2023_mar: 141 files\n",
      "  Loaded 2023_may: 141 files\n",
      "  Loaded 2023_nov: 138 files\n",
      "  Loaded 2023_oct: 141 files\n",
      "  Loaded 2023_sep: 141 files\n",
      "  Loaded 2024_apr: 141 files\n",
      "  Loaded 2024_aug: 141 files\n",
      "  Loaded 2024_dec: 141 files\n",
      "  Loaded 2024_feb: 141 files\n",
      "  Loaded 2024_jan: 141 files\n",
      "  Loaded 2024_jul: 141 files\n",
      "  Loaded 2024_jun: 141 files\n",
      "  Loaded 2024_mar: 141 files\n",
      "  Loaded 2024_may: 141 files\n",
      "  Loaded 2024_nov: 141 files\n",
      "  Loaded 2024_oct: 141 files\n",
      "  Loaded 2024_sep: 141 files\n",
      "  Loaded 2025_apr: 141 files\n",
      "  Loaded 2025_aug: 141 files\n",
      "  Loaded 2025_feb: 141 files\n",
      "  Loaded 2025_jan: 141 files\n",
      "  Loaded 2025_jul: 141 files\n",
      "  Loaded 2025_jun: 141 files\n",
      "  Loaded 2025_mar: 141 files\n",
      "  Loaded 2025_may: 141 files\n",
      "  Loaded 2025_nov: 141 files\n",
      "  Loaded 2025_oct: 141 files\n",
      "  Loaded 2025_sep: 141 files\n",
      "  Loaded report: 0 files\n",
      "\n",
      "========================================\n",
      "Total files loaded: 4932\n",
      "Total rows: 3,446,208\n",
      "Columns: ['@MeasurementDateGMT', '@Value', 'SpeciesCode', 'SiteCode', 'SpeciesName', 'SiteName', 'SiteType', 'Latitude', 'Longitude']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>@MeasurementDateGMT</th>\n",
       "      <th>@Value</th>\n",
       "      <th>SpeciesCode</th>\n",
       "      <th>SiteCode</th>\n",
       "      <th>SpeciesName</th>\n",
       "      <th>SiteName</th>\n",
       "      <th>SiteType</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-01 00:00:00</td>\n",
       "      <td>5.1</td>\n",
       "      <td>PM10</td>\n",
       "      <td>GB6</td>\n",
       "      <td>PM10 Particulate</td>\n",
       "      <td>Greenwich - Falconwood</td>\n",
       "      <td>Roadside</td>\n",
       "      <td>51.4563</td>\n",
       "      <td>0.085606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-01 01:00:00</td>\n",
       "      <td>4.4</td>\n",
       "      <td>PM10</td>\n",
       "      <td>GB6</td>\n",
       "      <td>PM10 Particulate</td>\n",
       "      <td>Greenwich - Falconwood</td>\n",
       "      <td>Roadside</td>\n",
       "      <td>51.4563</td>\n",
       "      <td>0.085606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-01 02:00:00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>PM10</td>\n",
       "      <td>GB6</td>\n",
       "      <td>PM10 Particulate</td>\n",
       "      <td>Greenwich - Falconwood</td>\n",
       "      <td>Roadside</td>\n",
       "      <td>51.4563</td>\n",
       "      <td>0.085606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-01 03:00:00</td>\n",
       "      <td>5.3</td>\n",
       "      <td>PM10</td>\n",
       "      <td>GB6</td>\n",
       "      <td>PM10 Particulate</td>\n",
       "      <td>Greenwich - Falconwood</td>\n",
       "      <td>Roadside</td>\n",
       "      <td>51.4563</td>\n",
       "      <td>0.085606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-01 04:00:00</td>\n",
       "      <td>3.9</td>\n",
       "      <td>PM10</td>\n",
       "      <td>GB6</td>\n",
       "      <td>PM10 Particulate</td>\n",
       "      <td>Greenwich - Falconwood</td>\n",
       "      <td>Roadside</td>\n",
       "      <td>51.4563</td>\n",
       "      <td>0.085606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-04-01 05:00:00</td>\n",
       "      <td>4.3</td>\n",
       "      <td>PM10</td>\n",
       "      <td>GB6</td>\n",
       "      <td>PM10 Particulate</td>\n",
       "      <td>Greenwich - Falconwood</td>\n",
       "      <td>Roadside</td>\n",
       "      <td>51.4563</td>\n",
       "      <td>0.085606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-04-01 06:00:00</td>\n",
       "      <td>4.2</td>\n",
       "      <td>PM10</td>\n",
       "      <td>GB6</td>\n",
       "      <td>PM10 Particulate</td>\n",
       "      <td>Greenwich - Falconwood</td>\n",
       "      <td>Roadside</td>\n",
       "      <td>51.4563</td>\n",
       "      <td>0.085606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-04-01 07:00:00</td>\n",
       "      <td>5.5</td>\n",
       "      <td>PM10</td>\n",
       "      <td>GB6</td>\n",
       "      <td>PM10 Particulate</td>\n",
       "      <td>Greenwich - Falconwood</td>\n",
       "      <td>Roadside</td>\n",
       "      <td>51.4563</td>\n",
       "      <td>0.085606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-04-01 08:00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PM10</td>\n",
       "      <td>GB6</td>\n",
       "      <td>PM10 Particulate</td>\n",
       "      <td>Greenwich - Falconwood</td>\n",
       "      <td>Roadside</td>\n",
       "      <td>51.4563</td>\n",
       "      <td>0.085606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-04-01 09:00:00</td>\n",
       "      <td>9.4</td>\n",
       "      <td>PM10</td>\n",
       "      <td>GB6</td>\n",
       "      <td>PM10 Particulate</td>\n",
       "      <td>Greenwich - Falconwood</td>\n",
       "      <td>Roadside</td>\n",
       "      <td>51.4563</td>\n",
       "      <td>0.085606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   @MeasurementDateGMT  @Value SpeciesCode SiteCode       SpeciesName  \\\n",
       "0  2023-04-01 00:00:00     5.1        PM10      GB6  PM10 Particulate   \n",
       "1  2023-04-01 01:00:00     4.4        PM10      GB6  PM10 Particulate   \n",
       "2  2023-04-01 02:00:00     3.5        PM10      GB6  PM10 Particulate   \n",
       "3  2023-04-01 03:00:00     5.3        PM10      GB6  PM10 Particulate   \n",
       "4  2023-04-01 04:00:00     3.9        PM10      GB6  PM10 Particulate   \n",
       "5  2023-04-01 05:00:00     4.3        PM10      GB6  PM10 Particulate   \n",
       "6  2023-04-01 06:00:00     4.2        PM10      GB6  PM10 Particulate   \n",
       "7  2023-04-01 07:00:00     5.5        PM10      GB6  PM10 Particulate   \n",
       "8  2023-04-01 08:00:00     8.0        PM10      GB6  PM10 Particulate   \n",
       "9  2023-04-01 09:00:00     9.4        PM10      GB6  PM10 Particulate   \n",
       "\n",
       "                 SiteName  SiteType  Latitude  Longitude  \n",
       "0  Greenwich - Falconwood  Roadside   51.4563   0.085606  \n",
       "1  Greenwich - Falconwood  Roadside   51.4563   0.085606  \n",
       "2  Greenwich - Falconwood  Roadside   51.4563   0.085606  \n",
       "3  Greenwich - Falconwood  Roadside   51.4563   0.085606  \n",
       "4  Greenwich - Falconwood  Roadside   51.4563   0.085606  \n",
       "5  Greenwich - Falconwood  Roadside   51.4563   0.085606  \n",
       "6  Greenwich - Falconwood  Roadside   51.4563   0.085606  \n",
       "7  Greenwich - Falconwood  Roadside   51.4563   0.085606  \n",
       "8  Greenwich - Falconwood  Roadside   51.4563   0.085606  \n",
       "9  Greenwich - Falconwood  Roadside   51.4563   0.085606  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all data\n",
    "df_raw = load_data(optimased_path)\n",
    "\n",
    "# preview data\n",
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d037ccd0",
   "metadata": {},
   "source": [
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>@MeasurementDateGMT</th>\n",
    "      <th>@Value</th>\n",
    "      <th>SpeciesCode</th>\n",
    "      <th>SiteCode</th>\n",
    "      <th>SpeciesName</th>\n",
    "      <th>SiteName</th>\n",
    "      <th>SiteType</th>\n",
    "      <th>Latitude</th>\n",
    "      <th>Longitude</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>2023-04-01 00:00:00</td>\n",
    "      <td>5.1</td>\n",
    "      <td>PM10</td>\n",
    "      <td>GB6</td>\n",
    "      <td>PM10 Particulate</td>\n",
    "      <td>Greenwich - Falconwood</td>\n",
    "      <td>Roadside</td>\n",
    "      <td>51.4563</td>\n",
    "      <td>0.085606</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>2023-04-01 01:00:00</td>\n",
    "      <td>4.4</td>\n",
    "      <td>PM10</td>\n",
    "      <td>GB6</td>\n",
    "      <td>PM10 Particulate</td>\n",
    "      <td>Greenwich - Falconwood</td>\n",
    "      <td>Roadside</td>\n",
    "      <td>51.4563</td>\n",
    "      <td>0.085606</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>2023-04-01 02:00:00</td>\n",
    "      <td>3.5</td>\n",
    "      <td>PM10</td>\n",
    "      <td>GB6</td>\n",
    "      <td>PM10 Particulate</td>\n",
    "      <td>Greenwich - Falconwood</td>\n",
    "      <td>Roadside</td>\n",
    "      <td>51.4563</td>\n",
    "      <td>0.085606</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>2023-04-01 03:00:00</td>\n",
    "      <td>5.3</td>\n",
    "      <td>PM10</td>\n",
    "      <td>GB6</td>\n",
    "      <td>PM10 Particulate</td>\n",
    "      <td>Greenwich - Falconwood</td>\n",
    "      <td>Roadside</td>\n",
    "      <td>51.4563</td>\n",
    "      <td>0.085606</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>2023-04-01 04:00:00</td>\n",
    "      <td>3.9</td>\n",
    "      <td>PM10</td>\n",
    "      <td>GB6</td>\n",
    "      <td>PM10 Particulate</td>\n",
    "      <td>Greenwich - Falconwood</td>\n",
    "      <td>Roadside</td>\n",
    "      <td>51.4563</td>\n",
    "      <td>0.085606</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>5</th>\n",
    "      <td>2023-04-01 05:00:00</td>\n",
    "      <td>4.3</td>\n",
    "      <td>PM10</td>\n",
    "      <td>GB6</td>\n",
    "      <td>PM10 Particulate</td>\n",
    "      <td>Greenwich - Falconwood</td>\n",
    "      <td>Roadside</td>\n",
    "      <td>51.4563</td>\n",
    "      <td>0.085606</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>6</th>\n",
    "      <td>2023-04-01 06:00:00</td>\n",
    "      <td>4.2</td>\n",
    "      <td>PM10</td>\n",
    "      <td>GB6</td>\n",
    "      <td>PM10 Particulate</td>\n",
    "      <td>Greenwich - Falconwood</td>\n",
    "      <td>Roadside</td>\n",
    "      <td>51.4563</td>\n",
    "      <td>0.085606</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>7</th>\n",
    "      <td>2023-04-01 07:00:00</td>\n",
    "      <td>5.5</td>\n",
    "      <td>PM10</td>\n",
    "      <td>GB6</td>\n",
    "      <td>PM10 Particulate</td>\n",
    "      <td>Greenwich - Falconwood</td>\n",
    "      <td>Roadside</td>\n",
    "      <td>51.4563</td>\n",
    "      <td>0.085606</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>8</th>\n",
    "      <td>2023-04-01 08:00:00</td>\n",
    "      <td>8.0</td>\n",
    "      <td>PM10</td>\n",
    "      <td>GB6</td>\n",
    "      <td>PM10 Particulate</td>\n",
    "      <td>Greenwich - Falconwood</td>\n",
    "      <td>Roadside</td>\n",
    "      <td>51.4563</td>\n",
    "      <td>0.085606</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>9</th>\n",
    "      <td>2023-04-01 09:00:00</td>\n",
    "      <td>9.4</td>\n",
    "      <td>PM10</td>\n",
    "      <td>GB6</td>\n",
    "      <td>PM10 Particulate</td>\n",
    "      <td>Greenwich - Falconwood</td>\n",
    "      <td>Roadside</td>\n",
    "      <td>51.4563</td>\n",
    "      <td>0.085606</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cee37895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (3446208, 9)\n",
      "\n",
      "Column types:\n",
      "@MeasurementDateGMT     object\n",
      "@Value                 float64\n",
      "SpeciesCode             object\n",
      "SiteCode                object\n",
      "SpeciesName             object\n",
      "SiteName                object\n",
      "SiteType                object\n",
      "Latitude               float64\n",
      "Longitude              float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "@MeasurementDateGMT         0\n",
      "@Value                 464791\n",
      "SpeciesCode                 0\n",
      "SiteCode                    0\n",
      "SpeciesName                 0\n",
      "SiteName                    0\n",
      "SiteType                    0\n",
      "Latitude                    0\n",
      "Longitude                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check data info\n",
    "print(\"Data shape:\", df_raw.shape)\n",
    "print(\"\\nColumn types:\")\n",
    "print(df_raw.dtypes)\n",
    "print(\"\\nMissing values:\")\n",
    "print(df_raw.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379ad84e",
   "metadata": {},
   "source": [
    "    Data shape: (3446208, 9)\n",
    "\n",
    "    Column types:\n",
    "    @MeasurementDateGMT     object\n",
    "    @Value                 float64\n",
    "    SpeciesCode             object\n",
    "    SiteCode                object\n",
    "    SpeciesName             object\n",
    "    SiteName                object\n",
    "    SiteType                object\n",
    "    Latitude               float64\n",
    "    Longitude              float64\n",
    "    dtype: object\n",
    "\n",
    "    Missing values:\n",
    "    @MeasurementDateGMT         0\n",
    "    @Value                 464791\n",
    "    SpeciesCode                 0\n",
    "    SiteCode                    0\n",
    "    SpeciesName                 0\n",
    "    SiteName                    0\n",
    "    SiteType                    0\n",
    "    Latitude                    0\n",
    "    Longitude                   0\n",
    "    dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1d0bc4",
   "metadata": {},
   "source": [
    "## 2) Data explarotion:\n",
    "Already checked data many times but  I think it is beneficial to add it here again:\n",
    "\n",
    "- How many unique sites? - 64\n",
    "- Which pollutants (species)? 6 pollutant\n",
    "- Date range? 1.01.2023 till 19.11.2925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5083132b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique sites: 64\n",
      "Unique species: 6\n",
      "\n",
      "Date range: 2023-01-01 00:00:00 to 2025-11-18 23:00:00\n",
      "\n",
      "Species in data:\n",
      "SpeciesCode\n",
      "NO2      1417752\n",
      "PM10     1026456\n",
      "PM2.5     586944\n",
      "O3        268320\n",
      "SO2        97824\n",
      "CO         48912\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define colm names based on optimased data structure\n",
    "date_col = '@MeasurementDateGMT'\n",
    "value_col = '@Value'\n",
    "site_col = 'SiteCode'\n",
    "species_col = 'SpeciesCode'\n",
    "\n",
    "# Convert datetime\n",
    "df_raw[date_col] = pd.to_datetime(df_raw[date_col])\n",
    "\n",
    "# run them.\n",
    "print(f\"Unique sites: {df_raw[site_col].nunique()}\")\n",
    "print(f\"Unique species: {df_raw[species_col].nunique()}\")\n",
    "print(f\"\\nDate range: {df_raw[date_col].min()} to {df_raw[date_col].max()}\")\n",
    "print(f\"\\nSpecies in data:\")\n",
    "print(df_raw[species_col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db01c665",
   "metadata": {},
   "source": [
    "    Unique sites: 64\n",
    "    Unique species: 6\n",
    "\n",
    "    Date range: 2023-01-01 00:00:00 to 2025-11-18 23:00:00\n",
    "\n",
    "    Species in data:\n",
    "    SpeciesCode\n",
    "    NO2      1417752\n",
    "    PM10     1026456\n",
    "    PM2.5     586944\n",
    "    O3        268320\n",
    "    SO2        97824\n",
    "    CO         48912\n",
    "    Name: count, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851ec7d4",
   "metadata": {},
   "source": [
    "## 3) Selecting target pollutants:\n",
    "As I mentioned at `/docs/LAQN_DEFRA_benchmark.md` and `/docs/LAQN_data_quality.md` highest coverage:\n",
    "- NO2 : 60 sites\n",
    "- PM25 : 53 sites\n",
    "- PM10: 43 sites\n",
    "- O3: 11 sites\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3f717a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before filtering: 3,446,208\n",
      "Rows after filtering: 2,712,528\n",
      "\n",
      "Pollutants included:\n",
      "SpeciesCode\n",
      "NO2     1417752\n",
      "PM10    1026456\n",
      "O3       268320\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# target pollutants\n",
    "target_pollutants = ['NO2', 'PM25', 'PM10', 'O3']\n",
    "\n",
    "# Filter data\n",
    "df_filtered = df_raw[df_raw[species_col].isin(target_pollutants)].copy()\n",
    "\n",
    "print(f\"Rows before filtering: {len(df_raw):,}\")\n",
    "print(f\"Rows after filtering: {len(df_filtered):,}\")\n",
    "print(f\"\\nPollutants included:\")\n",
    "print(df_filtered[species_col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff775672",
   "metadata": {},
   "source": [
    "## 4) Temporal feature adding:\n",
    "\n",
    "already added this feature in analyse part.\n",
    "\n",
    "- That will be help to see how pollutant concentrations more according to time of the day\n",
    "- day of the week (trafic effection)\n",
    "- Season/month of the year.\n",
    "\n",
    "These features help the model learn when pollution is typically high or low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcbc1868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_features(df, datetime_col):\n",
    "    \"\"\"\n",
    "     Temporal features from datetime column.\n",
    "    Param:\n",
    "            df : pandas.DataFrame\n",
    "\n",
    "            datetime_col : str\n",
    "       \n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    #  datetime type needs to be ensured\n",
    "    df[datetime_col] = pd.to_datetime(df[datetime_col])\n",
    "    \n",
    "    # Extract features\n",
    "    df['hour'] = df[datetime_col].dt.hour\n",
    "    df['day_of_week'] = df[datetime_col].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "    df['month'] = df[datetime_col].dt.month\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    \n",
    "    print(\"Added temporal features: hour, day_of_week, month, is_weekend\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f7257ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added temporal features: hour, day_of_week, month, is_weekend\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hour  day_of_week  month  is_weekend\n",
       "0     0            5      4           1\n",
       "1     1            5      4           1\n",
       "2     2            5      4           1\n",
       "3     3            5      4           1\n",
       "4     4            5      4           1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add temporal features\n",
    "df_temporal = temporal_features(df_filtered, date_col)\n",
    "\n",
    "# Preview\n",
    "df_temporal[['hour', 'day_of_week', 'month', 'is_weekend']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516a8368",
   "metadata": {},
   "source": [
    "| Column      | Value         | Meaning                       |\n",
    "| ----------- | ------------- | ----------------------------- |\n",
    "| hour        | 0, 1, 2, 3, 4 | Midnight, 1am, 2am, 3am, 4am  |\n",
    "| day_of_week | 5             | Saturday (0=Monday, 6=Sunday) |\n",
    "| month       | 4             | April                         |\n",
    "| is_weekend  | 1             | Yes, it is a weekend          |\n",
    "\n",
    "Added temporal features: hour, day_of_week, month, is_weekend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57bb2f6",
   "metadata": {},
   "source": [
    "## 5) Wide formatting\n",
    "\n",
    "For ml (Air quality prediction using CNN+LSTM-based hybrid deep learning architecture', *Environmental Science and Pollution Research*, 29(8), pp. 11920-11938)\n",
    "\n",
    "And according to their search here are the findings:\n",
    " | Method      | Input                                    | Output           |\n",
    "| ----------- | ---------------------------------------- | ---------------- |\n",
    "| UNI/UNI     | Historical info of target pollutant only | Single pollutant |\n",
    "| MULTI/UNI   | Historical info of all pollutants        | Single pollutant |\n",
    "| MULTI/MULTI | Historical info of all pollutants        | All pollutants   |\n",
    "\n",
    "page 11922 (Results section):\n",
    "\n",
    "> \"The multivariate model without using meteorological data revealed the best results.\"\n",
    "\n",
    "So order to create multivariate input I will be formatting pivot to wider,adding each station/species combination to table.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "918fff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_format(df, datetime_col, site_col, species_col, value_col):\n",
    "    \"\"\"\n",
    "    Pivot data from long to wide format. \n",
    "    Each site-species combination becomes a column.\n",
    "    Each row represents one timestamp.\n",
    "    \n",
    "    Params:\n",
    "        datetime_col, site_col, species_col, value_col \n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Create site_species identifier\n",
    "    df['site_species'] = df[site_col] + '_' + df[species_col]\n",
    "    \n",
    "    # Pivot table\n",
    "    # If duplicate datetime-site_species combinations exist, take mean\n",
    "    pivoted = df.pivot_table(\n",
    "        index=datetime_col,\n",
    "        columns='site_species',\n",
    "        values=value_col,\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    \n",
    "    # Sort by datetime\n",
    "    pivoted = pivoted.sort_index()\n",
    "    \n",
    "    print(f\"Created wide format:\")\n",
    "    print(f\"Timestamps: {len(pivoted):,}\")\n",
    "    print(f\"Features (site-species): {len(pivoted.columns)}\")\n",
    "    print(f\"Date range: {pivoted.index.min()} to {pivoted.index.max()}\")\n",
    "    \n",
    "    return pivoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b53f3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created wide format:\n",
      "Timestamps: 24,456\n",
      "Features (site-species): 111\n",
      "Date range: 2023-01-01 00:00:00 to 2025-11-18 23:00:00\n",
      "\n",
      "First 10 columns:\n",
      "['BG1_NO2', 'BG2_NO2', 'BG2_PM10', 'BQ7_NO2', 'BQ7_O3', 'BQ7_PM10', 'BQ9_PM10', 'BT4_NO2', 'BT4_PM10', 'BT5_NO2']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>site_species</th>\n",
       "      <th>BG1_NO2</th>\n",
       "      <th>BG2_NO2</th>\n",
       "      <th>BG2_PM10</th>\n",
       "      <th>BQ7_NO2</th>\n",
       "      <th>BQ7_O3</th>\n",
       "      <th>BQ7_PM10</th>\n",
       "      <th>BQ9_PM10</th>\n",
       "      <th>BT4_NO2</th>\n",
       "      <th>BT4_PM10</th>\n",
       "      <th>BT5_NO2</th>\n",
       "      <th>...</th>\n",
       "      <th>WA9_PM10</th>\n",
       "      <th>WAA_NO2</th>\n",
       "      <th>WAA_PM10</th>\n",
       "      <th>WAB_NO2</th>\n",
       "      <th>WAB_PM10</th>\n",
       "      <th>WAC_PM10</th>\n",
       "      <th>WM5_NO2</th>\n",
       "      <th>WM6_NO2</th>\n",
       "      <th>WM6_PM10</th>\n",
       "      <th>WMD_NO2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@MeasurementDateGMT</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:00</th>\n",
       "      <td>7.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>16.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>11.4</td>\n",
       "      <td>39.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>17.9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 01:00:00</th>\n",
       "      <td>4.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.4</td>\n",
       "      <td>6.8</td>\n",
       "      <td>7.1</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.2</td>\n",
       "      <td>15.1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 02:00:00</th>\n",
       "      <td>4.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.7</td>\n",
       "      <td>9.3</td>\n",
       "      <td>9.7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 03:00:00</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>10.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.4</td>\n",
       "      <td>11.8</td>\n",
       "      <td>13.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>6.2</td>\n",
       "      <td>19.7</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 04:00:00</th>\n",
       "      <td>2.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>13.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.1</td>\n",
       "      <td>12.7</td>\n",
       "      <td>14.5</td>\n",
       "      <td>7.9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>16.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "site_species         BG1_NO2  BG2_NO2  BG2_PM10  BQ7_NO2  BQ7_O3  BQ7_PM10  \\\n",
       "@MeasurementDateGMT                                                          \n",
       "2023-01-01 00:00:00      7.6      4.6      16.5      NaN    74.2      10.2   \n",
       "2023-01-01 01:00:00      4.4      4.4       NaN      NaN    74.4       6.8   \n",
       "2023-01-01 02:00:00      4.2      4.1       5.7      NaN    76.7       9.3   \n",
       "2023-01-01 03:00:00      4.5      3.7      10.2      NaN    76.4      11.8   \n",
       "2023-01-01 04:00:00      2.7      2.9      13.8      NaN    77.1      12.7   \n",
       "\n",
       "site_species         BQ9_PM10  BT4_NO2  BT4_PM10  BT5_NO2  ...  WA9_PM10  \\\n",
       "@MeasurementDateGMT                                        ...             \n",
       "2023-01-01 00:00:00       8.1     11.4      39.0      8.1  ...       9.0   \n",
       "2023-01-01 01:00:00       7.1     14.5      15.0      7.1  ...       3.0   \n",
       "2023-01-01 02:00:00       9.7     14.0      18.0      5.3  ...      11.0   \n",
       "2023-01-01 03:00:00      13.1     12.6      15.0      3.7  ...      11.0   \n",
       "2023-01-01 04:00:00      14.5      7.9      17.0      6.1  ...      13.0   \n",
       "\n",
       "site_species         WAA_NO2  WAA_PM10  WAB_NO2  WAB_PM10  WAC_PM10  WM5_NO2  \\\n",
       "@MeasurementDateGMT                                                            \n",
       "2023-01-01 00:00:00      9.0      12.7      NaN      24.0      19.9      5.7   \n",
       "2023-01-01 01:00:00      7.0       6.9      NaN       7.0       8.5      6.2   \n",
       "2023-01-01 02:00:00      6.0      11.0      NaN      13.0      12.1      9.1   \n",
       "2023-01-01 03:00:00      5.0      12.5      NaN      16.0      14.7      6.2   \n",
       "2023-01-01 04:00:00      5.0      15.6      NaN      19.0      18.4      5.3   \n",
       "\n",
       "site_species         WM6_NO2  WM6_PM10  WMD_NO2  \n",
       "@MeasurementDateGMT                              \n",
       "2023-01-01 00:00:00     17.9      14.0      8.8  \n",
       "2023-01-01 01:00:00     15.1      17.0      9.1  \n",
       "2023-01-01 02:00:00     16.0      16.0      8.4  \n",
       "2023-01-01 03:00:00     19.7      24.0      3.2  \n",
       "2023-01-01 04:00:00     16.5      20.0      4.0  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create wide format\n",
    "df_wide = wide_format(df_temporal, date_col, site_col, species_col, value_col)\n",
    "\n",
    "# Preview\n",
    "print(\"\\nFirst 10 columns:\")\n",
    "print(list(df_wide.columns)[:10])\n",
    "df_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12dc38f",
   "metadata": {},
   "source": [
    "    Created wide format:\n",
    "    Timestamps: 24,456\n",
    "    Features (site-species): 111\n",
    "    Date range: 2023-01-01 00:00:00 to 2025-11-18 23:00:00\n",
    "\n",
    "    First 10 columns:\n",
    "    ['BG1_NO2', 'BG2_NO2', 'BG2_PM10', 'BQ7_NO2', 'BQ7_O3', 'BQ7_PM10', 'BQ9_PM10', 'BT4_NO2', 'BT4_PM10', 'BT5_NO2']\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "<thead>\n",
    "<tr style=\"text-align: right;\">\n",
    "    <th>site_species</th>\n",
    "    <th>BG1_NO2</th>\n",
    "    <th>BG2_NO2</th>\n",
    "    <th>BG2_PM10</th>\n",
    "    <th>BQ7_NO2</th>\n",
    "    <th>BQ7_O3</th>\n",
    "    <th>BQ7_PM10</th>\n",
    "    <th>BQ9_PM10</th>\n",
    "    <th>BT4_NO2</th>\n",
    "    <th>BT4_PM10</th>\n",
    "    <th>BT5_NO2</th>\n",
    "    <th>...</th>\n",
    "    <th>WA9_PM10</th>\n",
    "    <th>WAA_NO2</th>\n",
    "    <th>WAA_PM10</th>\n",
    "    <th>WAB_NO2</th>\n",
    "    <th>WAB_PM10</th>\n",
    "    <th>WAC_PM10</th>\n",
    "    <th>WM5_NO2</th>\n",
    "    <th>WM6_NO2</th>\n",
    "    <th>WM6_PM10</th>\n",
    "    <th>WMD_NO2</th>\n",
    "</tr>\n",
    "<tr>\n",
    "    <th>@MeasurementDateGMT</th>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "    <th>2023-01-01 00:00:00</th>\n",
    "    <td>7.6</td>\n",
    "    <td>4.6</td>\n",
    "    <td>16.5</td>\n",
    "    <td>NaN</td>\n",
    "    <td>74.2</td>\n",
    "    <td>10.2</td>\n",
    "    <td>8.1</td>\n",
    "    <td>11.4</td>\n",
    "    <td>39.0</td>\n",
    "    <td>8.1</td>\n",
    "    <td>...</td>\n",
    "    <td>9.0</td>\n",
    "    <td>9.0</td>\n",
    "    <td>12.7</td>\n",
    "    <td>NaN</td>\n",
    "    <td>24.0</td>\n",
    "    <td>19.9</td>\n",
    "    <td>5.7</td>\n",
    "    <td>17.9</td>\n",
    "    <td>14.0</td>\n",
    "    <td>8.8</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <th>2023-01-01 01:00:00</th>\n",
    "    <td>4.4</td>\n",
    "    <td>4.4</td>\n",
    "    <td>NaN</td>\n",
    "    <td>NaN</td>\n",
    "    <td>74.4</td>\n",
    "    <td>6.8</td>\n",
    "    <td>7.1</td>\n",
    "    <td>14.5</td>\n",
    "    <td>15.0</td>\n",
    "    <td>7.1</td>\n",
    "    <td>...</td>\n",
    "    <td>3.0</td>\n",
    "    <td>7.0</td>\n",
    "    <td>6.9</td>\n",
    "    <td>NaN</td>\n",
    "    <td>7.0</td>\n",
    "    <td>8.5</td>\n",
    "    <td>6.2</td>\n",
    "    <td>15.1</td>\n",
    "    <td>17.0</td>\n",
    "    <td>9.1</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <th>2023-01-01 02:00:00</th>\n",
    "    <td>4.2</td>\n",
    "    <td>4.1</td>\n",
    "    <td>5.7</td>\n",
    "    <td>NaN</td>\n",
    "    <td>76.7</td>\n",
    "    <td>9.3</td>\n",
    "    <td>9.7</td>\n",
    "    <td>14.0</td>\n",
    "    <td>18.0</td>\n",
    "    <td>5.3</td>\n",
    "    <td>...</td>\n",
    "    <td>11.0</td>\n",
    "    <td>6.0</td>\n",
    "    <td>11.0</td>\n",
    "    <td>NaN</td>\n",
    "    <td>13.0</td>\n",
    "    <td>12.1</td>\n",
    "    <td>9.1</td>\n",
    "    <td>16.0</td>\n",
    "    <td>16.0</td>\n",
    "    <td>8.4</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <th>2023-01-01 03:00:00</th>\n",
    "    <td>4.5</td>\n",
    "    <td>3.7</td>\n",
    "    <td>10.2</td>\n",
    "    <td>NaN</td>\n",
    "    <td>76.4</td>\n",
    "    <td>11.8</td>\n",
    "    <td>13.1</td>\n",
    "    <td>12.6</td>\n",
    "    <td>15.0</td>\n",
    "    <td>3.7</td>\n",
    "    <td>...</td>\n",
    "    <td>11.0</td>\n",
    "    <td>5.0</td>\n",
    "    <td>12.5</td>\n",
    "    <td>NaN</td>\n",
    "    <td>16.0</td>\n",
    "    <td>14.7</td>\n",
    "    <td>6.2</td>\n",
    "    <td>19.7</td>\n",
    "    <td>24.0</td>\n",
    "    <td>3.2</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <th>2023-01-01 04:00:00</th>\n",
    "    <td>2.7</td>\n",
    "    <td>2.9</td>\n",
    "    <td>13.8</td>\n",
    "    <td>NaN</td>\n",
    "    <td>77.1</td>\n",
    "    <td>12.7</td>\n",
    "    <td>14.5</td>\n",
    "    <td>7.9</td>\n",
    "    <td>17.0</td>\n",
    "    <td>6.1</td>\n",
    "    <td>...</td>\n",
    "    <td>13.0</td>\n",
    "    <td>5.0</td>\n",
    "    <td>15.6</td>\n",
    "    <td>NaN</td>\n",
    "    <td>19.0</td>\n",
    "    <td>18.4</td>\n",
    "    <td>5.3</td>\n",
    "    <td>16.5</td>\n",
    "    <td>20.0</td>\n",
    "    <td>4.0</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "<p>5 rows × 111 columns</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f31df84",
   "metadata": {},
   "source": [
    "## 6) NaN value handling\n",
    "\n",
    "- Find the optimased stratagyies.\n",
    "- maybe interpolate small gaps 2/5 hours etc..\n",
    "- or usuall drill drop the remaining rows with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4627a9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value percentage by column (top 20):\n",
      "site_species\n",
      "WM6_PM10    62.798495\n",
      "CE3_NO2     46.589794\n",
      "TL4_NO2     40.407262\n",
      "RI2_O3      39.818449\n",
      "WA7_NO2     37.765783\n",
      "CD1_PM10    31.534184\n",
      "WAA_NO2     31.505561\n",
      "CE3_PM10    31.288845\n",
      "TH4_PM10    30.528296\n",
      "HG4_O3      28.999019\n",
      "CD1_NO2     28.557409\n",
      "MY1_O3      27.171246\n",
      "SK5_PM10    26.300294\n",
      "BG1_NO2     26.226693\n",
      "BG2_NO2     24.873242\n",
      "GB6_O3      24.345764\n",
      "CE2_O3      24.124959\n",
      "TH4_O3      23.994112\n",
      "RI2_NO2     23.769218\n",
      "TH4_NO2     22.894177\n",
      "dtype: float64\n",
      "\n",
      "Total cells: 2,714,616\n",
      "Missing cells: 330,540\n",
      "Missing percentage: 12.18%\n"
     ]
    }
   ],
   "source": [
    "# Check missing values before handling\n",
    "missing_pct = (df_wide.isnull().sum() / len(df_wide) * 100).sort_values(ascending=False)\n",
    "\n",
    "print(\"Missing value percentage by column (top 20):\")\n",
    "print(missing_pct.head(20))\n",
    "\n",
    "print(f\"\\nTotal cells: {df_wide.size:,}\")\n",
    "print(f\"Missing cells: {df_wide.isnull().sum().sum():,}\")\n",
    "print(f\"Missing percentage: {df_wide.isnull().sum().sum() / df_wide.size * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335e941b",
   "metadata": {},
   "source": [
    "        Missing value percentage by column (top 20):\n",
    "        site_species\n",
    "        WM6_PM10    62.798495\n",
    "        CE3_NO2     46.589794\n",
    "        TL4_NO2     40.407262\n",
    "        RI2_O3      39.818449\n",
    "        WA7_NO2     37.765783\n",
    "        CD1_PM10    31.534184\n",
    "        WAA_NO2     31.505561\n",
    "        CE3_PM10    31.288845\n",
    "        TH4_PM10    30.528296\n",
    "        HG4_O3      28.999019\n",
    "        CD1_NO2     28.557409\n",
    "        MY1_O3      27.171246\n",
    "        SK5_PM10    26.300294\n",
    "        BG1_NO2     26.226693\n",
    "        BG2_NO2     24.873242\n",
    "        GB6_O3      24.345764\n",
    "        CE2_O3      24.124959\n",
    "        TH4_O3      23.994112\n",
    "        RI2_NO2     23.769218\n",
    "        TH4_NO2     22.894177\n",
    "        dtype: float64\n",
    "\n",
    "        Total cells: 2,714,616\n",
    "        Missing cells: 330,540\n",
    "        Missing percentage: 12.18%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75bb040",
   "metadata": {},
   "source": [
    "- max_gap=5 value. (linear interpolation is applied to fill in missing values)\n",
    "\n",
    "Air quality prediction using CNN+LSTM-based hybrid deep learning architecture', *Environmental Science and Pollution Research*, 29(8), pp. 11920-11938"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c1f5df",
   "metadata": {},
   "source": [
    "after min_coverage = 0.8 filter my dataset to 58 rows only. So I will be test other tresolds below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e141d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.5: 0 rows, 110 columns\n",
      "Threshold 0.6: 0 rows, 108 columns\n",
      "Threshold 0.7: 0 rows, 102 columns\n",
      "Threshold 0.8: 58 rows, 86 columns\n",
      "Threshold 0.9: 4,069 rows, 62 columns\n",
      "Threshold 0.95: 13,190 rows, 39 columns\n"
     ]
    }
   ],
   "source": [
    "# # Test different thresholds to find what works\n",
    "# for threshold in [0.5, 0.6, 0.7, 0.8, 0.9, 0.95]:\n",
    "#     coverage = df_wide.notna().sum() / len(df_wide)\n",
    "#     cols_kept = coverage[coverage >= threshold].index\n",
    "#     temp_df = df_wide[cols_kept].interpolate(method='linear', limit=5, limit_direction='both').dropna()\n",
    "#     print(f\"Threshold {threshold}: {len(temp_df):,} rows, {len(cols_kept)} columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f42e9dd",
   "metadata": {},
   "source": [
    "## 6.A) optimal columns and handle missing values\n",
    "\n",
    "### The problem\n",
    "\n",
    "I have 111 site-species colm but their missing values different times. \n",
    "When any column has a gap at a timestamp, that entire row is dropped.Because of treshold = 0.8 I wanna use most of my data, order to do that I need to ran some test and find out that what is the best.\n",
    "\n",
    "- With all 111 columns: only 58 complete rows unfurtunatally it is unusable\n",
    "- Need to find balance between columns features and rows samples\n",
    "\n",
    "### Where is the sweet spot?\n",
    "\n",
    "I'll test different numbers of columns to max total data points rows × columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2fc345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns vs Rows\n",
      "----------------------------------------\n",
      "10 columns: 23,660 rows → 236,600 total data points\n",
      "15 columns: 22,122 rows → 331,830 total data points\n",
      "20 columns: 20,324 rows → 406,480 total data points\n",
      "25 columns: 17,944 rows → 448,600 total data points\n",
      "30 columns: 16,580 rows → 497,400 total data points\n",
      "35 columns: 14,221 rows → 497,735 total data points\n",
      "40 columns: 12,416 rows → 496,640 total data points\n",
      "45 columns: 10,070 rows → 453,150 total data points\n",
      "50 columns: 8,208 rows → 410,400 total data points\n",
      "\n",
      "Optimal: 35 columns with 14,221 rows\n"
     ]
    }
   ],
   "source": [
    "# # Testing different numbers of columns to find optimal balance\n",
    "# coverage = df_wide.notna().sum() / len(df_wide)\n",
    "# coverage_sorted = coverage.sort_values(ascending=False)\n",
    "\n",
    "# print(\"Columns vs Rows\")\n",
    "# print(\"-\" * 40)\n",
    "\n",
    "# results = []\n",
    "# for n_cols in [10, 15, 20, 25, 30, 35, 40, 45, 50]:\n",
    "#     best_cols = coverage_sorted.head(n_cols).index\n",
    "#     df_test = df_wide[best_cols].copy()\n",
    "#     df_test = df_test.interpolate(method='linear', limit=5, limit_direction='both')\n",
    "#     df_test = df_test.dropna()\n",
    "    \n",
    "#     total_data = len(df_test) * n_cols\n",
    "#     results.append({'columns': n_cols, 'rows': len(df_test), 'total': total_data})\n",
    "    \n",
    "#     print(f\"{n_cols} columns: {len(df_test):,} rows → {total_data:,} total data points\")\n",
    "\n",
    "# # Find sweetest spot \n",
    "# best = max(results, key=lambda x: x['total'])\n",
    "# print(f\"\\nOptimal: {best['columns']} columns with {best['rows']:,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3f7907",
   "metadata": {},
   "source": [
    "I will also check pollutants in selected colm, to see the pollutants I choose actually good mix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472ab092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 35 columns:\n",
      "\n",
      "  EN5_NO2: 99.6% coverage\n",
      "  WMD_NO2: 99.6% coverage\n",
      "  BT5_NO2: 99.5% coverage\n",
      "  HP1_PM10: 99.5% coverage\n",
      "  EN1_NO2: 99.4% coverage\n",
      "  ME9_NO2: 99.0% coverage\n",
      "  BT6_NO2: 99.0% coverage\n",
      "  BT8_PM10: 98.6% coverage\n",
      "  HV1_NO2: 98.3% coverage\n",
      "  BT4_PM10: 98.3% coverage\n",
      "  KC1_NO2: 98.1% coverage\n",
      "  BT8_NO2: 97.9% coverage\n",
      "  EI1_NO2: 97.8% coverage\n",
      "  HP1_NO2: 97.7% coverage\n",
      "  BX2_PM10: 97.7% coverage\n",
      "  GN0_NO2: 97.6% coverage\n",
      "  WM6_NO2: 97.5% coverage\n",
      "  IS6_NO2: 97.5% coverage\n",
      "  RI1_NO2: 97.4% coverage\n",
      "  HP1_O3: 97.3% coverage\n",
      "  BT6_PM10: 97.3% coverage\n",
      "  SK5_NO2: 97.0% coverage\n",
      "  BX1_O3: 96.8% coverage\n",
      "  GR9_NO2: 96.6% coverage\n",
      "  EN4_NO2: 96.6% coverage\n",
      "  GN6_NO2: 96.2% coverage\n",
      "  GR7_PM10: 96.1% coverage\n",
      "  KC1_O3: 96.0% coverage\n",
      "  GR7_NO2: 96.0% coverage\n",
      "  GN3_PM10: 95.9% coverage\n",
      "  LB4_NO2: 95.9% coverage\n",
      "  GN4_PM10: 95.7% coverage\n",
      "  GN4_NO2: 95.7% coverage\n",
      "  EA8_NO2: 95.7% coverage\n",
      "  EA6_NO2: 95.6% coverage\n",
      "\n",
      "Pollutant mix:\n",
      "NO2 stations: 24\n",
      "PM10 stations: 8\n",
      "O3 stations: 3\n"
     ]
    }
   ],
   "source": [
    "# # pollutant check  in selected columns\n",
    "# n_cols = best['columns'] # use 35 colmn with 14,221 row up.\n",
    "\n",
    "# best_cols = coverage_sorted.head(n_cols).index.tolist()\n",
    "\n",
    "# print(f\"Selected {n_cols} columns:\\n\")\n",
    "# for col in best_cols:\n",
    "#     print(f\"  {col}: {coverage_sorted[col]*100:.1f}% coverage\")\n",
    "\n",
    "# # Count by pollutant type\n",
    "# no2 = [c for c in best_cols if 'NO2' in c]\n",
    "# pm10 = [c for c in best_cols if 'PM10' in c]\n",
    "# o3 = [c for c in best_cols if 'O3' in c]\n",
    "\n",
    "# print(f\"\\nPollutant mix:\")\n",
    "# print(f\"NO2 stations: {len(no2)}\")\n",
    "# print(f\"PM10 stations: {len(pm10)}\")\n",
    "# print(f\"O3 stations: {len(o3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918b2ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" commented out function below because that's min_cov not gives me the max rows x col data point.\"\"\"\n",
    "\n",
    "# def handle_missing_values(df, max_gap=5, min_coverage=0.8):\n",
    "#     \"\"\"\n",
    "#     Handle NaN \n",
    "    \n",
    "#     Param\n",
    "#     max_gap : int max consecutive NaN values to interpolate\n",
    "#     min_coverage : Min. proportion of non-null values to keep a column.\n",
    "    \n",
    "#     \"\"\"\n",
    "#     df = df.copy()\n",
    "#     print(f\"Before: {df.shape}\")\n",
    "    \n",
    "#     # 1. rm columns with too many missing values\n",
    "#     coverage = df.notna().sum() / len(df)\n",
    "#     cols_to_keep = coverage[coverage >= min_coverage].index\n",
    "#     cols_removed = len(df.columns) - len(cols_to_keep)\n",
    "#     df = df[cols_to_keep]\n",
    "#     print(f\"Removed {cols_removed} columns with <{min_coverage*100:.0f}% coverage\")\n",
    "    \n",
    "#     # 2 Interpolate small gaps\n",
    "#     df = df.interpolate(method='linear', limit=max_gap, limit_direction='both')\n",
    "#     print(f\"Interpolated gaps up to {max_gap} consecutive values\")\n",
    "    \n",
    "#     # 3. Drop remaining rows with NaN\n",
    "#     rows_before = len(df)\n",
    "#     df = df.dropna()\n",
    "#     rows_dropped = rows_before - len(df)\n",
    "#     print(f\"Dropped {rows_dropped:,} rows with remaining NaN\")\n",
    "    \n",
    "#     print(f\"After: {df.shape}\")\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6925907e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (24456, 111)\n",
      "Removed 25 columns with <80% coverage\n",
      "Interpolated gaps up to 5 consecutive values\n",
      "Dropped 24,398 rows with remaining NaN\n",
      "After: (58, 86)\n",
      "\n",
      "Missing values remaining: 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\" commented out function below because that's min_cov not gives me the max rows x col data point.\"\"\"\n",
    "\n",
    "# # Handle missing values\n",
    "# df_clean = handle_missing_values(df_wide, max_gap=5, min_coverage=0.8)\n",
    "\n",
    "# print(f\"\\nMissing values remaining: {df_clean.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b898bd",
   "metadata": {},
   "source": [
    "## 6.B ) Reselect optimal col and handl NaN\n",
    "\n",
    "### The problem\n",
    "\n",
    "I have 111 site-species columns but their missing values occur at different times. \n",
    "When any column has a gap at a timestamp, that entire row is dropped.\n",
    "\n",
    "With all 111 columns: only 58 complete rows (unusable)\n",
    "\n",
    "### Finding the sweet spot\n",
    "\n",
    "Tested different column counts to maximise total data points (rows × columns):\n",
    "\n",
    "| Columns | Rows | Total data points |\n",
    "|---------|------|-------------------|\n",
    "| 10 | 23,660 | 236,600 |\n",
    "| 20 | 20,324 | 406,480 |\n",
    "| 30 | 16,580 | 497,400 |\n",
    "| **35** | **14,221** | **497,735**  optimal |\n",
    "| 40 | 12,416 | 496,640 |\n",
    "| 50 | 8,208 | 410,400 |\n",
    "\n",
    "### Selected columns\n",
    "\n",
    "35 columns with coverage between 95.6% and 99.6%:\n",
    "- NO2: 24 stations\n",
    "- PM10: 8 stations  \n",
    "- O3: 3 stations\n",
    "\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f6113da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset: 14,221 rows × 35 columns\n",
      "Pollutant mix: NO2=24, PM10=8, O3=3\n"
     ]
    }
   ],
   "source": [
    "# Select top 35 col ran tests for it 6.A  least nan \n",
    "coverage = df_wide.notna().sum() / len(df_wide)\n",
    "coverage_sorted = coverage.sort_values(ascending=False)\n",
    "\n",
    "n_cols = 35\n",
    "best_cols = coverage_sorted.head(n_cols).index.tolist()\n",
    "\n",
    "df_selected = df_wide[best_cols].copy()\n",
    "df_clean = df_selected.interpolate(method='linear', limit=5, limit_direction='both')\n",
    "df_clean = df_clean.dropna()\n",
    "\n",
    "print(f\"Final dataset: {len(df_clean):,} rows × {len(df_clean.columns)} columns\")\n",
    "\n",
    "# Verify pollutant mix\n",
    "no2 = sum(1 for c in best_cols if 'NO2' in c)\n",
    "pm10 = sum(1 for c in best_cols if 'PM10' in c)\n",
    "o3 = sum(1 for c in best_cols if 'O3' in c)\n",
    "print(f\"Pollutant mix: NO2={no2}, PM10={pm10}, O3={o3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb749f9",
   "metadata": {},
   "source": [
    "    Final dataset: 14,221 rows × 35 columns\n",
    "    Pollutant mix: NO2=24, PM10=8, O3=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65487425",
   "metadata": {},
   "source": [
    "## 7) temporal features addition:\n",
    " - extracting hour, day and month as column to make data wider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ee00cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_wide(df):\n",
    "    \"\"\"\n",
    "    Add temporal features to wide format data.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['hour'] = df.index.hour\n",
    "    df['day_of_week'] = df.index.dayofweek\n",
    "    df['month'] = df.index.month\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    \n",
    "    print(f\"Added temporal features\")\n",
    "    print(f\"Total features: {len(df.columns)}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bc681b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added temporal features\n",
      "Total features: 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>site_species</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@MeasurementDateGMT</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 01:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 02:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 03:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 04:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "site_species         hour  day_of_week  month  is_weekend\n",
       "@MeasurementDateGMT                                      \n",
       "2023-01-01 00:00:00     0            6      1           1\n",
       "2023-01-01 01:00:00     1            6      1           1\n",
       "2023-01-01 02:00:00     2            6      1           1\n",
       "2023-01-01 03:00:00     3            6      1           1\n",
       "2023-01-01 04:00:00     4            6      1           1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add temporal features\n",
    "df_features = temporal_wide(df_clean)\n",
    "\n",
    "# Preview\n",
    "df_features[['hour', 'day_of_week', 'month', 'is_weekend']].head()\n",
    "\n",
    "#  print(f\"df_features: {df_features.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083863a6",
   "metadata": {},
   "source": [
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th>site_species</th>\n",
    "      <th>hour</th>\n",
    "      <th>day_of_week</th>\n",
    "      <th>month</th>\n",
    "      <th>is_weekend</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>@MeasurementDateGMT</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>2023-01-01 00:00:00</th>\n",
    "      <td>0</td>\n",
    "      <td>6</td>\n",
    "      <td>1</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2023-01-01 01:00:00</th>\n",
    "      <td>1</td>\n",
    "      <td>6</td>\n",
    "      <td>1</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2023-01-01 02:00:00</th>\n",
    "      <td>2</td>\n",
    "      <td>6</td>\n",
    "      <td>1</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2023-01-01 03:00:00</th>\n",
    "      <td>3</td>\n",
    "      <td>6</td>\n",
    "      <td>1</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2023-01-01 04:00:00</th>\n",
    "      <td>4</td>\n",
    "      <td>6</td>\n",
    "      <td>1</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "\n",
    "Added temporal features\n",
    "Total features: 39"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b239a8a",
   "metadata": {},
   "source": [
    "## 8) Normalise the data\n",
    "\n",
    "Different features have different scales:\n",
    "- NO2: 0-200 µg/m³\n",
    "- PM25: 0-100 µg/m³\n",
    "- Hour: 0-23\n",
    "\n",
    "Neural networks work best when all inputs are on the same scale (0 to 1).\n",
    "\n",
    "MinMaxScaler from scikit-learn which applies:\n",
    "```\n",
    "X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "X_scaled = X_std * (max - min) + min\n",
    "```\n",
    "\n",
    "This transforms every value to a number between 0 and 1 (Géron, 2022).\n",
    "\n",
    "**Important:** Save the scaler object to reverse the transformation later when interpreting predictions.\n",
    "\n",
    "- MinMaxScaler is  scikit-learn lib. \n",
    "Scikit-learn (no date) sklearn.preprocessing.MinMaxScaler. Available at: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "\n",
    "Géron, A. (2022) Hands-on machine learning with scikit-learn, Keras, and TensorFlow. 3rd edn. Sebastopol: O'Reilly Media.\n",
    "Chapter 2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18e7abd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_data(df):\n",
    "    \"\"\"\n",
    "    Normalise all columns to 0-1 range using scikit-learn MinMaxScaler.\n",
    "\n",
    "    \"\"\"\n",
    "    feature_names = df.columns.tolist()\n",
    "    index = df.index\n",
    "    \n",
    "    # Fit and transform\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    normalised_values = scaler.fit_transform(df.values)\n",
    "    \n",
    "    # Create dataframe\n",
    "    normalised_df = pd.DataFrame(\n",
    "        normalised_values,\n",
    "        columns=feature_names,\n",
    "        index=index\n",
    "    )\n",
    "    \n",
    "    print(f\"Data normalised to range 0, 1\")\n",
    "    print(f\"Original range [{df.values.min():.2f}, {df.values.max():.2f}]\")\n",
    "    print(f\"Normalised range [{normalised_values.min():.2f}, {normalised_values.max():.2f}]\")\n",
    "    \n",
    "    return normalised_df, scaler, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d8836ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data normalised to range 0, 1\n",
      "Original range [0.00, 587.00]\n",
      "Normalised range [0.00, 1.00]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EN5_NO2</th>\n",
       "      <th>WMD_NO2</th>\n",
       "      <th>BT5_NO2</th>\n",
       "      <th>HP1_PM10</th>\n",
       "      <th>EN1_NO2</th>\n",
       "      <th>ME9_NO2</th>\n",
       "      <th>BT6_NO2</th>\n",
       "      <th>BT8_PM10</th>\n",
       "      <th>HV1_NO2</th>\n",
       "      <th>BT4_PM10</th>\n",
       "      <th>...</th>\n",
       "      <th>GN3_PM10</th>\n",
       "      <th>LB4_NO2</th>\n",
       "      <th>GN4_PM10</th>\n",
       "      <th>GN4_NO2</th>\n",
       "      <th>EA8_NO2</th>\n",
       "      <th>EA6_NO2</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@MeasurementDateGMT</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-01 00:00:00</th>\n",
       "      <td>0.061135</td>\n",
       "      <td>0.050996</td>\n",
       "      <td>0.069828</td>\n",
       "      <td>0.075868</td>\n",
       "      <td>0.067465</td>\n",
       "      <td>0.073740</td>\n",
       "      <td>0.062230</td>\n",
       "      <td>0.095833</td>\n",
       "      <td>0.066303</td>\n",
       "      <td>0.066440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208388</td>\n",
       "      <td>0.094123</td>\n",
       "      <td>0.055256</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.058506</td>\n",
       "      <td>0.071708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 01:00:00</th>\n",
       "      <td>0.055022</td>\n",
       "      <td>0.052755</td>\n",
       "      <td>0.061207</td>\n",
       "      <td>0.064568</td>\n",
       "      <td>0.056583</td>\n",
       "      <td>0.095561</td>\n",
       "      <td>0.048401</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.042688</td>\n",
       "      <td>0.025554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041940</td>\n",
       "      <td>0.244261</td>\n",
       "      <td>0.013477</td>\n",
       "      <td>0.023684</td>\n",
       "      <td>0.026103</td>\n",
       "      <td>0.085398</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 02:00:00</th>\n",
       "      <td>0.056769</td>\n",
       "      <td>0.048652</td>\n",
       "      <td>0.045690</td>\n",
       "      <td>0.078289</td>\n",
       "      <td>0.046790</td>\n",
       "      <td>0.069977</td>\n",
       "      <td>0.035436</td>\n",
       "      <td>0.045833</td>\n",
       "      <td>0.030881</td>\n",
       "      <td>0.030664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103539</td>\n",
       "      <td>0.175849</td>\n",
       "      <td>0.045148</td>\n",
       "      <td>0.019298</td>\n",
       "      <td>0.025203</td>\n",
       "      <td>0.073664</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 03:00:00</th>\n",
       "      <td>0.041921</td>\n",
       "      <td>0.018171</td>\n",
       "      <td>0.031897</td>\n",
       "      <td>0.103309</td>\n",
       "      <td>0.038085</td>\n",
       "      <td>0.064710</td>\n",
       "      <td>0.041487</td>\n",
       "      <td>0.054167</td>\n",
       "      <td>0.042688</td>\n",
       "      <td>0.025554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.137741</td>\n",
       "      <td>0.073450</td>\n",
       "      <td>0.012281</td>\n",
       "      <td>0.022502</td>\n",
       "      <td>0.058018</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01 04:00:00</th>\n",
       "      <td>0.039301</td>\n",
       "      <td>0.022860</td>\n",
       "      <td>0.052586</td>\n",
       "      <td>0.120258</td>\n",
       "      <td>0.043526</td>\n",
       "      <td>0.048157</td>\n",
       "      <td>0.052723</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.035422</td>\n",
       "      <td>0.028961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176933</td>\n",
       "      <td>0.145546</td>\n",
       "      <td>0.097709</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.036004</td>\n",
       "      <td>0.080183</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      EN5_NO2   WMD_NO2   BT5_NO2  HP1_PM10   EN1_NO2  \\\n",
       "@MeasurementDateGMT                                                     \n",
       "2023-01-01 00:00:00  0.061135  0.050996  0.069828  0.075868  0.067465   \n",
       "2023-01-01 01:00:00  0.055022  0.052755  0.061207  0.064568  0.056583   \n",
       "2023-01-01 02:00:00  0.056769  0.048652  0.045690  0.078289  0.046790   \n",
       "2023-01-01 03:00:00  0.041921  0.018171  0.031897  0.103309  0.038085   \n",
       "2023-01-01 04:00:00  0.039301  0.022860  0.052586  0.120258  0.043526   \n",
       "\n",
       "                      ME9_NO2   BT6_NO2  BT8_PM10   HV1_NO2  BT4_PM10  ...  \\\n",
       "@MeasurementDateGMT                                                    ...   \n",
       "2023-01-01 00:00:00  0.073740  0.062230  0.095833  0.066303  0.066440  ...   \n",
       "2023-01-01 01:00:00  0.095561  0.048401  0.033333  0.042688  0.025554  ...   \n",
       "2023-01-01 02:00:00  0.069977  0.035436  0.045833  0.030881  0.030664  ...   \n",
       "2023-01-01 03:00:00  0.064710  0.041487  0.054167  0.042688  0.025554  ...   \n",
       "2023-01-01 04:00:00  0.048157  0.052723  0.062500  0.035422  0.028961  ...   \n",
       "\n",
       "                     GN3_PM10   LB4_NO2  GN4_PM10   GN4_NO2   EA8_NO2  \\\n",
       "@MeasurementDateGMT                                                     \n",
       "2023-01-01 00:00:00  0.208388  0.094123  0.055256  0.017544  0.058506   \n",
       "2023-01-01 01:00:00  0.041940  0.244261  0.013477  0.023684  0.026103   \n",
       "2023-01-01 02:00:00  0.103539  0.175849  0.045148  0.019298  0.025203   \n",
       "2023-01-01 03:00:00  0.142857  0.137741  0.073450  0.012281  0.022502   \n",
       "2023-01-01 04:00:00  0.176933  0.145546  0.097709  0.007895  0.036004   \n",
       "\n",
       "                      EA6_NO2      hour  day_of_week  month  is_weekend  \n",
       "@MeasurementDateGMT                                                      \n",
       "2023-01-01 00:00:00  0.071708  0.000000          1.0    0.0         1.0  \n",
       "2023-01-01 01:00:00  0.085398  0.043478          1.0    0.0         1.0  \n",
       "2023-01-01 02:00:00  0.073664  0.086957          1.0    0.0         1.0  \n",
       "2023-01-01 03:00:00  0.058018  0.130435          1.0    0.0         1.0  \n",
       "2023-01-01 04:00:00  0.080183  0.173913          1.0    0.0         1.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalise the data\n",
    "df_normalised, scaler, feature_names = normalise_data(df_features)\n",
    "\n",
    "# Preview\n",
    "df_normalised.head()\n",
    "\n",
    "# print(f\"df_normalised: {df_normalised.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a76c76",
   "metadata": {},
   "source": [
    "  Data normalised to range 0, 1\n",
    "  Original range [0.00, 587.00]\n",
    "  Normalised range [0.00, 1.00]\n",
    "  df_normalised: (14221, 39)\n",
    "\n",
    "  <div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>EN5_NO2</th>\n",
    "      <th>WMD_NO2</th>\n",
    "      <th>BT5_NO2</th>\n",
    "      <th>HP1_PM10</th>\n",
    "      <th>EN1_NO2</th>\n",
    "      <th>ME9_NO2</th>\n",
    "      <th>BT6_NO2</th>\n",
    "      <th>BT8_PM10</th>\n",
    "      <th>HV1_NO2</th>\n",
    "      <th>BT4_PM10</th>\n",
    "      <th>...</th>\n",
    "      <th>GN3_PM10</th>\n",
    "      <th>LB4_NO2</th>\n",
    "      <th>GN4_PM10</th>\n",
    "      <th>GN4_NO2</th>\n",
    "      <th>EA8_NO2</th>\n",
    "      <th>EA6_NO2</th>\n",
    "      <th>hour</th>\n",
    "      <th>day_of_week</th>\n",
    "      <th>month</th>\n",
    "      <th>is_weekend</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>@MeasurementDateGMT</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>2023-01-01 00:00:00</th>\n",
    "      <td>0.061135</td>\n",
    "      <td>0.050996</td>\n",
    "      <td>0.069828</td>\n",
    "      <td>0.075868</td>\n",
    "      <td>0.067465</td>\n",
    "      <td>0.073740</td>\n",
    "      <td>0.062230</td>\n",
    "      <td>0.095833</td>\n",
    "      <td>0.066303</td>\n",
    "      <td>0.066440</td>\n",
    "      <td>...</td>\n",
    "      <td>0.208388</td>\n",
    "      <td>0.094123</td>\n",
    "      <td>0.055256</td>\n",
    "      <td>0.017544</td>\n",
    "      <td>0.058506</td>\n",
    "      <td>0.071708</td>\n",
    "      <td>0.000000</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2023-01-01 01:00:00</th>\n",
    "      <td>0.055022</td>\n",
    "      <td>0.052755</td>\n",
    "      <td>0.061207</td>\n",
    "      <td>0.064568</td>\n",
    "      <td>0.056583</td>\n",
    "      <td>0.095561</td>\n",
    "      <td>0.048401</td>\n",
    "      <td>0.033333</td>\n",
    "      <td>0.042688</td>\n",
    "      <td>0.025554</td>\n",
    "      <td>...</td>\n",
    "      <td>0.041940</td>\n",
    "      <td>0.244261</td>\n",
    "      <td>0.013477</td>\n",
    "      <td>0.023684</td>\n",
    "      <td>0.026103</td>\n",
    "      <td>0.085398</td>\n",
    "      <td>0.043478</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2023-01-01 02:00:00</th>\n",
    "      <td>0.056769</td>\n",
    "      <td>0.048652</td>\n",
    "      <td>0.045690</td>\n",
    "      <td>0.078289</td>\n",
    "      <td>0.046790</td>\n",
    "      <td>0.069977</td>\n",
    "      <td>0.035436</td>\n",
    "      <td>0.045833</td>\n",
    "      <td>0.030881</td>\n",
    "      <td>0.030664</td>\n",
    "      <td>...</td>\n",
    "      <td>0.103539</td>\n",
    "      <td>0.175849</td>\n",
    "      <td>0.045148</td>\n",
    "      <td>0.019298</td>\n",
    "      <td>0.025203</td>\n",
    "      <td>0.073664</td>\n",
    "      <td>0.086957</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2023-01-01 03:00:00</th>\n",
    "      <td>0.041921</td>\n",
    "      <td>0.018171</td>\n",
    "      <td>0.031897</td>\n",
    "      <td>0.103309</td>\n",
    "      <td>0.038085</td>\n",
    "      <td>0.064710</td>\n",
    "      <td>0.041487</td>\n",
    "      <td>0.054167</td>\n",
    "      <td>0.042688</td>\n",
    "      <td>0.025554</td>\n",
    "      <td>...</td>\n",
    "      <td>0.142857</td>\n",
    "      <td>0.137741</td>\n",
    "      <td>0.073450</td>\n",
    "      <td>0.012281</td>\n",
    "      <td>0.022502</td>\n",
    "      <td>0.058018</td>\n",
    "      <td>0.130435</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2023-01-01 04:00:00</th>\n",
    "      <td>0.039301</td>\n",
    "      <td>0.022860</td>\n",
    "      <td>0.052586</td>\n",
    "      <td>0.120258</td>\n",
    "      <td>0.043526</td>\n",
    "      <td>0.048157</td>\n",
    "      <td>0.052723</td>\n",
    "      <td>0.062500</td>\n",
    "      <td>0.035422</td>\n",
    "      <td>0.028961</td>\n",
    "      <td>...</td>\n",
    "      <td>0.176933</td>\n",
    "      <td>0.145546</td>\n",
    "      <td>0.097709</td>\n",
    "      <td>0.007895</td>\n",
    "      <td>0.036004</td>\n",
    "      <td>0.080183</td>\n",
    "      <td>0.173913</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "<p>5 rows × 39 columns</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eaeafd",
   "metadata": {},
   "source": [
    "## 9) Create sequences\n",
    "\n",
    "### Why sequences are needed\n",
    "\n",
    "A single row of data is just one moment with no context. Machine learning needs to see what happened before to make predictions.\n",
    "\n",
    "By creating sequences, I give the model historical context. Instead of seeing one timestamp, it sees the last 12 hours of measurements and can learn patterns like pollution rising or falling.\n",
    "\n",
    "### What is the sliding window method?\n",
    "\n",
    "The sliding window method restructures time series data for supervised learning (Brownlee, J. (2017) ). With `n_past=12`, I use the last 12 hours to predict the next hour:\n",
    "```\n",
    "Input (X):  [hour1, hour2, hour3, ..., hour12]  → shape: (12, num_features)\n",
    "Output (y): [hour13]                            → shape: (num_features,)\n",
    "```\n",
    "\n",
    "The window slides forward to create many training samples:\n",
    "```\n",
    "Sample 1: hours 1-12  → predict hour 13\n",
    "Sample 2: hours 2-13  → predict hour 14\n",
    "Sample 3: hours 3-14  → predict hour 15\n",
    "...\n",
    "```\n",
    "\n",
    "### Why 12 hours?\n",
    "\n",
    "Gilik, A., Ogrenci, A.S. and Ozmen, A. (2021). tested frame sizes between 8 and 15 hours for air quality prediction. I chose 12 because it captures half a day of patterns including rush hour variations.\n",
    "\n",
    "https://www.inf.szte.hu/~korosig/teach/books/Jason%20Brownlee%20-%20Introduction%20to%20Time%20Series%20Forecasting%20with%20Python%20-%20How%20to%20Prepare%20Data%20and%20Develop%20Models%20to%20Predict%20the%20Future-v1.9%20(2020).pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bf8853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, n_past=12, n_future=1):\n",
    "    \"\"\"\n",
    "    Create sequences for time series prediction using rolling window. \n",
    "    Sliding window method restructures time series as supervised learning\n",
    "    problem (Brownlee, J. (2017) ). Window size based on Gilik, Ogrenci and \n",
    "    Ozmen (2021) who tested values between 8-15 hours. \n",
    "    \n",
    "    Params\n",
    "\n",
    "    data : numpy.ndarray Normalised data of shape (timestamps, features).\n",
    "    n_past : int  Number of past timesteps to use as input.\n",
    "    n_future : int Number of future timesteps to predict.\n",
    "    \n",
    "    Returns\n",
    "    \n",
    "    tuple: (X, y)\n",
    "        X: Input sequences, shape (samples, n_past, features) (coordinates X needs to be capital)\n",
    "        y: Target values, shape (samples, features)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(n_past, len(data) - n_future + 1):\n",
    "        #  past n_past timesteps\n",
    "        X.append(data[i - n_past:i])\n",
    "        # Output value at n_future steps ahead\n",
    "        y.append(data[i + n_future - 1])\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    print(f\"Created sequences:\")\n",
    "    print(f\" n_past (history): {n_past} hours\")\n",
    "    print(f\"n_future (predict): {n_future} hour\")\n",
    "    print(f\"Samples: {len(X):,}\")\n",
    "    print(f\"X shape: {X.shape} (samples, timesteps, features)\")\n",
    "    print(f\"y shape: {y.shape} (samples, features)\")\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "32f14a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created sequences:\n",
      " n_past (history): 12 hours\n",
      "n_future (predict): 1 hour\n",
      "Samples: 14,209\n",
      "X shape: (14209, 12, 39) (samples, timesteps, features)\n",
      "y shape: (14209, 39) (samples, features)\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "N_PAST = 12      # Use last 12 hours as input\n",
    "N_FUTURE = 1     # Predict 1 hour ahead\n",
    "\n",
    "# Convert to numpy array\n",
    "data_array = df_normalised.values\n",
    "\n",
    "# Create sequences\n",
    "X, y = create_sequences(data_array, n_past=N_PAST, n_future=N_FUTURE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba380a7a",
   "metadata": {},
   "source": [
    "    Created sequences:\n",
    "    n_past (history): 12 hours\n",
    "    n_future (predict): 1 hour\n",
    "    Samples: 46\n",
    "    X shape: (46, 12, 90) (samples, timesteps, features)\n",
    "    y shape: (46, 90) (samples, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cbbb4f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pivot (wide format): 24456\n",
      "After handle_missing_values: 14221\n",
      "After normalisation: 14221\n"
     ]
    }
   ],
   "source": [
    "# Check how many rows at each step\n",
    "print(f\"After pivot (wide format): {len(df_wide)}\")\n",
    "print(f\"After handle_missing_values: {len(df_clean)}\")\n",
    "print(f\"After normalisation: {len(df_normalised)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f1ca38",
   "metadata": {},
   "source": [
    "## 10) Split into train/validation/test\n",
    "\n",
    "### Why split the data?\n",
    "\n",
    "Split data into three parts:\n",
    "- Training (70%): model learns patterns from this\n",
    "- Validation (15%): tune model and check for overfitting during training\n",
    "- Test (15%): final evaluation, model never sees this until the end\n",
    "```\n",
    "|-------- Training (70%) --------|--- Val (15%) ---|--- Test (15%) ---|\n",
    "Aug 2023                                                        Nov 2025\n",
    "```\n",
    "\n",
    "### Why sequential split, not random?\n",
    "\n",
    "For time series, split sequentially (oldest to newest), not randomly. \n",
    "Random splitting causes data leakage where model sees future data when \n",
    "training to predict the past (Brownlee, J. (2017) ).\n",
    "\n",
    "### Why 70/15/15 ratio?\n",
    "\n",
    "Gilik, A., Ogrenci, A.S. and Ozmen, A. (2021). used this split for air quality prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f722b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_time_series(X, y, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
    "    \"\"\"\n",
    "    Split time series data sequentially into train/validation and test\n",
    "    Sequential split avoids data leakage (Brownlee, J. (2017) ).\n",
    "    Ratio based on Gilik, Ogrenci and Ozmen (2021)\n",
    "    \"\"\"\n",
    "    n_samples = len(X)\n",
    "    \n",
    "    train_end = int(n_samples * train_ratio)\n",
    "    val_end = int(n_samples * (train_ratio + val_ratio))\n",
    "    \n",
    "    splits = {\n",
    "        'X_train': X[:train_end],\n",
    "        'y_train': y[:train_end],\n",
    "        'X_val': X[train_end:val_end],\n",
    "        'y_val': y[train_end:val_end],\n",
    "        'X_test': X[val_end:],\n",
    "        'y_test': y[val_end:]\n",
    "    }\n",
    "    \n",
    "    print(f\"Data split (sequential):\")\n",
    "    print(f\"Training: {len(splits['X_train']):,} samples ({train_ratio*100:.0f}%)\")\n",
    "    print(f\"Validation: {len(splits['X_val']):,} samples ({val_ratio*100:.0f}%)\")\n",
    "    print(f\"Test: {len(splits['X_test']):,} samples ({test_ratio*100:.0f}%)\")\n",
    "    \n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0825445c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split (sequential):\n",
      "Training: 9,946 samples (70%)\n",
      "Validation: 2,131 samples (15%)\n",
      "Test: 2,132 samples (15%)\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "splits = split_time_series(X, y, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03d670b",
   "metadata": {},
   "source": [
    "    Data split (sequential):\n",
    "    Training: 9,946 samples (70%)\n",
    "    Validation: 2,131 samples (15%)\n",
    "    Test: 2,132 samples (15%)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
